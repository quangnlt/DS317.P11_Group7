{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xhVqbYqNV9V"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-1Kjpo5NYpe",
        "outputId": "a56362e3-afbe-4b0e-e4a9-e00a1a96d0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "! gcloud config set project main-train-445501"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud ai models describe 4054423838656561152"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK7io4W9l6Oo",
        "outputId": "4c1d5948-7ba4-4704-aaf2-840339d86cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please specify a region:\n",
            " [1] africa-south1\n",
            " [2] asia-east1\n",
            " [3] asia-east2\n",
            " [4] asia-northeast1\n",
            " [5] asia-northeast2\n",
            " [6] asia-northeast3\n",
            " [7] asia-south1\n",
            " [8] asia-southeast1\n",
            " [9] asia-southeast2\n",
            " [10] australia-southeast1\n",
            " [11] australia-southeast2\n",
            " [12] europe-central2\n",
            " [13] europe-north1\n",
            " [14] europe-southwest1\n",
            " [15] europe-west1\n",
            " [16] europe-west2\n",
            " [17] europe-west3\n",
            " [18] europe-west4\n",
            " [19] europe-west6\n",
            " [20] europe-west8\n",
            " [21] europe-west9\n",
            " [22] europe-west12\n",
            " [23] me-central1\n",
            " [24] me-central2\n",
            " [25] me-west1\n",
            " [26] northamerica-northeast1\n",
            " [27] northamerica-northeast2\n",
            " [28] southamerica-east1\n",
            " [29] southamerica-west1\n",
            " [30] us-central1\n",
            " [31] us-east1\n",
            " [32] us-east4\n",
            " [33] us-east5\n",
            " [34] us-south1\n",
            " [35] us-west1\n",
            " [36] us-west2\n",
            " [37] us-west3\n",
            " [38] us-west4\n",
            " [39] cancel\n",
            "Please enter your numeric choice:  30\n",
            "\n",
            "To make this the default region, run `gcloud config set ai/region us-central1`.\n",
            "\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "containerSpec:\n",
            "  healthRoute: /health\n",
            "  imageUri: gcr.io/main-train-445501/predict-new1\n",
            "  ports:\n",
            "  - containerPort: 80\n",
            "  predictRoute: /predict\n",
            "createTime: '2024-12-23T07:25:52.040305Z'\n",
            "deployedModels:\n",
            "- deployedModelId: '2327328565932064768'\n",
            "  endpoint: projects/990238876285/locations/us-central1/endpoints/8237551010902441984\n",
            "displayName: student-predictt\n",
            "etag: AMEw9yM-cL0kc_tO9Y7863dpEnCz4_911K5rWfnG7qPASSs3g7LvgYMLu6v-ceSKdAx1\n",
            "modelSourceInfo:\n",
            "  sourceType: CUSTOM\n",
            "name: projects/990238876285/locations/us-central1/models/4054423838656561152\n",
            "predictSchemata: {}\n",
            "supportedDeploymentResourcesTypes:\n",
            "- DEDICATED_RESOURCES\n",
            "supportedExportFormats:\n",
            "- exportableContents:\n",
            "  - IMAGE\n",
            "  id: custom-trained\n",
            "supportedInputStorageFormats:\n",
            "- jsonl\n",
            "- bigquery\n",
            "- csv\n",
            "- tf-record\n",
            "- tf-record-gzip\n",
            "- file-list\n",
            "supportedOutputStorageFormats:\n",
            "- jsonl\n",
            "- bigquery\n",
            "updateTime: '2024-12-23T07:28:47.778907Z'\n",
            "versionAliases:\n",
            "- default\n",
            "versionCreateTime: '2024-12-23T07:25:52.040305Z'\n",
            "versionId: '1'\n",
            "versionUpdateTime: '2024-12-23T07:28:47.778907Z'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NomCeaX0SM0B",
        "outputId": "072f693c-bc35-4974-cc9f-e0e92b3f2933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "from fastapi import FastAPI, HTTPException, Request\n",
        "from fastapi.responses import JSONResponse\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "import numpy as np\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "app = FastAPI(title=\"Student Grade Prediction API\")\n",
        "\n",
        "# Define API routes\n",
        "AIP_HEALTH_ROUTE = os.environ.get('AIP_HEALTH_ROUTE', '/health')\n",
        "AIP_PREDICT_ROUTE = os.environ.get('AIP_PREDICT_ROUTE', '/predict')\n",
        "MODEL_INFO_ROUTE = '/model-info'\n",
        "FEATURES_ROUTE = '/features'\n",
        "\n",
        "# Load saved model and preprocessor\n",
        "model = TabNetRegressor()\n",
        "model.load_model(\"model8.zip\")\n",
        "\n",
        "class StudentData(BaseModel):\n",
        "    namsinh: int\n",
        "    dtb_toankhoa: float\n",
        "    dtb_tichluy: float\n",
        "    sotc_tichluy: int\n",
        "    diemtbhk_1: float\n",
        "    diemtbhk_2: float\n",
        "    diemtbhk_3: float\n",
        "    diemtbhk_4: float\n",
        "    diemtbhk_5: float\n",
        "    diemtbhk_6: float\n",
        "    diemtbhk_7: float\n",
        "\n",
        "class PredictionRequest(BaseModel):\n",
        "    instances: List[StudentData]\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    predicted_grade: float\n",
        "    confidence_score: Optional[float]\n",
        "\n",
        "class Predictions(BaseModel):\n",
        "    predictions: List[PredictionResponse]\n",
        "\n",
        "# Health check endpoint\n",
        "@app.get(AIP_HEALTH_ROUTE, status_code=200)\n",
        "async def health():\n",
        "    return {'healthy': 'ok'}\n",
        "\n",
        "# Model information endpoint\n",
        "@app.get(MODEL_INFO_ROUTE)\n",
        "async def model_info():\n",
        "    return {\n",
        "        'model_type': 'TabNet Regressor',\n",
        "        'feature_count': len(feature_names),\n",
        "        'target_variable': 'diemtbhk_8',\n",
        "    }\n",
        "\n",
        "# Available features endpoint\n",
        "@app.get(FEATURES_ROUTE)\n",
        "async def get_features():\n",
        "    return {\n",
        "        'features': feature_names.tolist(),\n",
        "        'required_features': StudentData.schema()['required']\n",
        "    }\n",
        "\n",
        "# Batch prediction endpoint\n",
        "@app.post(AIP_PREDICT_ROUTE, response_model=Predictions)\n",
        "async def predict(request: Request):\n",
        "      # Get JSON body\n",
        "      body = await request.json()\n",
        "      feature_names = ['namsinh', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy', 'diemtbhk_1', 'diemtbhk_2', 'diemtbhk_3', 'diemtbhk_4', 'diemtbhk_5', 'diemtbhk_6', 'diemtbhk_7']\n",
        "\n",
        "      # Convert instances to StudentData objects\n",
        "      instances = [StudentData(**inst) for inst in body[\"instances\"]]\n",
        "      input_data = pd.DataFrame([inst.dict() for inst in instances])\n",
        "\n",
        "      # Ensure columns are in correct order\n",
        "      input_data = input_data[feature_names]\n",
        "\n",
        "      # Make predictions\n",
        "      predictions = model.predict(input_data.values)\n",
        "      return {\"predictions\": predictions.tolist()}\n",
        "\n",
        "# Error handler\n",
        "@app.exception_handler(Exception)\n",
        "async def general_exception_handler(request: Request, exc: Exception):\n",
        "    return JSONResponse(\n",
        "        status_code=500,\n",
        "        content={\n",
        "            \"error\": str(exc),\n",
        "            \"type\": type(exc).__name__\n",
        "        }\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM7vbrvoSv9v",
        "outputId": "61f64643-8042-4c7c-f927-851471effa4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile Dockerfile\n",
        "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8-slim\n",
        "RUN pip install --no-cache-dir  numpy==1.23.1 pytorch-tabnet fastapi pydantic joblib pandas uvicorn\n",
        "COPY main.py ./main.py\n",
        "COPY model8.zip ./model8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVQSLbdkWOp4",
        "outputId": "91528559-022c-4b33-8507-a529622755c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cloudbuild.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile cloudbuild.yaml\n",
        "\n",
        "steps:\n",
        "# Bước 1: Tải mô hình từ Google Cloud Storage\n",
        "- name: 'gcr.io/cloud-builders/gsutil'\n",
        "  args: ['cp', 'gs://student_train/model/model8.zip', '.']\n",
        "  id: 'download-model'\n",
        "\n",
        "# Bước 2: Build Docker Image\n",
        "- name: 'gcr.io/cloud-builders/docker'\n",
        "  args: ['build', '-t', 'gcr.io/main-train-445501/predict-neww', '.']\n",
        "  waitFor: ['download-model']\n",
        "\n",
        "# Bước 3: Đẩy Docker Image lên Container Registry\n",
        "- name: 'gcr.io/cloud-builders/docker'\n",
        "  args: ['push', 'gcr.io/main-train-445501/predict-neww']\n",
        "\n",
        "images:\n",
        "- gcr.io/main-train-445501/predict-neww"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma3eWVowXbhR",
        "outputId": "a7a658ad-fb22-4115-b886-337334d87960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating temporary archive of 62 file(s) totalling 56.8 MiB before compression.\n",
            "Uploading tarball of [.] to [gs://main-train-445501_cloudbuild/source/1734969686.277068-15f2bbe17ada4e0a9dfb9a310893bbd0.tgz]\n",
            "Created [https://cloudbuild.googleapis.com/v1/projects/main-train-445501/locations/global/builds/95a1eff6-af0f-418a-8331-1791e72cd00d].\n",
            "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/95a1eff6-af0f-418a-8331-1791e72cd00d?project=990238876285 ].\n",
            "Waiting for build to complete. Polling interval: 1 second(s).\n",
            " REMOTE BUILD OUTPUT\n",
            "starting build \"95a1eff6-af0f-418a-8331-1791e72cd00d\"\n",
            "\n",
            "FETCHSOURCE\n",
            "Fetching storage object: gs://main-train-445501_cloudbuild/source/1734969686.277068-15f2bbe17ada4e0a9dfb9a310893bbd0.tgz#1734969696379913\n",
            "Copying gs://main-train-445501_cloudbuild/source/1734969686.277068-15f2bbe17ada4e0a9dfb9a310893bbd0.tgz#1734969696379913...\n",
            "/ [1 files][  7.5 MiB/  7.5 MiB]                                                \n",
            "Operation completed over 1 objects/7.5 MiB.\n",
            "BUILD\n",
            "Starting Step #0 - \"download-model\"\n",
            "Step #0 - \"download-model\": Already have image (with digest): gcr.io/cloud-builders/gsutil\n",
            "Step #0 - \"download-model\": Copying gs://student_train/model/model8.zip...\n",
            "/ [1 files][970.3 KiB/970.3 KiB]                                                \n",
            "Step #0 - \"download-model\": Operation completed over 1 objects/970.3 KiB.                                    \n",
            "Finished Step #0 - \"download-model\"\n",
            "Starting Step #1\n",
            "Step #1: Already have image (with digest): gcr.io/cloud-builders/docker\n",
            "Step #1: Sending build context to Docker daemon  59.57MB\n",
            "Step #1: Step 1/4 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.8-slim\n",
            "Step #1: python3.8-slim: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
            "Step #1: 302e3ee49805: Pulling fs layer\n",
            "Step #1: 030d7bdc20a6: Pulling fs layer\n",
            "Step #1: a3f1dfe736c5: Pulling fs layer\n",
            "Step #1: 3971691a3637: Pulling fs layer\n",
            "Step #1: bbf1d4580c66: Pulling fs layer\n",
            "Step #1: 476e6e3689e7: Pulling fs layer\n",
            "Step #1: c91e100ce6a8: Pulling fs layer\n",
            "Step #1: 933c39536099: Pulling fs layer\n",
            "Step #1: d2d2df0931f2: Pulling fs layer\n",
            "Step #1: 682bbd7ca49f: Pulling fs layer\n",
            "Step #1: a341ea5de3f7: Pulling fs layer\n",
            "Step #1: 591d286a3a62: Pulling fs layer\n",
            "Step #1: 4f4fb700ef54: Pulling fs layer\n",
            "Step #1: 23d105c66cb3: Pulling fs layer\n",
            "Step #1: 25a84c4df8c5: Pulling fs layer\n",
            "Step #1: 1c47f5a6834c: Pulling fs layer\n",
            "Step #1: 3971691a3637: Waiting\n",
            "Step #1: bbf1d4580c66: Waiting\n",
            "Step #1: 476e6e3689e7: Waiting\n",
            "Step #1: c91e100ce6a8: Waiting\n",
            "Step #1: 933c39536099: Waiting\n",
            "Step #1: d2d2df0931f2: Waiting\n",
            "Step #1: 682bbd7ca49f: Waiting\n",
            "Step #1: a341ea5de3f7: Waiting\n",
            "Step #1: 591d286a3a62: Waiting\n",
            "Step #1: 4f4fb700ef54: Waiting\n",
            "Step #1: 23d105c66cb3: Waiting\n",
            "Step #1: 25a84c4df8c5: Waiting\n",
            "Step #1: 1c47f5a6834c: Waiting\n",
            "Step #1: 302e3ee49805: Verifying Checksum\n",
            "Step #1: 302e3ee49805: Download complete\n",
            "Step #1: 030d7bdc20a6: Verifying Checksum\n",
            "Step #1: 030d7bdc20a6: Download complete\n",
            "Step #1: a3f1dfe736c5: Verifying Checksum\n",
            "Step #1: a3f1dfe736c5: Download complete\n",
            "Step #1: bbf1d4580c66: Verifying Checksum\n",
            "Step #1: bbf1d4580c66: Download complete\n",
            "Step #1: 3971691a3637: Verifying Checksum\n",
            "Step #1: 3971691a3637: Download complete\n",
            "Step #1: c91e100ce6a8: Verifying Checksum\n",
            "Step #1: c91e100ce6a8: Download complete\n",
            "Step #1: 476e6e3689e7: Download complete\n",
            "Step #1: 933c39536099: Verifying Checksum\n",
            "Step #1: 933c39536099: Download complete\n",
            "Step #1: d2d2df0931f2: Verifying Checksum\n",
            "Step #1: d2d2df0931f2: Download complete\n",
            "Step #1: 682bbd7ca49f: Verifying Checksum\n",
            "Step #1: 682bbd7ca49f: Download complete\n",
            "Step #1: a341ea5de3f7: Download complete\n",
            "Step #1: 591d286a3a62: Verifying Checksum\n",
            "Step #1: 591d286a3a62: Download complete\n",
            "Step #1: 4f4fb700ef54: Verifying Checksum\n",
            "Step #1: 4f4fb700ef54: Download complete\n",
            "Step #1: 23d105c66cb3: Verifying Checksum\n",
            "Step #1: 23d105c66cb3: Download complete\n",
            "Step #1: 302e3ee49805: Pull complete\n",
            "Step #1: 1c47f5a6834c: Download complete\n",
            "Step #1: 25a84c4df8c5: Verifying Checksum\n",
            "Step #1: 25a84c4df8c5: Download complete\n",
            "Step #1: 030d7bdc20a6: Pull complete\n",
            "Step #1: a3f1dfe736c5: Pull complete\n",
            "Step #1: 3971691a3637: Pull complete\n",
            "Step #1: bbf1d4580c66: Pull complete\n",
            "Step #1: 476e6e3689e7: Pull complete\n",
            "Step #1: c91e100ce6a8: Pull complete\n",
            "Step #1: 933c39536099: Pull complete\n",
            "Step #1: d2d2df0931f2: Pull complete\n",
            "Step #1: 682bbd7ca49f: Pull complete\n",
            "Step #1: a341ea5de3f7: Pull complete\n",
            "Step #1: 591d286a3a62: Pull complete\n",
            "Step #1: 4f4fb700ef54: Pull complete\n",
            "Step #1: 23d105c66cb3: Pull complete\n",
            "Step #1: 25a84c4df8c5: Pull complete\n",
            "Step #1: 1c47f5a6834c: Pull complete\n",
            "Step #1: Digest: sha256:7f294150993b63b992d3b9caa5427a18ee6e4cbb8aa3c21e133eb3cf2e531aea\n",
            "Step #1: Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.8-slim\n",
            "Step #1:  ---> d4c88916c9c2\n",
            "Step #1: Step 2/4 : RUN pip install --no-cache-dir  numpy==1.23.1 pytorch-tabnet fastapi pydantic joblib pandas uvicorn\n",
            "Step #1:  ---> Running in 09e5252c76fb\n",
            "Step #1: Collecting numpy==1.23.1\n",
            "Step #1:   Downloading numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 80.1 MB/s eta 0:00:00\n",
            "Step #1: Collecting pytorch-tabnet\n",
            "Step #1:   Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.5/44.5 kB 133.7 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: fastapi in /usr/local/lib/python3.8/site-packages (0.88.0)\n",
            "Step #1: Requirement already satisfied: pydantic in /usr/local/lib/python3.8/site-packages (1.10.18)\n",
            "Step #1: Collecting joblib\n",
            "Step #1:   Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 kB 203.1 MB/s eta 0:00:00\n",
            "Step #1: Collecting pandas\n",
            "Step #1:   Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 158.0 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: uvicorn in /usr/local/lib/python3.8/site-packages (0.20.0)\n",
            "Step #1: Collecting tqdm>=4.36\n",
            "Step #1:   Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 172.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting torch>=1.3\n",
            "Step #1:   Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 797.1/797.1 MB 188.2 MB/s eta 0:00:00\n",
            "Step #1: Collecting scikit_learn>0.21\n",
            "Step #1:   Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 185.1 MB/s eta 0:00:00\n",
            "Step #1: Collecting scipy>1.4\n",
            "Step #1:   Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 174.4 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: starlette==0.22.0 in /usr/local/lib/python3.8/site-packages (from fastapi) (0.22.0)\n",
            "Step #1: Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/site-packages (from starlette==0.22.0->fastapi) (4.5.2)\n",
            "Step #1: Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.8/site-packages (from starlette==0.22.0->fastapi) (4.12.2)\n",
            "Step #1: Collecting pytz>=2020.1\n",
            "Step #1:   Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 508.0/508.0 kB 176.7 MB/s eta 0:00:00\n",
            "Step #1: Collecting python-dateutil>=2.8.2\n",
            "Step #1:   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 210.6 MB/s eta 0:00:00\n",
            "Step #1: Collecting tzdata>=2022.1\n",
            "Step #1:   Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 346.6/346.6 kB 217.8 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/site-packages (from uvicorn) (8.1.7)\n",
            "Step #1: Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.8/site-packages (from uvicorn) (0.14.0)\n",
            "Step #1: Collecting six>=1.5\n",
            "Step #1:   Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Step #1: Collecting threadpoolctl>=2.0.0\n",
            "Step #1:   Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Step #1: Collecting nvidia-cufft-cu12==11.0.2.54\n",
            "Step #1:   Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 170.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-nvtx-cu12==12.1.105\n",
            "Step #1:   Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 162.0 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cusparse-cu12==12.1.0.106\n",
            "Step #1:   Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 176.5 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cudnn-cu12==9.1.0.70\n",
            "Step #1:   Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 169.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting networkx\n",
            "Step #1:   Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 190.0 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-nccl-cu12==2.20.5\n",
            "Step #1:   Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 176.2/176.2 MB 185.5 MB/s eta 0:00:00\n",
            "Step #1: Collecting fsspec\n",
            "Step #1:   Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 183.9/183.9 kB 203.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
            "Step #1:   Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 172.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting triton==3.0.0\n",
            "Step #1:   Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.4/209.4 MB 194.3 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
            "Step #1:   Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 228.1 MB/s eta 0:00:00\n",
            "Step #1: Collecting filelock\n",
            "Step #1:   Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Step #1: Collecting nvidia-curand-cu12==10.3.2.106\n",
            "Step #1:   Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 186.7 MB/s eta 0:00:00\n",
            "Step #1: Collecting sympy\n",
            "Step #1:   Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 173.9 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cusolver-cu12==11.4.5.107\n",
            "Step #1:   Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 177.3 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Step #1: Collecting nvidia-cublas-cu12==12.1.3.1\n",
            "Step #1:   Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 181.6 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
            "Step #1:   Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 140.4 MB/s eta 0:00:00\n",
            "Step #1: Collecting nvidia-nvjitlink-cu12\n",
            "Step #1:   Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 174.0 MB/s eta 0:00:00\n",
            "Step #1: Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (3.10)\n",
            "Step #1: Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (1.3.1)\n",
            "Step #1: Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.8/site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi) (1.2.2)\n",
            "Step #1: Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Step #1: Collecting mpmath<1.4,>=1.1.0\n",
            "Step #1:   Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Step #1:      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 212.6 MB/s eta 0:00:00\n",
            "Step #1: Installing collected packages: pytz, mpmath, tzdata, tqdm, threadpoolctl, sympy, six, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, joblib, fsspec, filelock, triton, scipy, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, scikit_learn, pandas, nvidia-cusolver-cu12, torch, pytorch-tabnet\n",
            "Step #1: Successfully installed filelock-3.16.1 fsspec-2024.12.0 joblib-1.4.2 mpmath-1.3.0 networkx-3.1 numpy-1.23.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 pandas-2.0.3 python-dateutil-2.9.0.post0 pytorch-tabnet-4.1.0 pytz-2024.2 scikit_learn-1.3.2 scipy-1.10.1 six-1.17.0 sympy-1.13.3 threadpoolctl-3.5.0 torch-2.4.1 tqdm-4.67.1 triton-3.0.0 tzdata-2024.2\n",
            "Step #1: \u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "Step #1: \u001b[0m\u001b[91m\n",
            "Step #1: [notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
            "Step #1: [notice] To update, run: pip install --upgrade pip\n",
            "Step #1: \u001b[0mRemoving intermediate container 09e5252c76fb\n",
            "Step #1:  ---> 233c0260ccf2\n",
            "Step #1: Step 3/4 : COPY main.py ./main.py\n",
            "Step #1:  ---> b869b3e08612\n",
            "Step #1: Step 4/4 : COPY model8.zip ./model8.zip\n",
            "Step #1:  ---> 93df46d9a09f\n",
            "Step #1: Successfully built 93df46d9a09f\n",
            "Step #1: Successfully tagged gcr.io/main-train-445501/predict-neww:latest\n",
            "Finished Step #1\n",
            "Starting Step #2\n",
            "Step #2: Already have image (with digest): gcr.io/cloud-builders/docker\n",
            "Step #2: Using default tag: latest\n",
            "Step #2: The push refers to repository [gcr.io/main-train-445501/predict-neww]\n",
            "Step #2: f948f9e3fc72: Preparing\n",
            "Step #2: 204962e88a7a: Preparing\n",
            "Step #2: 21d02895b713: Preparing\n",
            "Step #2: 349783903a0b: Preparing\n",
            "Step #2: 0593e0abadd7: Preparing\n",
            "Step #2: 1c8d0524265e: Preparing\n",
            "Step #2: 5f70bf18a086: Preparing\n",
            "Step #2: dacb3947f503: Preparing\n",
            "Step #2: 31f1f51e68e2: Preparing\n",
            "Step #2: e4800dca176e: Preparing\n",
            "Step #2: cd752e95cbfa: Preparing\n",
            "Step #2: 97670aa1c61b: Preparing\n",
            "Step #2: 1798d8b77003: Preparing\n",
            "Step #2: c735df600e5f: Preparing\n",
            "Step #2: ab18fae321b5: Preparing\n",
            "Step #2: d2a2207b52a4: Preparing\n",
            "Step #2: 5d2d143f3d7f: Preparing\n",
            "Step #2: c3772b569c3a: Preparing\n",
            "Step #2: 8d853c8add5d: Preparing\n",
            "Step #2: 97670aa1c61b: Waiting\n",
            "Step #2: 1798d8b77003: Waiting\n",
            "Step #2: c735df600e5f: Waiting\n",
            "Step #2: ab18fae321b5: Waiting\n",
            "Step #2: d2a2207b52a4: Waiting\n",
            "Step #2: 5d2d143f3d7f: Waiting\n",
            "Step #2: c3772b569c3a: Waiting\n",
            "Step #2: 8d853c8add5d: Waiting\n",
            "Step #2: dacb3947f503: Waiting\n",
            "Step #2: 31f1f51e68e2: Waiting\n",
            "Step #2: e4800dca176e: Waiting\n",
            "Step #2: cd752e95cbfa: Waiting\n",
            "Step #2: 1c8d0524265e: Waiting\n",
            "Step #2: 5f70bf18a086: Waiting\n",
            "Step #2: 0593e0abadd7: Layer already exists\n",
            "Step #2: 349783903a0b: Layer already exists\n",
            "Step #2: 5f70bf18a086: Layer already exists\n",
            "Step #2: 1c8d0524265e: Layer already exists\n",
            "Step #2: dacb3947f503: Layer already exists\n",
            "Step #2: 31f1f51e68e2: Layer already exists\n",
            "Step #2: e4800dca176e: Layer already exists\n",
            "Step #2: cd752e95cbfa: Layer already exists\n",
            "Step #2: 1798d8b77003: Layer already exists\n",
            "Step #2: 97670aa1c61b: Layer already exists\n",
            "Step #2: f948f9e3fc72: Pushed\n",
            "Step #2: c735df600e5f: Layer already exists\n",
            "Step #2: ab18fae321b5: Layer already exists\n",
            "Step #2: 204962e88a7a: Pushed\n",
            "Step #2: d2a2207b52a4: Layer already exists\n",
            "Step #2: 5d2d143f3d7f: Layer already exists\n",
            "Step #2: c3772b569c3a: Layer already exists\n",
            "Step #2: 8d853c8add5d: Layer already exists\n",
            "Step #2: 21d02895b713: Pushed\n",
            "Step #2: latest: digest: sha256:ad61b507b9f4d0d2771c519e2d33a0ac1b3bee01d57048cfc3e6a5fdb1868214 size: 4283\n",
            "Finished Step #2\n",
            "PUSH\n",
            "Pushing gcr.io/main-train-445501/predict-neww\n",
            "The push refers to repository [gcr.io/main-train-445501/predict-neww]\n",
            "f948f9e3fc72: Preparing\n",
            "204962e88a7a: Preparing\n",
            "21d02895b713: Preparing\n",
            "349783903a0b: Preparing\n",
            "0593e0abadd7: Preparing\n",
            "1c8d0524265e: Preparing\n",
            "5f70bf18a086: Preparing\n",
            "dacb3947f503: Preparing\n",
            "31f1f51e68e2: Preparing\n",
            "e4800dca176e: Preparing\n",
            "cd752e95cbfa: Preparing\n",
            "97670aa1c61b: Preparing\n",
            "1798d8b77003: Preparing\n",
            "c735df600e5f: Preparing\n",
            "ab18fae321b5: Preparing\n",
            "d2a2207b52a4: Preparing\n",
            "5d2d143f3d7f: Preparing\n",
            "c3772b569c3a: Preparing\n",
            "8d853c8add5d: Preparing\n",
            "1c8d0524265e: Waiting\n",
            "5f70bf18a086: Waiting\n",
            "dacb3947f503: Waiting\n",
            "31f1f51e68e2: Waiting\n",
            "e4800dca176e: Waiting\n",
            "cd752e95cbfa: Waiting\n",
            "97670aa1c61b: Waiting\n",
            "1798d8b77003: Waiting\n",
            "c735df600e5f: Waiting\n",
            "ab18fae321b5: Waiting\n",
            "d2a2207b52a4: Waiting\n",
            "5d2d143f3d7f: Waiting\n",
            "c3772b569c3a: Waiting\n",
            "8d853c8add5d: Waiting\n",
            "f948f9e3fc72: Layer already exists\n",
            "0593e0abadd7: Layer already exists\n",
            "349783903a0b: Layer already exists\n",
            "204962e88a7a: Layer already exists\n",
            "21d02895b713: Layer already exists\n",
            "1c8d0524265e: Layer already exists\n",
            "dacb3947f503: Layer already exists\n",
            "5f70bf18a086: Layer already exists\n",
            "e4800dca176e: Layer already exists\n",
            "31f1f51e68e2: Layer already exists\n",
            "cd752e95cbfa: Layer already exists\n",
            "97670aa1c61b: Layer already exists\n",
            "1798d8b77003: Layer already exists\n",
            "ab18fae321b5: Layer already exists\n",
            "c735df600e5f: Layer already exists\n",
            "d2a2207b52a4: Layer already exists\n",
            "5d2d143f3d7f: Layer already exists\n",
            "8d853c8add5d: Layer already exists\n",
            "c3772b569c3a: Layer already exists\n",
            "latest: digest: sha256:ad61b507b9f4d0d2771c519e2d33a0ac1b3bee01d57048cfc3e6a5fdb1868214 size: 4283\n",
            "DONE\n",
            "\n",
            "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                           IMAGES                                           STATUS\n",
            "95a1eff6-af0f-418a-8331-1791e72cd00d  2024-12-23T16:01:36+00:00  7M36S     gs://main-train-445501_cloudbuild/source/1734969686.277068-15f2bbe17ada4e0a9dfb9a310893bbd0.tgz  gcr.io/main-train-445501/predict-neww (+1 more)  SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!gcloud builds submit --config cloudbuild.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JBJlqQLXdfv",
        "outputId": "f5e7f6ac-0639-4b80-feb3-9faccffc0b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai models upload \\\n",
        "  --container-ports=80 \\\n",
        "  --container-predict-route=\"/predict\" \\\n",
        "  --container-health-route=\"/health\" \\\n",
        "  --region=us-central1 \\\n",
        "  --display-name=student-predictt \\\n",
        "  --container-image-uri=gcr.io/main-train-445501/predict-neww"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7sNV3K5Xl3E",
        "outputId": "29fc8743-35a6-4c39-c948-ef5e285b3acf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Created Vertex AI endpoint: projects/990238876285/locations/us-central1/endpoints/970993012140146688.\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai endpoints create \\\n",
        "  --project=main-train-445501 \\\n",
        "  --region=us-central1 \\\n",
        "  --display-name=student-predictt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K7PEoAQXqk9",
        "outputId": "5b3a953e-cb2c-4f56-b830-6a2892dc5c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Deployed a model to the endpoint 970993012140146688. Id of the deployed model: 4026874475311005696.\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai endpoints deploy-model 970993012140146688 \\\n",
        "  --project=main-train-445501 \\\n",
        "  --region=us-central1 \\\n",
        "  --model=3052372921566625792 \\\n",
        "  --traffic-split=0=100 \\\n",
        "  --machine-type=\"n1-standard-2\" \\\n",
        "  --display-name=studentt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOMVWOOpkQVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca56e3ae-abee-48c2-d2c6-c986ba222b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting request.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile request.json\n",
        "{\n",
        "  \"instances\": [\n",
        "    {\n",
        "      \"namsinh\": 19,\n",
        "      \"dtb_toankhoa\": 9.37,\n",
        "      \"dtb_tichluy\": 9.37,\n",
        "      \"sotc_tichluy\": 24,\n",
        "      \"diemtbhk_1\": 9.37,\n",
        "      \"diemtbhk_2\": 9.34,\n",
        "      \"diemtbhk_3\": 9.4,\n",
        "      \"diemtbhk_4\": 9.37,\n",
        "      \"diemtbhk_5\": 9.37,\n",
        "      \"diemtbhk_6\": 9.37,\n",
        "      \"diemtbhk_7\": 9.37\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGCcJaELkUlj",
        "outputId": "51eb1a2a-a46e-47c6-f688-31924f559e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ai.endpoints.predict) HttpError accessing <https://us-central1-prediction-aiplatform.googleapis.com/v1/projects/main-train-445501/locations/us-central1/endpoints/2613680976223535104:predict?alt=json>: response: <{'date': 'Mon, 23 Dec 2024 15:56:12 GMT', 'content-type': 'application/json', 'x-vertex-ai-internal-prediction-backend': 'harpoon', 'vary': 'Origin, X-Origin, Referer', 'content-encoding': 'gzip', 'server': 'scaffolding on HTTPServer2', 'x-xss-protection': '0', 'x-frame-options': 'SAMEORIGIN', 'x-content-type-options': 'nosniff', 'transfer-encoding': 'chunked', 'status': 500}>, content <{\"error\":\"1 validation error for Predictions\\nresponse\\n  value is not a valid dict (type=type_error.dict)\",\"type\":\"ValidationError\"}>\n",
            "This may be due to network connectivity issues. Please check your network settings, and the status of the service you are trying to reach.\n"
          ]
        }
      ],
      "source": [
        "!gcloud ai endpoints predict 2613680976223535104 \\\n",
        "  --region=us-central1 \\\n",
        "  --json-request=request.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WarqOKHxHy4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVME6eNeIURu",
        "outputId": "6f5713d8-290e-4441-f6b9-a333c6454d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.6.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pytorch_tabnet.tab_model import TabNetRegressor"
      ],
      "metadata": {
        "id": "QAcmxjL3IXK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/request.json', 'r') as file:\n",
        "#     body = json.load(file)  # Đọc file JSON thành dict\n",
        "\n",
        "# # Danh sách các đặc trưng\n",
        "# feature_names = ['namsinh', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy',\n",
        "#                  'diemtbhk_1', 'diemtbhk_2', 'diemtbhk_3', 'diemtbhk_4',\n",
        "#                  'diemtbhk_5', 'diemtbhk_6', 'diemtbhk_7']\n",
        "\n",
        "# # Chuyển đổi dữ liệu thành đối tượng StudentData\n",
        "# instances = [StudentData(**inst) for inst in body[\"instances\"]]\n",
        "# input_data = pd.DataFrame([inst.dict() for inst in instances])\n",
        "\n",
        "# # Ensure columns are in correct order\n",
        "# input_data = input_data[feature_names]\n",
        "# model = TabNetRegressor()\n",
        "# model.load_model(\"model8.zip\")\n",
        "\n",
        "# # Make predictions\n",
        "# predictions = model.predict(input_data.values)\n",
        "# predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXuDnpYSGtaK",
        "outputId": "b6e688d7-f306-485d-cf55-3388fae3fa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-a09cde8478b3>:11: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  input_data = pd.DataFrame([inst.dict() for inst in instances])\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:454: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  saved_state_dict = torch.load(f, map_location=self.device)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.67573]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# return {\"predictions\": predictions.tolist()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYz_7ugtPygv",
        "outputId": "d113348a-fae6-4e73-9d78-7ec361bbd442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions [[9.675729751586914]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input_data.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_UpNEeFIu4t",
        "outputId": "486cfb58-a632-4656-a1d6-dce8a695ebf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19.  ,  9.37,  9.37, 24.  ,  9.37,  9.34,  9.4 ,  9.37,  9.37,\n",
              "         9.37,  9.37]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJYSSm5eg2Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "5a1e0ed9-455e-465f-f2bf-b4081569d800"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "500 {\"error\":\"1 validation error for Predictions\\nresponse -> predictions -> 0\\n  value is not a valid dict (type=type_error.dict)\",\"type\":\"ValidationError\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INTERNAL\n\tdetails = \"{\"error\":\"1 validation error for Predictions\\nresponse -> predictions -> 0\\n  value is not a valid dict (type=type_error.dict)\",\"type\":\"ValidationError\"}\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:108.177.12.95:443 {created_time:\"2024-12-23T16:39:28.559817644+00:00\", grpc_status:13, grpc_message:\"{\\\"error\\\":\\\"1 validation error for Predictions\\\\nresponse -> predictions -> 0\\\\n  value is not a valid dict (type=type_error.dict)\\\",\\\"type\\\":\\\"ValidationError\\\"}\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-13a44000d716>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m predict_custom_trained_model_sample(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"990238876285\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mendpoint_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"970993012140146688\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-a51f0d1ff13c>\u001b[0m in \u001b[0;36mpredict_custom_trained_model_sample\u001b[0;34m(project, endpoint_id, instances, location, api_endpoint)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     )\n\u001b[0;32m---> 49\u001b[0;31m     response = client.predict(\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    876\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalServerError\u001b[0m: 500 {\"error\":\"1 validation error for Predictions\\nresponse -> predictions -> 0\\n  value is not a valid dict (type=type_error.dict)\",\"type\":\"ValidationError\"}"
          ]
        }
      ],
      "source": [
        "student_data = {\n",
        "    \"namsinh\": 10,\n",
        "    \"dtb_toankhoa\": 8.0,\n",
        "    \"dtb_tichluy\": 8.2,\n",
        "    \"sotc_tichluy\": 120,\n",
        "    \"diemtbhk_1\": 8.3,\n",
        "    \"diemtbhk_2\": 8.4,\n",
        "    \"diemtbhk_3\": 8.5,\n",
        "    \"diemtbhk_4\": 8.6,\n",
        "    \"diemtbhk_5\": 8.7,\n",
        "    \"diemtbhk_6\": 8.8,\n",
        "    \"diemtbhk_7\": 8.9\n",
        "}\n",
        "\n",
        "predict_custom_trained_model_sample(\n",
        "    project=\"990238876285\",\n",
        "    endpoint_id=\"970993012140146688\",\n",
        "    location=\"us-central1\",\n",
        "    instances=student_data\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPPEiXu9g7Cj"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# [START aiplatform_predict_custom_trained_model_sample]\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import json_format\n",
        "from google.protobuf.struct_pb2 import Value\n",
        "\n",
        "\n",
        "def predict_custom_trained_model_sample(\n",
        "    project: str,\n",
        "    endpoint_id: str,\n",
        "    instances: Union[Dict, List[Dict]],\n",
        "    location: str = \"us-central1\",\n",
        "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
        "):\n",
        "    \"\"\"\n",
        "    `instances` can be either single instance of type dict or a list\n",
        "    of instances.\n",
        "    \"\"\"\n",
        "    # The AI Platform services require regional API endpoints.\n",
        "    client_options = {\"api_endpoint\": api_endpoint}\n",
        "    # Initialize client that will be used to create and send requests.\n",
        "    # This client only needs to be created once, and can be reused for multiple requests.\n",
        "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
        "    instances = instances if isinstance(instances, list) else [instances]\n",
        "    instances = [\n",
        "        json_format.ParseDict(instance_dict, Value()) for instance_dict in instances\n",
        "    ]\n",
        "    parameters_dict = {}\n",
        "    parameters = json_format.ParseDict(parameters_dict, Value())\n",
        "    endpoint = client.endpoint_path(\n",
        "        project=project, location=location, endpoint=endpoint_id\n",
        "    )\n",
        "    response = client.predict(\n",
        "        endpoint=endpoint, instances=instances, parameters=parameters\n",
        "    )\n",
        "    print(\"response\")\n",
        "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
        "    # The predictions are a google.protobuf.Value representation of the model's predictions.\n",
        "    predictions = response.predictions\n",
        "    for prediction in predictions:\n",
        "        print(\" prediction:\", prediction)\n",
        "\n",
        "\n",
        "# [END aiplatform_predict_custom_trained_model_sample]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}