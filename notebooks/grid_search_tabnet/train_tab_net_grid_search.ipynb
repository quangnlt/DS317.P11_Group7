{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ozAhOSc_RFb",
        "outputId": "42d3a847-f88a-44f6-dbe2-eaaaf95e31af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.6.0)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ef4codmtBhiC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ2I5EscBie7",
        "outputId": "a861c699-caa5-413b-f1ec-0ddb5de25855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "6m_Eu0MGBjab",
        "outputId": "37ee8604-b9bd-448d-ead5-f630c46fa486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       mssv  namsinh  gioitinh         drl  \\\n",
              "0  39B39397XPvAibaEXe/vGZ1xWLvpK7wMZlgBlCBs       19         0   75.198135   \n",
              "1  3AB392AFXPvAibaEXe/NRwqjPAC0MKjf0QSiSLjM       17         0   85.000000   \n",
              "2  BEC54CF0XPvAibaEXe/qZKhoIW7F1rbPON7lHJUG       19         0   82.000000   \n",
              "3  43386D57XPvAibaEXe/nw3DhNQnHfzJZvI0o00SJ       20         0   75.655535   \n",
              "4  8F1A725FXPvAibaEXe88DMpF1KL2K3HyZfgFjAif       19         0  100.000000   \n",
              "\n",
              "   diem_tt  dtb_toankhoa  dtb_tichluy  sotc_tichluy  diemtbhk_1  diemtbhk_2  \\\n",
              "0     30.0          9.37         9.37            24        9.37        9.34   \n",
              "1     26.5          7.07         7.07           139        7.00        6.74   \n",
              "2     30.0          6.54         6.54            18        6.54        6.54   \n",
              "3     22.0          1.83         1.83             4        3.56        0.00   \n",
              "4     30.0          9.31         9.31            64        9.21        9.32   \n",
              "\n",
              "   diemtbhk_3  diemtbhk_4  diemtbhk_5  diemtbhk_6  diemtbhk_7  diemtbhk_8  \n",
              "0        9.40    9.370000    9.370000    9.370000    9.370000    9.370000  \n",
              "1        6.25    6.230000    7.150000    6.920000    6.970000    7.600000  \n",
              "2        6.54    6.540000    6.540000    6.540000    6.540000    6.540000  \n",
              "3        1.78    1.780000    1.780000    1.780000    1.780000    1.780000  \n",
              "4        9.41    9.313333    9.313333    9.313333    9.313333    9.313333  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88651a70-fc7b-4d6a-8c66-b36062c0d47a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mssv</th>\n",
              "      <th>namsinh</th>\n",
              "      <th>gioitinh</th>\n",
              "      <th>drl</th>\n",
              "      <th>diem_tt</th>\n",
              "      <th>dtb_toankhoa</th>\n",
              "      <th>dtb_tichluy</th>\n",
              "      <th>sotc_tichluy</th>\n",
              "      <th>diemtbhk_1</th>\n",
              "      <th>diemtbhk_2</th>\n",
              "      <th>diemtbhk_3</th>\n",
              "      <th>diemtbhk_4</th>\n",
              "      <th>diemtbhk_5</th>\n",
              "      <th>diemtbhk_6</th>\n",
              "      <th>diemtbhk_7</th>\n",
              "      <th>diemtbhk_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39B39397XPvAibaEXe/vGZ1xWLvpK7wMZlgBlCBs</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>75.198135</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.37</td>\n",
              "      <td>9.37</td>\n",
              "      <td>24</td>\n",
              "      <td>9.37</td>\n",
              "      <td>9.34</td>\n",
              "      <td>9.40</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>9.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3AB392AFXPvAibaEXe/NRwqjPAC0MKjf0QSiSLjM</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>26.5</td>\n",
              "      <td>7.07</td>\n",
              "      <td>7.07</td>\n",
              "      <td>139</td>\n",
              "      <td>7.00</td>\n",
              "      <td>6.74</td>\n",
              "      <td>6.25</td>\n",
              "      <td>6.230000</td>\n",
              "      <td>7.150000</td>\n",
              "      <td>6.920000</td>\n",
              "      <td>6.970000</td>\n",
              "      <td>7.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BEC54CF0XPvAibaEXe/qZKhoIW7F1rbPON7lHJUG</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6.54</td>\n",
              "      <td>6.54</td>\n",
              "      <td>18</td>\n",
              "      <td>6.54</td>\n",
              "      <td>6.54</td>\n",
              "      <td>6.54</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>6.540000</td>\n",
              "      <td>6.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43386D57XPvAibaEXe/nw3DhNQnHfzJZvI0o00SJ</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>75.655535</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.83</td>\n",
              "      <td>4</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>1.780000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8F1A725FXPvAibaEXe88DMpF1KL2K3HyZfgFjAif</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>30.0</td>\n",
              "      <td>9.31</td>\n",
              "      <td>9.31</td>\n",
              "      <td>64</td>\n",
              "      <td>9.21</td>\n",
              "      <td>9.32</td>\n",
              "      <td>9.41</td>\n",
              "      <td>9.313333</td>\n",
              "      <td>9.313333</td>\n",
              "      <td>9.313333</td>\n",
              "      <td>9.313333</td>\n",
              "      <td>9.313333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88651a70-fc7b-4d6a-8c66-b36062c0d47a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88651a70-fc7b-4d6a-8c66-b36062c0d47a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88651a70-fc7b-4d6a-8c66-b36062c0d47a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0556154-5904-41c3-95e8-ac9593a49a43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0556154-5904-41c3-95e8-ac9593a49a43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0556154-5904-41c3-95e8-ac9593a49a43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11548,\n  \"fields\": [\n    {\n      \"column\": \"mssv\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11548,\n        \"samples\": [\n          \"C3014044XPvAibaEXe/kLXGQZojyiUag2miwNoRN\",\n          \"0DE370C5XPvAibaEXe93zTruI/+aDEPB+SkJADIe\",\n          \"F406C807XPvAibaEXe8bVXYGG8kdZcFZHur1VEtL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"namsinh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 22,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          14,\n          9,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gioitinh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.787273333484745,\n        \"min\": 47.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          75.19813454155285,\n          78.33960814444872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diem_tt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.579299237653719,\n        \"min\": 17.0,\n        \"max\": 35.5,\n        \"num_unique_values\": 412,\n        \"samples\": [\n          27.55227408054158,\n          25.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtb_toankhoa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7008599564932692,\n        \"min\": 0.0,\n        \"max\": 9.66,\n        \"num_unique_values\": 867,\n        \"samples\": [\n          4.85,\n          1.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtb_tichluy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7008599564932692,\n        \"min\": 0.0,\n        \"max\": 9.66,\n        \"num_unique_values\": 867,\n        \"samples\": [\n          4.85,\n          1.43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sotc_tichluy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 0,\n        \"max\": 177,\n        \"num_unique_values\": 173,\n        \"samples\": [\n          37,\n          145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6567911822957082,\n        \"min\": 0.0,\n        \"max\": 9.79,\n        \"num_unique_values\": 867,\n        \"samples\": [\n          6.35,\n          5.47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.054291493505188,\n        \"min\": 0.0,\n        \"max\": 9.71,\n        \"num_unique_values\": 952,\n        \"samples\": [\n          7.65,\n          4.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8917282409656873,\n        \"min\": 0.0,\n        \"max\": 9.73,\n        \"num_unique_values\": 1047,\n        \"samples\": [\n          4.38,\n          4.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0631980770027107,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1915,\n        \"samples\": [\n          0.675,\n          7.18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.994114607661309,\n        \"min\": 0.0,\n        \"max\": 9.95,\n        \"num_unique_values\": 2122,\n        \"samples\": [\n          8.686666666666667,\n          4.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.101710088630327,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 3076,\n        \"samples\": [\n          7.37,\n          6.396666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0212517386647204,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 3241,\n        \"samples\": [\n          4.185,\n          7.702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1740148020462833,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 4421,\n        \"samples\": [\n          8.713999999999999,\n          1.415\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/my_data_DS317/train_update.xlsx')\n",
        "df.drop(['gioitinh'], axis=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "fgc9jbmrBP5F",
        "outputId": "cf6e580d-4c38-49df-c3a7-8607a935a611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       mssv  namsinh  gioitinh         drl  \\\n",
              "0  14EEA146XPvAibaEXe/2sgPA+OKAks3AV3zsZSFH       22         0   82.105913   \n",
              "1  4A2628C7XPvAibaEXe9urngX21O5XaWExeziRFls       22         1   82.105913   \n",
              "2  44634117XPvAibaEXe+WdrMfsV/1fSPAGTu3hQ5U       22         0   82.105913   \n",
              "3  8A7BA5ACXPvAibaEXe8FNnc+c+WuJHdW9KyIp7Nl       19         0  100.000000   \n",
              "4  A3A77666XPvAibaEXe/4WyTnp6RTwi1hkjCNtuCX       20         0   75.655535   \n",
              "\n",
              "     diem_tt  dtb_toankhoa  dtb_tichluy  sotc_tichluy  diemtbhk_1  diemtbhk_2  \\\n",
              "0  26.762789          8.77         8.77           123        8.61        8.79   \n",
              "1  30.000000          8.42         8.42           130        9.11        8.64   \n",
              "2  22.350000          7.73         7.73           137        7.83        7.46   \n",
              "3  30.000000          6.52         6.52            83        7.63        7.21   \n",
              "4  24.250000          6.50         6.50           148        6.02        6.75   \n",
              "\n",
              "   diemtbhk_3  diemtbhk_4  diemtbhk_5  diemtbhk_6  diemtbhk_7  diemtbhk_8  \n",
              "0        9.01        9.04        8.63       8.620       8.530    8.747143  \n",
              "1        7.78        8.60        8.45       8.300       9.300    8.597143  \n",
              "2        7.53        7.67        7.89       8.030       7.750    7.737143  \n",
              "3        7.70        7.05        1.67       6.252       6.252    6.252000  \n",
              "4        6.79        6.26        5.21       5.580       6.450    6.690000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-597ea1b8-17da-4a5b-bd34-38c8eaa68cd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mssv</th>\n",
              "      <th>namsinh</th>\n",
              "      <th>gioitinh</th>\n",
              "      <th>drl</th>\n",
              "      <th>diem_tt</th>\n",
              "      <th>dtb_toankhoa</th>\n",
              "      <th>dtb_tichluy</th>\n",
              "      <th>sotc_tichluy</th>\n",
              "      <th>diemtbhk_1</th>\n",
              "      <th>diemtbhk_2</th>\n",
              "      <th>diemtbhk_3</th>\n",
              "      <th>diemtbhk_4</th>\n",
              "      <th>diemtbhk_5</th>\n",
              "      <th>diemtbhk_6</th>\n",
              "      <th>diemtbhk_7</th>\n",
              "      <th>diemtbhk_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14EEA146XPvAibaEXe/2sgPA+OKAks3AV3zsZSFH</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>82.105913</td>\n",
              "      <td>26.762789</td>\n",
              "      <td>8.77</td>\n",
              "      <td>8.77</td>\n",
              "      <td>123</td>\n",
              "      <td>8.61</td>\n",
              "      <td>8.79</td>\n",
              "      <td>9.01</td>\n",
              "      <td>9.04</td>\n",
              "      <td>8.63</td>\n",
              "      <td>8.620</td>\n",
              "      <td>8.530</td>\n",
              "      <td>8.747143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4A2628C7XPvAibaEXe9urngX21O5XaWExeziRFls</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>82.105913</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>8.42</td>\n",
              "      <td>8.42</td>\n",
              "      <td>130</td>\n",
              "      <td>9.11</td>\n",
              "      <td>8.64</td>\n",
              "      <td>7.78</td>\n",
              "      <td>8.60</td>\n",
              "      <td>8.45</td>\n",
              "      <td>8.300</td>\n",
              "      <td>9.300</td>\n",
              "      <td>8.597143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44634117XPvAibaEXe+WdrMfsV/1fSPAGTu3hQ5U</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>82.105913</td>\n",
              "      <td>22.350000</td>\n",
              "      <td>7.73</td>\n",
              "      <td>7.73</td>\n",
              "      <td>137</td>\n",
              "      <td>7.83</td>\n",
              "      <td>7.46</td>\n",
              "      <td>7.53</td>\n",
              "      <td>7.67</td>\n",
              "      <td>7.89</td>\n",
              "      <td>8.030</td>\n",
              "      <td>7.750</td>\n",
              "      <td>7.737143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8A7BA5ACXPvAibaEXe8FNnc+c+WuJHdW9KyIp7Nl</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>6.52</td>\n",
              "      <td>6.52</td>\n",
              "      <td>83</td>\n",
              "      <td>7.63</td>\n",
              "      <td>7.21</td>\n",
              "      <td>7.70</td>\n",
              "      <td>7.05</td>\n",
              "      <td>1.67</td>\n",
              "      <td>6.252</td>\n",
              "      <td>6.252</td>\n",
              "      <td>6.252000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3A77666XPvAibaEXe/4WyTnp6RTwi1hkjCNtuCX</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>75.655535</td>\n",
              "      <td>24.250000</td>\n",
              "      <td>6.50</td>\n",
              "      <td>6.50</td>\n",
              "      <td>148</td>\n",
              "      <td>6.02</td>\n",
              "      <td>6.75</td>\n",
              "      <td>6.79</td>\n",
              "      <td>6.26</td>\n",
              "      <td>5.21</td>\n",
              "      <td>5.580</td>\n",
              "      <td>6.450</td>\n",
              "      <td>6.690000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-597ea1b8-17da-4a5b-bd34-38c8eaa68cd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-597ea1b8-17da-4a5b-bd34-38c8eaa68cd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-597ea1b8-17da-4a5b-bd34-38c8eaa68cd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5922668d-2d4f-422d-8edd-11bdd53fbaa8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5922668d-2d4f-422d-8edd-11bdd53fbaa8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5922668d-2d4f-422d-8edd-11bdd53fbaa8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 2039,\n  \"fields\": [\n    {\n      \"column\": \"mssv\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2039,\n        \"samples\": [\n          \"9FA94C10XPvAibaEXe/A4DdQ4aR8pOdhCEfFGfHY\",\n          \"B53CD112XPvAibaEXe9kybgr+3BpgIjsk9S/TlBY\",\n          \"66C3AEB9XPvAibaEXe/fvouekn0IRoDsSabzcJMB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"namsinh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 11,\n        \"max\": 22,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          16,\n          22,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gioitinh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.941331356862342,\n        \"min\": 44.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          78.0,\n          96.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diem_tt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.564169358149519,\n        \"min\": 17.25,\n        \"max\": 35.0,\n        \"num_unique_values\": 209,\n        \"samples\": [\n          25.75,\n          24.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtb_toankhoa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7536103469882496,\n        \"min\": 0.0,\n        \"max\": 9.5,\n        \"num_unique_values\": 565,\n        \"samples\": [\n          2.12,\n          6.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dtb_tichluy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7536103469882496,\n        \"min\": 0.0,\n        \"max\": 9.5,\n        \"num_unique_values\": 565,\n        \"samples\": [\n          2.12,\n          6.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sotc_tichluy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 0,\n        \"max\": 193,\n        \"num_unique_values\": 164,\n        \"samples\": [\n          44,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6906553438104874,\n        \"min\": 0.0,\n        \"max\": 9.72,\n        \"num_unique_values\": 582,\n        \"samples\": [\n          4.53,\n          8.99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.114252758262715,\n        \"min\": 0.0,\n        \"max\": 9.73,\n        \"num_unique_values\": 646,\n        \"samples\": [\n          5.38,\n          2.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9930844611391374,\n        \"min\": 0.0,\n        \"max\": 9.7,\n        \"num_unique_values\": 603,\n        \"samples\": [\n          8.67,\n          6.01\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.058951473847494,\n        \"min\": 0.0,\n        \"max\": 9.82,\n        \"num_unique_values\": 804,\n        \"samples\": [\n          4.42,\n          8.523333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.027770553065024,\n        \"min\": 0.0,\n        \"max\": 9.78,\n        \"num_unique_values\": 834,\n        \"samples\": [\n          7.906666666666666,\n          7.546666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1429419412979542,\n        \"min\": 0.0,\n        \"max\": 9.83,\n        \"num_unique_values\": 984,\n        \"samples\": [\n          6.19,\n          9.03\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0582117686271544,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1035,\n        \"samples\": [\n          8.336666666666666,\n          7.124000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diemtbhk_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2490045917384958,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 1236,\n        \"samples\": [\n          9.09,\n          2.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_test = pd.read_excel('/content/drive/MyDrive/my_data_DS317/test_update.xlsx')\n",
        "df_test.drop(['gioitinh'], axis=1)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qSXVpRGRBm4F"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100 if np.all(y_true != 0) else np.nan\n",
        "    mpe = np.mean((y_true - y_pred) / y_true) * 100 if np.all(y_true != 0) else np.nan\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return {\"R2 Score\": r2, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape, \"MPE\": mpe}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeIr5_YyBnsp",
        "outputId": "334b61bb-5e84-4def-adb9-840027f3ce7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ],
      "source": [
        "# model=  TabNetRegressor(\n",
        "#         n_d=32, n_a=32, n_steps=3,\n",
        "#         #random_state=42\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-MLI_bhoB-8Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Khởi tạo danh sách tham số khả quan\n",
        "param_grid = {\n",
        "    'n_d': [8, 32, 48],\n",
        "    'n_a': [8, 32, 48],\n",
        "    'n_steps': [5, 7],\n",
        "}\n",
        "\n",
        "grid = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_model = None\n",
        "best_score = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tpUxYzuDB_i-",
        "outputId": "1233f873-87cb-42e1-9aae-6dd7d42eeee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 7.12708 |  0:00:01s\n",
            "epoch 1  | loss: 1.53646 |  0:00:02s\n",
            "epoch 2  | loss: 1.07986 |  0:00:03s\n",
            "epoch 3  | loss: 1.03461 |  0:00:04s\n",
            "epoch 4  | loss: 0.95405 |  0:00:05s\n",
            "epoch 5  | loss: 0.95865 |  0:00:07s\n",
            "epoch 6  | loss: 1.01314 |  0:00:09s\n",
            "epoch 7  | loss: 0.9478  |  0:00:10s\n",
            "epoch 8  | loss: 0.88482 |  0:00:12s\n",
            "epoch 9  | loss: 0.84979 |  0:00:13s\n",
            "epoch 10 | loss: 0.9036  |  0:00:14s\n",
            "epoch 11 | loss: 0.81996 |  0:00:15s\n",
            "epoch 12 | loss: 0.85149 |  0:00:16s\n",
            "epoch 13 | loss: 0.82404 |  0:00:17s\n",
            "epoch 14 | loss: 0.80869 |  0:00:19s\n",
            "epoch 15 | loss: 0.81147 |  0:00:20s\n",
            "epoch 16 | loss: 0.8431  |  0:00:21s\n",
            "epoch 17 | loss: 0.79669 |  0:00:23s\n",
            "epoch 18 | loss: 0.8514  |  0:00:25s\n",
            "epoch 19 | loss: 0.84445 |  0:00:26s\n",
            "epoch 20 | loss: 0.81454 |  0:00:27s\n",
            "epoch 21 | loss: 0.83821 |  0:00:28s\n",
            "epoch 22 | loss: 0.85655 |  0:00:29s\n",
            "epoch 23 | loss: 0.87266 |  0:00:30s\n",
            "epoch 24 | loss: 0.87384 |  0:00:31s\n",
            "epoch 25 | loss: 0.82363 |  0:00:32s\n",
            "epoch 26 | loss: 0.87253 |  0:00:33s\n",
            "epoch 27 | loss: 0.87762 |  0:00:35s\n",
            "epoch 28 | loss: 0.81932 |  0:00:36s\n",
            "epoch 29 | loss: 0.83248 |  0:00:38s\n",
            "epoch 30 | loss: 0.83737 |  0:00:39s\n",
            "epoch 31 | loss: 0.78978 |  0:00:40s\n",
            "epoch 32 | loss: 0.78133 |  0:00:42s\n",
            "epoch 33 | loss: 0.78109 |  0:00:43s\n",
            "epoch 34 | loss: 0.79261 |  0:00:44s\n",
            "epoch 35 | loss: 0.81637 |  0:00:45s\n",
            "epoch 36 | loss: 0.79214 |  0:00:46s\n",
            "epoch 37 | loss: 0.75081 |  0:00:47s\n",
            "epoch 38 | loss: 0.80198 |  0:00:48s\n",
            "epoch 39 | loss: 0.79193 |  0:00:50s\n",
            "epoch 40 | loss: 0.7843  |  0:00:51s\n",
            "epoch 41 | loss: 0.76819 |  0:00:53s\n",
            "epoch 42 | loss: 0.76264 |  0:00:54s\n",
            "epoch 43 | loss: 0.77267 |  0:00:55s\n",
            "epoch 44 | loss: 0.74667 |  0:00:56s\n",
            "epoch 45 | loss: 0.74802 |  0:00:57s\n",
            "epoch 46 | loss: 0.7644  |  0:00:58s\n",
            "epoch 47 | loss: 0.73619 |  0:01:00s\n",
            "epoch 48 | loss: 0.8609  |  0:01:01s\n",
            "epoch 49 | loss: 0.79377 |  0:01:02s\n",
            "epoch 50 | loss: 0.7327  |  0:01:03s\n",
            "epoch 51 | loss: 0.73356 |  0:01:05s\n",
            "epoch 52 | loss: 0.75672 |  0:01:06s\n",
            "epoch 53 | loss: 0.74808 |  0:01:08s\n",
            "epoch 54 | loss: 0.76088 |  0:01:09s\n",
            "epoch 55 | loss: 0.73232 |  0:01:11s\n",
            "epoch 56 | loss: 0.73767 |  0:01:12s\n",
            "epoch 57 | loss: 0.72476 |  0:01:13s\n",
            "epoch 58 | loss: 0.73834 |  0:01:14s\n",
            "epoch 59 | loss: 0.72717 |  0:01:15s\n",
            "epoch 60 | loss: 0.72604 |  0:01:16s\n",
            "epoch 61 | loss: 0.73021 |  0:01:18s\n",
            "epoch 62 | loss: 0.72675 |  0:01:19s\n",
            "epoch 63 | loss: 0.72637 |  0:01:21s\n",
            "epoch 64 | loss: 0.72075 |  0:01:22s\n",
            "epoch 65 | loss: 0.74573 |  0:01:23s\n",
            "epoch 66 | loss: 0.79451 |  0:01:24s\n",
            "epoch 67 | loss: 0.7182  |  0:01:25s\n",
            "epoch 68 | loss: 0.72142 |  0:01:27s\n",
            "epoch 69 | loss: 0.76522 |  0:01:28s\n",
            "epoch 70 | loss: 0.72294 |  0:01:29s\n",
            "epoch 71 | loss: 0.73375 |  0:01:30s\n",
            "epoch 72 | loss: 0.74424 |  0:01:31s\n",
            "epoch 73 | loss: 0.74072 |  0:01:32s\n",
            "epoch 74 | loss: 0.72133 |  0:01:34s\n",
            "epoch 75 | loss: 0.73085 |  0:01:35s\n",
            "epoch 76 | loss: 0.72479 |  0:01:37s\n",
            "epoch 77 | loss: 0.75113 |  0:01:38s\n",
            "epoch 78 | loss: 0.71197 |  0:01:39s\n",
            "epoch 79 | loss: 0.71078 |  0:01:40s\n",
            "epoch 80 | loss: 0.70466 |  0:01:41s\n",
            "epoch 81 | loss: 0.71396 |  0:01:42s\n",
            "epoch 82 | loss: 0.70133 |  0:01:43s\n",
            "epoch 83 | loss: 0.71433 |  0:01:44s\n",
            "epoch 84 | loss: 0.69971 |  0:01:45s\n",
            "epoch 85 | loss: 0.72566 |  0:01:47s\n",
            "epoch 86 | loss: 0.73967 |  0:01:49s\n",
            "epoch 87 | loss: 0.73791 |  0:01:50s\n",
            "epoch 88 | loss: 0.72851 |  0:01:51s\n",
            "epoch 89 | loss: 0.75001 |  0:01:52s\n",
            "epoch 90 | loss: 0.72785 |  0:01:53s\n",
            "epoch 91 | loss: 0.74851 |  0:01:54s\n",
            "epoch 92 | loss: 0.73842 |  0:01:55s\n",
            "epoch 93 | loss: 0.73454 |  0:01:57s\n",
            "epoch 94 | loss: 0.73314 |  0:01:58s\n",
            "epoch 95 | loss: 0.72863 |  0:01:59s\n",
            "epoch 96 | loss: 0.69213 |  0:02:00s\n",
            "epoch 97 | loss: 0.72204 |  0:02:02s\n",
            "epoch 98 | loss: 0.70627 |  0:02:03s\n",
            "epoch 99 | loss: 0.70671 |  0:02:04s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 10.29999|  0:00:01s\n",
            "epoch 1  | loss: 1.16052 |  0:00:02s\n",
            "epoch 2  | loss: 0.94705 |  0:00:03s\n",
            "epoch 3  | loss: 0.86259 |  0:00:04s\n",
            "epoch 4  | loss: 0.81242 |  0:00:05s\n",
            "epoch 5  | loss: 0.70846 |  0:00:06s\n",
            "epoch 6  | loss: 0.75525 |  0:00:07s\n",
            "epoch 7  | loss: 0.78905 |  0:00:09s\n",
            "epoch 8  | loss: 0.74453 |  0:00:10s\n",
            "epoch 9  | loss: 0.7123  |  0:00:12s\n",
            "epoch 10 | loss: 0.66733 |  0:00:13s\n",
            "epoch 11 | loss: 0.71848 |  0:00:14s\n",
            "epoch 12 | loss: 0.66984 |  0:00:15s\n",
            "epoch 13 | loss: 0.66856 |  0:00:16s\n",
            "epoch 14 | loss: 0.64259 |  0:00:18s\n",
            "epoch 15 | loss: 0.6697  |  0:00:19s\n",
            "epoch 16 | loss: 0.63909 |  0:00:20s\n",
            "epoch 17 | loss: 0.61702 |  0:00:21s\n",
            "epoch 18 | loss: 0.61807 |  0:00:22s\n",
            "epoch 19 | loss: 0.63118 |  0:00:24s\n",
            "epoch 20 | loss: 0.60677 |  0:00:26s\n",
            "epoch 21 | loss: 0.6909  |  0:00:27s\n",
            "epoch 22 | loss: 0.71498 |  0:00:28s\n",
            "epoch 23 | loss: 0.62698 |  0:00:29s\n",
            "epoch 24 | loss: 0.6462  |  0:00:30s\n",
            "epoch 25 | loss: 0.601   |  0:00:31s\n",
            "epoch 26 | loss: 0.59055 |  0:00:32s\n",
            "epoch 27 | loss: 0.56119 |  0:00:33s\n",
            "epoch 28 | loss: 0.58729 |  0:00:35s\n",
            "epoch 29 | loss: 0.5993  |  0:00:36s\n",
            "epoch 30 | loss: 0.58248 |  0:00:37s\n",
            "epoch 31 | loss: 0.55938 |  0:00:39s\n",
            "epoch 32 | loss: 0.57415 |  0:00:40s\n",
            "epoch 33 | loss: 0.57354 |  0:00:42s\n",
            "epoch 34 | loss: 0.54585 |  0:00:43s\n",
            "epoch 35 | loss: 0.58374 |  0:00:44s\n",
            "epoch 36 | loss: 0.56117 |  0:00:45s\n",
            "epoch 37 | loss: 0.53781 |  0:00:46s\n",
            "epoch 38 | loss: 0.56976 |  0:00:47s\n",
            "epoch 39 | loss: 0.55719 |  0:00:48s\n",
            "epoch 40 | loss: 0.53085 |  0:00:49s\n",
            "epoch 41 | loss: 0.55426 |  0:00:50s\n",
            "epoch 42 | loss: 0.51745 |  0:00:52s\n",
            "epoch 43 | loss: 0.52484 |  0:00:54s\n",
            "epoch 44 | loss: 0.57149 |  0:00:55s\n",
            "epoch 45 | loss: 0.55775 |  0:00:56s\n",
            "epoch 46 | loss: 0.59766 |  0:00:57s\n",
            "epoch 47 | loss: 0.57764 |  0:00:58s\n",
            "epoch 48 | loss: 0.54072 |  0:00:59s\n",
            "epoch 49 | loss: 0.52077 |  0:01:01s\n",
            "epoch 50 | loss: 0.56003 |  0:01:02s\n",
            "epoch 51 | loss: 0.56062 |  0:01:03s\n",
            "epoch 52 | loss: 0.51535 |  0:01:04s\n",
            "epoch 53 | loss: 0.52567 |  0:01:05s\n",
            "epoch 54 | loss: 0.53852 |  0:01:07s\n",
            "epoch 55 | loss: 0.55437 |  0:01:08s\n",
            "epoch 56 | loss: 0.55518 |  0:01:10s\n",
            "epoch 57 | loss: 0.5353  |  0:01:11s\n",
            "epoch 58 | loss: 0.53503 |  0:01:12s\n",
            "epoch 59 | loss: 0.53612 |  0:01:13s\n",
            "epoch 60 | loss: 0.56242 |  0:01:14s\n",
            "epoch 61 | loss: 0.53576 |  0:01:15s\n",
            "epoch 62 | loss: 0.5362  |  0:01:16s\n",
            "epoch 63 | loss: 0.53764 |  0:01:17s\n",
            "epoch 64 | loss: 0.52586 |  0:01:19s\n",
            "epoch 65 | loss: 0.5479  |  0:01:20s\n",
            "epoch 66 | loss: 0.53146 |  0:01:22s\n",
            "epoch 67 | loss: 0.53581 |  0:01:23s\n",
            "epoch 68 | loss: 0.54925 |  0:01:24s\n",
            "epoch 69 | loss: 0.50868 |  0:01:26s\n",
            "epoch 70 | loss: 0.4988  |  0:01:27s\n",
            "epoch 71 | loss: 0.53881 |  0:01:28s\n",
            "epoch 72 | loss: 0.54429 |  0:01:29s\n",
            "epoch 73 | loss: 0.50914 |  0:01:30s\n",
            "epoch 74 | loss: 0.51506 |  0:01:31s\n",
            "epoch 75 | loss: 0.50567 |  0:01:32s\n",
            "epoch 76 | loss: 0.53528 |  0:01:33s\n",
            "epoch 77 | loss: 0.51144 |  0:01:35s\n",
            "epoch 78 | loss: 0.51786 |  0:01:36s\n",
            "epoch 79 | loss: 0.54436 |  0:01:38s\n",
            "epoch 80 | loss: 0.55524 |  0:01:39s\n",
            "epoch 81 | loss: 0.51739 |  0:01:40s\n",
            "epoch 82 | loss: 0.53484 |  0:01:41s\n",
            "epoch 83 | loss: 0.53311 |  0:01:42s\n",
            "epoch 84 | loss: 0.53856 |  0:01:43s\n",
            "epoch 85 | loss: 0.53086 |  0:01:44s\n",
            "epoch 86 | loss: 0.53241 |  0:01:46s\n",
            "epoch 87 | loss: 0.54946 |  0:01:47s\n",
            "epoch 88 | loss: 0.53293 |  0:01:48s\n",
            "epoch 89 | loss: 0.52683 |  0:01:49s\n",
            "epoch 90 | loss: 0.50923 |  0:01:51s\n",
            "epoch 91 | loss: 0.53333 |  0:01:52s\n",
            "epoch 92 | loss: 0.52699 |  0:01:53s\n",
            "epoch 93 | loss: 0.50829 |  0:01:54s\n",
            "epoch 94 | loss: 0.49571 |  0:01:55s\n",
            "epoch 95 | loss: 0.52627 |  0:01:57s\n",
            "epoch 96 | loss: 0.53283 |  0:01:58s\n",
            "epoch 97 | loss: 0.52338 |  0:01:59s\n",
            "epoch 98 | loss: 0.51733 |  0:02:00s\n",
            "epoch 99 | loss: 0.54642 |  0:02:01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 13.15992|  0:00:01s\n",
            "epoch 1  | loss: 1.76393 |  0:00:03s\n",
            "epoch 2  | loss: 1.70832 |  0:00:04s\n",
            "epoch 3  | loss: 1.51264 |  0:00:05s\n",
            "epoch 4  | loss: 1.34575 |  0:00:06s\n",
            "epoch 5  | loss: 1.39864 |  0:00:07s\n",
            "epoch 6  | loss: 1.35941 |  0:00:08s\n",
            "epoch 7  | loss: 1.27282 |  0:00:09s\n",
            "epoch 8  | loss: 1.25359 |  0:00:11s\n",
            "epoch 9  | loss: 1.28552 |  0:00:12s\n",
            "epoch 10 | loss: 1.23889 |  0:00:13s\n",
            "epoch 11 | loss: 1.19008 |  0:00:14s\n",
            "epoch 12 | loss: 1.26722 |  0:00:16s\n",
            "epoch 13 | loss: 1.22704 |  0:00:17s\n",
            "epoch 14 | loss: 1.18885 |  0:00:18s\n",
            "epoch 15 | loss: 1.21701 |  0:00:20s\n",
            "epoch 16 | loss: 1.14569 |  0:00:21s\n",
            "epoch 17 | loss: 1.16752 |  0:00:22s\n",
            "epoch 18 | loss: 1.21564 |  0:00:23s\n",
            "epoch 19 | loss: 1.21824 |  0:00:24s\n",
            "epoch 20 | loss: 1.17092 |  0:00:25s\n",
            "epoch 21 | loss: 1.23795 |  0:00:26s\n",
            "epoch 22 | loss: 1.18593 |  0:00:27s\n",
            "epoch 23 | loss: 1.16826 |  0:00:28s\n",
            "epoch 24 | loss: 1.16451 |  0:00:30s\n",
            "epoch 25 | loss: 1.2011  |  0:00:32s\n",
            "epoch 26 | loss: 1.13824 |  0:00:33s\n",
            "epoch 27 | loss: 1.17191 |  0:00:34s\n",
            "epoch 28 | loss: 1.18146 |  0:00:35s\n",
            "epoch 29 | loss: 1.13358 |  0:00:36s\n",
            "epoch 30 | loss: 1.12655 |  0:00:37s\n",
            "epoch 31 | loss: 1.12093 |  0:00:38s\n",
            "epoch 32 | loss: 1.13414 |  0:00:39s\n",
            "epoch 33 | loss: 1.13795 |  0:00:40s\n",
            "epoch 34 | loss: 1.1244  |  0:00:42s\n",
            "epoch 35 | loss: 1.1394  |  0:00:43s\n",
            "epoch 36 | loss: 1.14452 |  0:00:45s\n",
            "epoch 37 | loss: 1.12734 |  0:00:46s\n",
            "epoch 38 | loss: 1.13259 |  0:00:47s\n",
            "epoch 39 | loss: 1.13529 |  0:00:48s\n",
            "epoch 40 | loss: 1.11957 |  0:00:49s\n",
            "epoch 41 | loss: 1.10527 |  0:00:50s\n",
            "epoch 42 | loss: 1.12619 |  0:00:52s\n",
            "epoch 43 | loss: 1.16098 |  0:00:53s\n",
            "epoch 44 | loss: 1.13819 |  0:00:54s\n",
            "epoch 45 | loss: 1.11754 |  0:00:55s\n",
            "epoch 46 | loss: 1.10305 |  0:00:56s\n",
            "epoch 47 | loss: 1.11544 |  0:00:58s\n",
            "epoch 48 | loss: 1.1137  |  0:00:59s\n",
            "epoch 49 | loss: 1.10028 |  0:01:00s\n",
            "epoch 50 | loss: 1.1245  |  0:01:02s\n",
            "epoch 51 | loss: 1.13296 |  0:01:03s\n",
            "epoch 52 | loss: 1.10759 |  0:01:04s\n",
            "epoch 53 | loss: 1.10596 |  0:01:05s\n",
            "epoch 54 | loss: 1.13566 |  0:01:06s\n",
            "epoch 55 | loss: 1.1061  |  0:01:07s\n",
            "epoch 56 | loss: 1.12561 |  0:01:08s\n",
            "epoch 57 | loss: 1.16436 |  0:01:09s\n",
            "epoch 58 | loss: 1.1333  |  0:01:11s\n",
            "epoch 59 | loss: 1.17897 |  0:01:12s\n",
            "epoch 60 | loss: 1.11883 |  0:01:14s\n",
            "epoch 61 | loss: 1.10321 |  0:01:15s\n",
            "epoch 62 | loss: 1.11443 |  0:01:16s\n",
            "epoch 63 | loss: 1.10834 |  0:01:17s\n",
            "epoch 64 | loss: 1.11652 |  0:01:18s\n",
            "epoch 65 | loss: 1.12724 |  0:01:20s\n",
            "epoch 66 | loss: 1.17584 |  0:01:21s\n",
            "epoch 67 | loss: 1.13276 |  0:01:22s\n",
            "epoch 68 | loss: 1.11883 |  0:01:23s\n",
            "epoch 69 | loss: 1.1037  |  0:01:24s\n",
            "epoch 70 | loss: 1.09691 |  0:01:25s\n",
            "epoch 71 | loss: 1.09114 |  0:01:27s\n",
            "epoch 72 | loss: 1.09195 |  0:01:28s\n",
            "epoch 73 | loss: 1.08842 |  0:01:30s\n",
            "epoch 74 | loss: 1.1222  |  0:01:31s\n",
            "epoch 75 | loss: 1.15893 |  0:01:32s\n",
            "epoch 76 | loss: 1.13083 |  0:01:33s\n",
            "epoch 77 | loss: 1.13892 |  0:01:34s\n",
            "epoch 78 | loss: 1.11841 |  0:01:35s\n",
            "epoch 79 | loss: 1.1727  |  0:01:36s\n",
            "epoch 80 | loss: 1.10967 |  0:01:37s\n",
            "epoch 81 | loss: 1.08952 |  0:01:38s\n",
            "epoch 82 | loss: 1.06612 |  0:01:40s\n",
            "epoch 83 | loss: 1.06963 |  0:01:41s\n",
            "epoch 84 | loss: 1.09909 |  0:01:43s\n",
            "epoch 85 | loss: 1.12568 |  0:01:44s\n",
            "epoch 86 | loss: 1.1503  |  0:01:45s\n",
            "epoch 87 | loss: 1.11119 |  0:01:46s\n",
            "epoch 88 | loss: 1.11065 |  0:01:47s\n",
            "epoch 89 | loss: 1.10014 |  0:01:48s\n",
            "epoch 90 | loss: 1.09598 |  0:01:49s\n",
            "epoch 91 | loss: 1.11358 |  0:01:51s\n",
            "epoch 92 | loss: 1.0937  |  0:01:52s\n",
            "epoch 93 | loss: 1.10017 |  0:01:53s\n",
            "epoch 94 | loss: 1.11815 |  0:01:54s\n",
            "epoch 95 | loss: 1.11595 |  0:01:56s\n",
            "epoch 96 | loss: 1.09544 |  0:01:57s\n",
            "epoch 97 | loss: 1.08738 |  0:01:58s\n",
            "epoch 98 | loss: 1.07709 |  0:01:59s\n",
            "epoch 99 | loss: 1.09923 |  0:02:00s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 19.41037|  0:00:01s\n",
            "epoch 1  | loss: 1.28181 |  0:00:02s\n",
            "epoch 2  | loss: 0.89917 |  0:00:03s\n",
            "epoch 3  | loss: 0.89364 |  0:00:04s\n",
            "epoch 4  | loss: 0.79603 |  0:00:05s\n",
            "epoch 5  | loss: 0.74501 |  0:00:07s\n",
            "epoch 6  | loss: 0.74256 |  0:00:08s\n",
            "epoch 7  | loss: 0.72227 |  0:00:10s\n",
            "epoch 8  | loss: 0.74574 |  0:00:11s\n",
            "epoch 9  | loss: 0.85475 |  0:00:12s\n",
            "epoch 10 | loss: 0.66759 |  0:00:13s\n",
            "epoch 11 | loss: 0.7227  |  0:00:14s\n",
            "epoch 12 | loss: 0.70799 |  0:00:15s\n",
            "epoch 13 | loss: 0.66885 |  0:00:16s\n",
            "epoch 14 | loss: 0.66479 |  0:00:18s\n",
            "epoch 15 | loss: 0.65925 |  0:00:19s\n",
            "epoch 16 | loss: 0.68043 |  0:00:20s\n",
            "epoch 17 | loss: 0.64801 |  0:00:21s\n",
            "epoch 18 | loss: 0.66103 |  0:00:23s\n",
            "epoch 19 | loss: 0.67271 |  0:00:25s\n",
            "epoch 20 | loss: 0.67855 |  0:00:26s\n",
            "epoch 21 | loss: 0.64578 |  0:00:27s\n",
            "epoch 22 | loss: 0.66065 |  0:00:28s\n",
            "epoch 23 | loss: 0.65256 |  0:00:29s\n",
            "epoch 24 | loss: 0.68845 |  0:00:30s\n",
            "epoch 25 | loss: 0.66093 |  0:00:31s\n",
            "epoch 26 | loss: 0.60445 |  0:00:32s\n",
            "epoch 27 | loss: 0.63704 |  0:00:33s\n",
            "epoch 28 | loss: 0.62266 |  0:00:35s\n",
            "epoch 29 | loss: 0.63373 |  0:00:36s\n",
            "epoch 30 | loss: 0.6633  |  0:00:38s\n",
            "epoch 31 | loss: 0.65608 |  0:00:39s\n",
            "epoch 32 | loss: 0.70846 |  0:00:40s\n",
            "epoch 33 | loss: 0.69131 |  0:00:41s\n",
            "epoch 34 | loss: 0.64399 |  0:00:42s\n",
            "epoch 35 | loss: 0.6074  |  0:00:44s\n",
            "epoch 36 | loss: 0.60535 |  0:00:45s\n",
            "epoch 37 | loss: 0.72175 |  0:00:46s\n",
            "epoch 38 | loss: 0.66404 |  0:00:47s\n",
            "epoch 39 | loss: 0.61653 |  0:00:48s\n",
            "epoch 40 | loss: 0.60023 |  0:00:49s\n",
            "epoch 41 | loss: 0.5972  |  0:00:51s\n",
            "epoch 42 | loss: 0.63428 |  0:00:53s\n",
            "epoch 43 | loss: 0.58889 |  0:00:54s\n",
            "epoch 44 | loss: 0.58394 |  0:00:55s\n",
            "epoch 45 | loss: 0.56407 |  0:00:56s\n",
            "epoch 46 | loss: 0.562   |  0:00:57s\n",
            "epoch 47 | loss: 0.54577 |  0:00:58s\n",
            "epoch 48 | loss: 0.56105 |  0:01:00s\n",
            "epoch 49 | loss: 0.56195 |  0:01:01s\n",
            "epoch 50 | loss: 0.55442 |  0:01:02s\n",
            "epoch 51 | loss: 0.56413 |  0:01:03s\n",
            "epoch 52 | loss: 0.54591 |  0:01:05s\n",
            "epoch 53 | loss: 0.55302 |  0:01:07s\n",
            "epoch 54 | loss: 0.56597 |  0:01:08s\n",
            "epoch 55 | loss: 0.56605 |  0:01:09s\n",
            "epoch 56 | loss: 0.54437 |  0:01:10s\n",
            "epoch 57 | loss: 0.58124 |  0:01:11s\n",
            "epoch 58 | loss: 0.56742 |  0:01:12s\n",
            "epoch 59 | loss: 0.59225 |  0:01:13s\n",
            "epoch 60 | loss: 0.57949 |  0:01:14s\n",
            "epoch 61 | loss: 0.68195 |  0:01:16s\n",
            "epoch 62 | loss: 0.63298 |  0:01:17s\n",
            "epoch 63 | loss: 0.65825 |  0:01:18s\n",
            "epoch 64 | loss: 0.62826 |  0:01:20s\n",
            "epoch 65 | loss: 0.60801 |  0:01:21s\n",
            "epoch 66 | loss: 0.58328 |  0:01:22s\n",
            "epoch 67 | loss: 0.64356 |  0:01:23s\n",
            "epoch 68 | loss: 0.63063 |  0:01:25s\n",
            "epoch 69 | loss: 0.5886  |  0:01:26s\n",
            "epoch 70 | loss: 0.5937  |  0:01:27s\n",
            "epoch 71 | loss: 0.56962 |  0:01:28s\n",
            "epoch 72 | loss: 0.54365 |  0:01:29s\n",
            "epoch 73 | loss: 0.55223 |  0:01:30s\n",
            "epoch 74 | loss: 0.60528 |  0:01:31s\n",
            "epoch 75 | loss: 0.5528  |  0:01:33s\n",
            "epoch 76 | loss: 0.54082 |  0:01:35s\n",
            "epoch 77 | loss: 0.54662 |  0:01:36s\n",
            "epoch 78 | loss: 0.56922 |  0:01:37s\n",
            "epoch 79 | loss: 0.55726 |  0:01:38s\n",
            "epoch 80 | loss: 0.55523 |  0:01:39s\n",
            "epoch 81 | loss: 0.56087 |  0:01:40s\n",
            "epoch 82 | loss: 0.5653  |  0:01:41s\n",
            "epoch 83 | loss: 0.53433 |  0:01:42s\n",
            "epoch 84 | loss: 0.55407 |  0:01:43s\n",
            "epoch 85 | loss: 0.54528 |  0:01:44s\n",
            "epoch 86 | loss: 0.56808 |  0:01:46s\n",
            "epoch 87 | loss: 0.59683 |  0:01:47s\n",
            "epoch 88 | loss: 0.56982 |  0:01:49s\n",
            "epoch 89 | loss: 0.56629 |  0:01:50s\n",
            "epoch 90 | loss: 0.56341 |  0:01:51s\n",
            "epoch 91 | loss: 0.55251 |  0:01:53s\n",
            "epoch 92 | loss: 0.55205 |  0:01:54s\n",
            "epoch 93 | loss: 0.53713 |  0:01:55s\n",
            "epoch 94 | loss: 0.5299  |  0:01:56s\n",
            "epoch 95 | loss: 0.54889 |  0:01:57s\n",
            "epoch 96 | loss: 0.52077 |  0:01:58s\n",
            "epoch 97 | loss: 0.54589 |  0:01:59s\n",
            "epoch 98 | loss: 0.53317 |  0:02:01s\n",
            "epoch 99 | loss: 0.54251 |  0:02:03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14.82016|  0:00:01s\n",
            "epoch 1  | loss: 1.77423 |  0:00:02s\n",
            "epoch 2  | loss: 1.50308 |  0:00:03s\n",
            "epoch 3  | loss: 1.44913 |  0:00:04s\n",
            "epoch 4  | loss: 1.33107 |  0:00:05s\n",
            "epoch 5  | loss: 1.20812 |  0:00:06s\n",
            "epoch 6  | loss: 1.22653 |  0:00:07s\n",
            "epoch 7  | loss: 1.19335 |  0:00:08s\n",
            "epoch 8  | loss: 1.18176 |  0:00:10s\n",
            "epoch 9  | loss: 1.24972 |  0:00:11s\n",
            "epoch 10 | loss: 1.15681 |  0:00:13s\n",
            "epoch 11 | loss: 1.09013 |  0:00:14s\n",
            "epoch 12 | loss: 1.12963 |  0:00:15s\n",
            "epoch 13 | loss: 1.0679  |  0:00:16s\n",
            "epoch 14 | loss: 1.11488 |  0:00:17s\n",
            "epoch 15 | loss: 1.09203 |  0:00:19s\n",
            "epoch 16 | loss: 1.03305 |  0:00:20s\n",
            "epoch 17 | loss: 1.03907 |  0:00:21s\n",
            "epoch 18 | loss: 1.01908 |  0:00:22s\n",
            "epoch 19 | loss: 1.02176 |  0:00:23s\n",
            "epoch 20 | loss: 1.02327 |  0:00:25s\n",
            "epoch 21 | loss: 1.03688 |  0:00:26s\n",
            "epoch 22 | loss: 1.03046 |  0:00:28s\n",
            "epoch 23 | loss: 0.96615 |  0:00:29s\n",
            "epoch 24 | loss: 1.00131 |  0:00:30s\n",
            "epoch 25 | loss: 1.07733 |  0:00:31s\n",
            "epoch 26 | loss: 1.0578  |  0:00:32s\n",
            "epoch 27 | loss: 1.05759 |  0:00:33s\n",
            "epoch 28 | loss: 1.02595 |  0:00:34s\n",
            "epoch 29 | loss: 1.04139 |  0:00:36s\n",
            "epoch 30 | loss: 1.02714 |  0:00:37s\n",
            "epoch 31 | loss: 1.02704 |  0:00:38s\n",
            "epoch 32 | loss: 0.98446 |  0:00:40s\n",
            "epoch 33 | loss: 1.043   |  0:00:42s\n",
            "epoch 34 | loss: 1.00382 |  0:00:43s\n",
            "epoch 35 | loss: 0.98687 |  0:00:44s\n",
            "epoch 36 | loss: 0.98476 |  0:00:45s\n",
            "epoch 37 | loss: 1.00359 |  0:00:46s\n",
            "epoch 38 | loss: 0.95108 |  0:00:47s\n",
            "epoch 39 | loss: 1.01442 |  0:00:48s\n",
            "epoch 40 | loss: 1.0127  |  0:00:49s\n",
            "epoch 41 | loss: 0.9906  |  0:00:50s\n",
            "epoch 42 | loss: 1.03088 |  0:00:51s\n",
            "epoch 43 | loss: 1.02089 |  0:00:53s\n",
            "epoch 44 | loss: 1.00694 |  0:00:55s\n",
            "epoch 45 | loss: 1.03348 |  0:00:56s\n",
            "epoch 46 | loss: 1.00979 |  0:00:57s\n",
            "epoch 47 | loss: 1.03241 |  0:00:58s\n",
            "epoch 48 | loss: 0.99292 |  0:01:00s\n",
            "epoch 49 | loss: 0.97888 |  0:01:01s\n",
            "epoch 50 | loss: 0.99719 |  0:01:02s\n",
            "epoch 51 | loss: 0.98139 |  0:01:03s\n",
            "epoch 52 | loss: 0.97704 |  0:01:04s\n",
            "epoch 53 | loss: 1.05485 |  0:01:05s\n",
            "epoch 54 | loss: 0.9888  |  0:01:06s\n",
            "epoch 55 | loss: 0.97397 |  0:01:08s\n",
            "epoch 56 | loss: 0.96562 |  0:01:10s\n",
            "epoch 57 | loss: 0.95277 |  0:01:11s\n",
            "epoch 58 | loss: 0.97666 |  0:01:12s\n",
            "epoch 59 | loss: 0.99561 |  0:01:13s\n",
            "epoch 60 | loss: 0.95897 |  0:01:14s\n",
            "epoch 61 | loss: 0.97342 |  0:01:15s\n",
            "epoch 62 | loss: 0.96833 |  0:01:17s\n",
            "epoch 63 | loss: 1.01057 |  0:01:18s\n",
            "epoch 64 | loss: 1.01407 |  0:01:19s\n",
            "epoch 65 | loss: 0.97035 |  0:01:20s\n",
            "epoch 66 | loss: 0.95654 |  0:01:21s\n",
            "epoch 67 | loss: 1.04572 |  0:01:23s\n",
            "epoch 68 | loss: 1.00883 |  0:01:25s\n",
            "epoch 69 | loss: 0.97022 |  0:01:26s\n",
            "epoch 70 | loss: 0.95221 |  0:01:27s\n",
            "epoch 71 | loss: 0.94236 |  0:01:28s\n",
            "epoch 72 | loss: 0.95851 |  0:01:29s\n",
            "epoch 73 | loss: 1.02548 |  0:01:30s\n",
            "epoch 74 | loss: 0.96831 |  0:01:31s\n",
            "epoch 75 | loss: 0.96973 |  0:01:32s\n",
            "epoch 76 | loss: 0.97264 |  0:01:33s\n",
            "epoch 77 | loss: 0.99196 |  0:01:35s\n",
            "epoch 78 | loss: 1.00312 |  0:01:36s\n",
            "epoch 79 | loss: 1.04662 |  0:01:38s\n",
            "epoch 80 | loss: 0.98986 |  0:01:39s\n",
            "epoch 81 | loss: 0.95803 |  0:01:40s\n",
            "epoch 82 | loss: 0.96046 |  0:01:41s\n",
            "epoch 83 | loss: 1.01167 |  0:01:43s\n",
            "epoch 84 | loss: 0.97177 |  0:01:44s\n",
            "epoch 85 | loss: 0.94234 |  0:01:45s\n",
            "epoch 86 | loss: 0.96318 |  0:01:46s\n",
            "epoch 87 | loss: 0.96984 |  0:01:47s\n",
            "epoch 88 | loss: 0.97392 |  0:01:49s\n",
            "epoch 89 | loss: 0.96209 |  0:01:50s\n",
            "epoch 90 | loss: 0.93243 |  0:01:52s\n",
            "epoch 91 | loss: 1.04333 |  0:01:54s\n",
            "epoch 92 | loss: 1.09871 |  0:01:55s\n",
            "epoch 93 | loss: 1.01747 |  0:01:56s\n",
            "epoch 94 | loss: 0.95435 |  0:01:58s\n",
            "epoch 95 | loss: 0.94439 |  0:01:59s\n",
            "epoch 96 | loss: 0.91949 |  0:02:00s\n",
            "epoch 97 | loss: 0.93225 |  0:02:01s\n",
            "epoch 98 | loss: 0.94678 |  0:02:03s\n",
            "epoch 99 | loss: 0.94004 |  0:02:04s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14.51228|  0:00:01s\n",
            "epoch 1  | loss: 1.16524 |  0:00:02s\n",
            "epoch 2  | loss: 0.90155 |  0:00:03s\n",
            "epoch 3  | loss: 0.858   |  0:00:04s\n",
            "epoch 4  | loss: 0.77235 |  0:00:06s\n",
            "epoch 5  | loss: 0.74474 |  0:00:07s\n",
            "epoch 6  | loss: 0.72025 |  0:00:08s\n",
            "epoch 7  | loss: 0.70899 |  0:00:09s\n",
            "epoch 8  | loss: 0.73903 |  0:00:10s\n",
            "epoch 9  | loss: 0.74845 |  0:00:11s\n",
            "epoch 10 | loss: 0.70982 |  0:00:13s\n",
            "epoch 11 | loss: 0.68884 |  0:00:15s\n",
            "epoch 12 | loss: 0.68901 |  0:00:16s\n",
            "epoch 13 | loss: 0.66685 |  0:00:17s\n",
            "epoch 14 | loss: 0.68499 |  0:00:18s\n",
            "epoch 15 | loss: 0.70152 |  0:00:19s\n",
            "epoch 16 | loss: 0.6997  |  0:00:21s\n",
            "epoch 17 | loss: 0.73982 |  0:00:22s\n",
            "epoch 18 | loss: 0.64796 |  0:00:23s\n",
            "epoch 19 | loss: 0.66346 |  0:00:24s\n",
            "epoch 20 | loss: 0.64403 |  0:00:25s\n",
            "epoch 21 | loss: 0.58342 |  0:00:27s\n",
            "epoch 22 | loss: 0.58261 |  0:00:28s\n",
            "epoch 23 | loss: 0.60299 |  0:00:30s\n",
            "epoch 24 | loss: 0.56839 |  0:00:31s\n",
            "epoch 25 | loss: 0.58243 |  0:00:32s\n",
            "epoch 26 | loss: 0.59856 |  0:00:33s\n",
            "epoch 27 | loss: 0.58153 |  0:00:34s\n",
            "epoch 28 | loss: 0.6106  |  0:00:35s\n",
            "epoch 29 | loss: 0.59508 |  0:00:37s\n",
            "epoch 30 | loss: 0.58923 |  0:00:38s\n",
            "epoch 31 | loss: 0.59573 |  0:00:39s\n",
            "epoch 32 | loss: 0.62287 |  0:00:41s\n",
            "epoch 33 | loss: 0.62391 |  0:00:42s\n",
            "epoch 34 | loss: 0.58297 |  0:00:44s\n",
            "epoch 35 | loss: 0.56006 |  0:00:45s\n",
            "epoch 36 | loss: 0.58116 |  0:00:46s\n",
            "epoch 37 | loss: 0.57328 |  0:00:47s\n",
            "epoch 38 | loss: 0.5923  |  0:00:48s\n",
            "epoch 39 | loss: 0.57201 |  0:00:49s\n",
            "epoch 40 | loss: 0.56983 |  0:00:51s\n",
            "epoch 41 | loss: 0.6031  |  0:00:52s\n",
            "epoch 42 | loss: 0.58957 |  0:00:53s\n",
            "epoch 43 | loss: 0.565   |  0:00:54s\n",
            "epoch 44 | loss: 0.57783 |  0:00:56s\n",
            "epoch 45 | loss: 0.62269 |  0:00:57s\n",
            "epoch 46 | loss: 0.57034 |  0:00:58s\n",
            "epoch 47 | loss: 0.56386 |  0:01:00s\n",
            "epoch 48 | loss: 0.55565 |  0:01:01s\n",
            "epoch 49 | loss: 0.56762 |  0:01:02s\n",
            "epoch 50 | loss: 0.54814 |  0:01:03s\n",
            "epoch 51 | loss: 0.56404 |  0:01:04s\n",
            "epoch 52 | loss: 0.57602 |  0:01:05s\n",
            "epoch 53 | loss: 0.58415 |  0:01:06s\n",
            "epoch 54 | loss: 0.55377 |  0:01:08s\n",
            "epoch 55 | loss: 0.52252 |  0:01:10s\n",
            "epoch 56 | loss: 0.52032 |  0:01:11s\n",
            "epoch 57 | loss: 0.53781 |  0:01:12s\n",
            "epoch 58 | loss: 0.5244  |  0:01:13s\n",
            "epoch 59 | loss: 0.53733 |  0:01:14s\n",
            "epoch 60 | loss: 0.57423 |  0:01:16s\n",
            "epoch 61 | loss: 0.60744 |  0:01:17s\n",
            "epoch 62 | loss: 0.57485 |  0:01:18s\n",
            "epoch 63 | loss: 0.54816 |  0:01:19s\n",
            "epoch 64 | loss: 0.5379  |  0:01:20s\n",
            "epoch 65 | loss: 0.54714 |  0:01:21s\n",
            "epoch 66 | loss: 0.53591 |  0:01:23s\n",
            "epoch 67 | loss: 0.5234  |  0:01:25s\n",
            "epoch 68 | loss: 0.53355 |  0:01:26s\n",
            "epoch 69 | loss: 0.54039 |  0:01:27s\n",
            "epoch 70 | loss: 0.5465  |  0:01:28s\n",
            "epoch 71 | loss: 0.57412 |  0:01:29s\n",
            "epoch 72 | loss: 0.53773 |  0:01:31s\n",
            "epoch 73 | loss: 0.53962 |  0:01:32s\n",
            "epoch 74 | loss: 0.56718 |  0:01:33s\n",
            "epoch 75 | loss: 0.55958 |  0:01:34s\n",
            "epoch 76 | loss: 0.53076 |  0:01:36s\n",
            "epoch 77 | loss: 0.53685 |  0:01:37s\n",
            "epoch 78 | loss: 0.531   |  0:01:39s\n",
            "epoch 79 | loss: 0.52115 |  0:01:40s\n",
            "epoch 80 | loss: 0.57443 |  0:01:41s\n",
            "epoch 81 | loss: 0.58535 |  0:01:42s\n",
            "epoch 82 | loss: 0.57908 |  0:01:43s\n",
            "epoch 83 | loss: 0.54773 |  0:01:44s\n",
            "epoch 84 | loss: 0.55264 |  0:01:46s\n",
            "epoch 85 | loss: 0.55944 |  0:01:47s\n",
            "epoch 86 | loss: 0.55212 |  0:01:48s\n",
            "epoch 87 | loss: 0.5495  |  0:01:49s\n",
            "epoch 88 | loss: 0.52067 |  0:01:51s\n",
            "epoch 89 | loss: 0.53343 |  0:01:53s\n",
            "epoch 90 | loss: 0.53017 |  0:01:54s\n",
            "epoch 91 | loss: 0.51682 |  0:01:55s\n",
            "epoch 92 | loss: 0.53243 |  0:01:56s\n",
            "epoch 93 | loss: 0.54541 |  0:01:57s\n",
            "epoch 94 | loss: 0.56068 |  0:01:58s\n",
            "epoch 95 | loss: 0.53869 |  0:01:59s\n",
            "epoch 96 | loss: 0.53121 |  0:02:00s\n",
            "epoch 97 | loss: 0.52982 |  0:02:02s\n",
            "epoch 98 | loss: 0.55661 |  0:02:03s\n",
            "epoch 99 | loss: 0.55153 |  0:02:04s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.46568|  0:00:01s\n",
            "epoch 1  | loss: 2.32526 |  0:00:02s\n",
            "epoch 2  | loss: 1.78191 |  0:00:03s\n",
            "epoch 3  | loss: 1.64184 |  0:00:05s\n",
            "epoch 4  | loss: 1.56876 |  0:00:06s\n",
            "epoch 5  | loss: 1.544   |  0:00:07s\n",
            "epoch 6  | loss: 1.5983  |  0:00:08s\n",
            "epoch 7  | loss: 1.55662 |  0:00:09s\n",
            "epoch 8  | loss: 1.49031 |  0:00:10s\n",
            "epoch 9  | loss: 1.47094 |  0:00:12s\n",
            "epoch 10 | loss: 1.51496 |  0:00:13s\n",
            "epoch 11 | loss: 1.49398 |  0:00:15s\n",
            "epoch 12 | loss: 1.44792 |  0:00:16s\n",
            "epoch 13 | loss: 1.41855 |  0:00:17s\n",
            "epoch 14 | loss: 1.41924 |  0:00:18s\n",
            "epoch 15 | loss: 1.438   |  0:00:20s\n",
            "epoch 16 | loss: 1.41068 |  0:00:21s\n",
            "epoch 17 | loss: 1.49686 |  0:00:22s\n",
            "epoch 18 | loss: 1.37234 |  0:00:23s\n",
            "epoch 19 | loss: 1.37248 |  0:00:24s\n",
            "epoch 20 | loss: 1.40899 |  0:00:26s\n",
            "epoch 21 | loss: 1.40832 |  0:00:27s\n",
            "epoch 22 | loss: 1.35262 |  0:00:29s\n",
            "epoch 23 | loss: 1.37577 |  0:00:30s\n",
            "epoch 24 | loss: 1.37659 |  0:00:31s\n",
            "epoch 25 | loss: 1.31984 |  0:00:32s\n",
            "epoch 26 | loss: 1.38904 |  0:00:33s\n",
            "epoch 27 | loss: 1.33658 |  0:00:35s\n",
            "epoch 28 | loss: 1.32581 |  0:00:36s\n",
            "epoch 29 | loss: 1.33974 |  0:00:37s\n",
            "epoch 30 | loss: 1.31564 |  0:00:38s\n",
            "epoch 31 | loss: 1.28906 |  0:00:39s\n",
            "epoch 32 | loss: 1.27483 |  0:00:41s\n",
            "epoch 33 | loss: 1.31321 |  0:00:43s\n",
            "epoch 34 | loss: 1.31522 |  0:00:44s\n",
            "epoch 35 | loss: 1.30507 |  0:00:45s\n",
            "epoch 36 | loss: 1.30516 |  0:00:46s\n",
            "epoch 37 | loss: 1.29941 |  0:00:47s\n",
            "epoch 38 | loss: 1.33173 |  0:00:48s\n",
            "epoch 39 | loss: 1.25058 |  0:00:49s\n",
            "epoch 40 | loss: 1.27936 |  0:00:50s\n",
            "epoch 41 | loss: 1.30826 |  0:00:52s\n",
            "epoch 42 | loss: 1.27736 |  0:00:53s\n",
            "epoch 43 | loss: 1.27254 |  0:00:55s\n",
            "epoch 44 | loss: 1.25958 |  0:00:56s\n",
            "epoch 45 | loss: 1.27349 |  0:00:57s\n",
            "epoch 46 | loss: 1.28228 |  0:00:59s\n",
            "epoch 47 | loss: 1.26107 |  0:01:00s\n",
            "epoch 48 | loss: 1.2506  |  0:01:01s\n",
            "epoch 49 | loss: 1.26496 |  0:01:02s\n",
            "epoch 50 | loss: 1.27842 |  0:01:03s\n",
            "epoch 51 | loss: 1.2749  |  0:01:04s\n",
            "epoch 52 | loss: 1.23978 |  0:01:05s\n",
            "epoch 53 | loss: 1.23982 |  0:01:07s\n",
            "epoch 54 | loss: 1.24052 |  0:01:08s\n",
            "epoch 55 | loss: 1.2348  |  0:01:10s\n",
            "epoch 56 | loss: 1.23489 |  0:01:11s\n",
            "epoch 57 | loss: 1.2816  |  0:01:12s\n",
            "epoch 58 | loss: 1.23019 |  0:01:13s\n",
            "epoch 59 | loss: 1.21399 |  0:01:14s\n",
            "epoch 60 | loss: 1.20216 |  0:01:16s\n",
            "epoch 61 | loss: 1.22482 |  0:01:17s\n",
            "epoch 62 | loss: 1.21762 |  0:01:18s\n",
            "epoch 63 | loss: 1.22735 |  0:01:19s\n",
            "epoch 64 | loss: 1.19904 |  0:01:20s\n",
            "epoch 65 | loss: 1.19696 |  0:01:22s\n",
            "epoch 66 | loss: 1.19757 |  0:01:24s\n",
            "epoch 67 | loss: 1.2201  |  0:01:25s\n",
            "epoch 68 | loss: 1.23125 |  0:01:26s\n",
            "epoch 69 | loss: 1.2311  |  0:01:27s\n",
            "epoch 70 | loss: 1.20921 |  0:01:28s\n",
            "epoch 71 | loss: 1.20384 |  0:01:29s\n",
            "epoch 72 | loss: 1.21386 |  0:01:30s\n",
            "epoch 73 | loss: 1.19589 |  0:01:32s\n",
            "epoch 74 | loss: 1.21463 |  0:01:33s\n",
            "epoch 75 | loss: 1.17773 |  0:01:34s\n",
            "epoch 76 | loss: 1.19068 |  0:01:35s\n",
            "epoch 77 | loss: 1.16542 |  0:01:37s\n",
            "epoch 78 | loss: 1.21702 |  0:01:39s\n",
            "epoch 79 | loss: 1.36237 |  0:01:40s\n",
            "epoch 80 | loss: 1.14841 |  0:01:41s\n",
            "epoch 81 | loss: 1.15916 |  0:01:42s\n",
            "epoch 82 | loss: 1.14156 |  0:01:43s\n",
            "epoch 83 | loss: 1.2577  |  0:01:44s\n",
            "epoch 84 | loss: 1.25746 |  0:01:45s\n",
            "epoch 85 | loss: 1.23205 |  0:01:47s\n",
            "epoch 86 | loss: 1.21017 |  0:01:48s\n",
            "epoch 87 | loss: 1.24748 |  0:01:49s\n",
            "epoch 88 | loss: 1.18904 |  0:01:51s\n",
            "epoch 89 | loss: 1.17352 |  0:01:52s\n",
            "epoch 90 | loss: 1.16879 |  0:01:54s\n",
            "epoch 91 | loss: 1.17997 |  0:01:55s\n",
            "epoch 92 | loss: 1.18633 |  0:01:56s\n",
            "epoch 93 | loss: 1.18759 |  0:01:57s\n",
            "epoch 94 | loss: 1.20967 |  0:01:58s\n",
            "epoch 95 | loss: 1.14673 |  0:01:59s\n",
            "epoch 96 | loss: 1.1412  |  0:02:00s\n",
            "epoch 97 | loss: 1.12347 |  0:02:02s\n",
            "epoch 98 | loss: 1.14037 |  0:02:03s\n",
            "epoch 99 | loss: 1.18609 |  0:02:05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 6.71628 |  0:00:01s\n",
            "epoch 1  | loss: 1.68756 |  0:00:03s\n",
            "epoch 2  | loss: 1.23651 |  0:00:04s\n",
            "epoch 3  | loss: 0.99052 |  0:00:06s\n",
            "epoch 4  | loss: 1.04319 |  0:00:07s\n",
            "epoch 5  | loss: 1.08262 |  0:00:09s\n",
            "epoch 6  | loss: 1.02622 |  0:00:10s\n",
            "epoch 7  | loss: 0.87523 |  0:00:12s\n",
            "epoch 8  | loss: 0.85509 |  0:00:14s\n",
            "epoch 9  | loss: 0.90973 |  0:00:16s\n",
            "epoch 10 | loss: 1.02308 |  0:00:18s\n",
            "epoch 11 | loss: 0.93281 |  0:00:19s\n",
            "epoch 12 | loss: 0.93427 |  0:00:20s\n",
            "epoch 13 | loss: 0.94027 |  0:00:22s\n",
            "epoch 14 | loss: 0.87012 |  0:00:23s\n",
            "epoch 15 | loss: 0.85818 |  0:00:25s\n",
            "epoch 16 | loss: 0.85475 |  0:00:27s\n",
            "epoch 17 | loss: 0.90292 |  0:00:29s\n",
            "epoch 18 | loss: 0.85673 |  0:00:31s\n",
            "epoch 19 | loss: 0.86717 |  0:00:32s\n",
            "epoch 20 | loss: 0.88805 |  0:00:33s\n",
            "epoch 21 | loss: 0.88808 |  0:00:35s\n",
            "epoch 22 | loss: 0.87247 |  0:00:36s\n",
            "epoch 23 | loss: 1.01504 |  0:00:38s\n",
            "epoch 24 | loss: 0.86113 |  0:00:39s\n",
            "epoch 25 | loss: 0.8328  |  0:00:42s\n",
            "epoch 26 | loss: 0.85056 |  0:00:43s\n",
            "epoch 27 | loss: 0.88154 |  0:00:45s\n",
            "epoch 28 | loss: 0.83523 |  0:00:46s\n",
            "epoch 29 | loss: 0.85122 |  0:00:48s\n",
            "epoch 30 | loss: 0.88119 |  0:00:49s\n",
            "epoch 31 | loss: 0.81562 |  0:00:51s\n",
            "epoch 32 | loss: 0.80821 |  0:00:52s\n",
            "epoch 33 | loss: 0.83552 |  0:00:54s\n",
            "epoch 34 | loss: 0.8017  |  0:00:56s\n",
            "epoch 35 | loss: 0.77519 |  0:00:58s\n",
            "epoch 36 | loss: 0.79609 |  0:00:59s\n",
            "epoch 37 | loss: 0.80952 |  0:01:01s\n",
            "epoch 38 | loss: 0.79639 |  0:01:02s\n",
            "epoch 39 | loss: 0.79593 |  0:01:04s\n",
            "epoch 40 | loss: 0.869   |  0:01:05s\n",
            "epoch 41 | loss: 0.78263 |  0:01:07s\n",
            "epoch 42 | loss: 0.77821 |  0:01:09s\n",
            "epoch 43 | loss: 0.78782 |  0:01:11s\n",
            "epoch 44 | loss: 0.7923  |  0:01:12s\n",
            "epoch 45 | loss: 0.77108 |  0:01:14s\n",
            "epoch 46 | loss: 0.76398 |  0:01:15s\n",
            "epoch 47 | loss: 0.77926 |  0:01:16s\n",
            "epoch 48 | loss: 0.75993 |  0:01:18s\n",
            "epoch 49 | loss: 0.79194 |  0:01:19s\n",
            "epoch 50 | loss: 0.81578 |  0:01:21s\n",
            "epoch 51 | loss: 0.81561 |  0:01:23s\n",
            "epoch 52 | loss: 0.79164 |  0:01:25s\n",
            "epoch 53 | loss: 0.78061 |  0:01:26s\n",
            "epoch 54 | loss: 0.77788 |  0:01:28s\n",
            "epoch 55 | loss: 0.82593 |  0:01:29s\n",
            "epoch 56 | loss: 0.81531 |  0:01:31s\n",
            "epoch 57 | loss: 0.8225  |  0:01:32s\n",
            "epoch 58 | loss: 0.81395 |  0:01:34s\n",
            "epoch 59 | loss: 0.82941 |  0:01:36s\n",
            "epoch 60 | loss: 0.81665 |  0:01:38s\n",
            "epoch 61 | loss: 0.78146 |  0:01:39s\n",
            "epoch 62 | loss: 0.79787 |  0:01:41s\n",
            "epoch 63 | loss: 0.74993 |  0:01:42s\n",
            "epoch 64 | loss: 0.76    |  0:01:44s\n",
            "epoch 65 | loss: 0.77703 |  0:01:45s\n",
            "epoch 66 | loss: 0.76326 |  0:01:47s\n",
            "epoch 67 | loss: 0.74646 |  0:01:48s\n",
            "epoch 68 | loss: 0.75306 |  0:01:50s\n",
            "epoch 69 | loss: 0.73737 |  0:01:52s\n",
            "epoch 70 | loss: 0.7439  |  0:01:54s\n",
            "epoch 71 | loss: 0.76816 |  0:01:55s\n",
            "epoch 72 | loss: 0.81866 |  0:01:57s\n",
            "epoch 73 | loss: 0.7401  |  0:01:58s\n",
            "epoch 74 | loss: 0.78286 |  0:01:59s\n",
            "epoch 75 | loss: 0.79308 |  0:02:01s\n",
            "epoch 76 | loss: 0.76138 |  0:02:03s\n",
            "epoch 77 | loss: 0.76756 |  0:02:05s\n",
            "epoch 78 | loss: 0.74427 |  0:02:07s\n",
            "epoch 79 | loss: 0.73542 |  0:02:08s\n",
            "epoch 80 | loss: 0.78959 |  0:02:10s\n",
            "epoch 81 | loss: 0.75656 |  0:02:11s\n",
            "epoch 82 | loss: 0.75544 |  0:02:12s\n",
            "epoch 83 | loss: 0.75097 |  0:02:14s\n",
            "epoch 84 | loss: 0.73356 |  0:02:15s\n",
            "epoch 85 | loss: 0.74693 |  0:02:17s\n",
            "epoch 86 | loss: 0.75054 |  0:02:20s\n",
            "epoch 87 | loss: 0.74255 |  0:02:21s\n",
            "epoch 88 | loss: 0.73167 |  0:02:23s\n",
            "epoch 89 | loss: 0.73069 |  0:02:24s\n",
            "epoch 90 | loss: 0.74267 |  0:02:25s\n",
            "epoch 91 | loss: 0.74961 |  0:02:27s\n",
            "epoch 92 | loss: 0.76058 |  0:02:28s\n",
            "epoch 93 | loss: 0.77045 |  0:02:30s\n",
            "epoch 94 | loss: 0.75561 |  0:02:32s\n",
            "epoch 95 | loss: 0.77348 |  0:02:34s\n",
            "epoch 96 | loss: 0.75176 |  0:02:36s\n",
            "epoch 97 | loss: 0.73474 |  0:02:37s\n",
            "epoch 98 | loss: 0.72971 |  0:02:39s\n",
            "epoch 99 | loss: 0.74294 |  0:02:40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 22.37627|  0:00:01s\n",
            "epoch 1  | loss: 1.93623 |  0:00:03s\n",
            "epoch 2  | loss: 1.32451 |  0:00:05s\n",
            "epoch 3  | loss: 1.03775 |  0:00:07s\n",
            "epoch 4  | loss: 0.94153 |  0:00:08s\n",
            "epoch 5  | loss: 0.82815 |  0:00:10s\n",
            "epoch 6  | loss: 1.02535 |  0:00:11s\n",
            "epoch 7  | loss: 1.05735 |  0:00:13s\n",
            "epoch 8  | loss: 0.8886  |  0:00:14s\n",
            "epoch 9  | loss: 0.75139 |  0:00:16s\n",
            "epoch 10 | loss: 0.74008 |  0:00:17s\n",
            "epoch 11 | loss: 0.69676 |  0:00:19s\n",
            "epoch 12 | loss: 0.70276 |  0:00:21s\n",
            "epoch 13 | loss: 0.69598 |  0:00:23s\n",
            "epoch 14 | loss: 0.66656 |  0:00:24s\n",
            "epoch 15 | loss: 0.64889 |  0:00:25s\n",
            "epoch 16 | loss: 0.84978 |  0:00:27s\n",
            "epoch 17 | loss: 0.8283  |  0:00:29s\n",
            "epoch 18 | loss: 0.69671 |  0:00:30s\n",
            "epoch 19 | loss: 0.62577 |  0:00:32s\n",
            "epoch 20 | loss: 0.61393 |  0:00:34s\n",
            "epoch 21 | loss: 0.65693 |  0:00:36s\n",
            "epoch 22 | loss: 0.61138 |  0:00:37s\n",
            "epoch 23 | loss: 0.64596 |  0:00:39s\n",
            "epoch 24 | loss: 0.66922 |  0:00:40s\n",
            "epoch 25 | loss: 0.64095 |  0:00:42s\n",
            "epoch 26 | loss: 0.58767 |  0:00:43s\n",
            "epoch 27 | loss: 0.56921 |  0:00:45s\n",
            "epoch 28 | loss: 0.579   |  0:00:47s\n",
            "epoch 29 | loss: 0.56621 |  0:00:49s\n",
            "epoch 30 | loss: 0.56666 |  0:00:50s\n",
            "epoch 31 | loss: 0.55602 |  0:00:52s\n",
            "epoch 32 | loss: 0.6303  |  0:00:53s\n",
            "epoch 33 | loss: 0.64164 |  0:00:55s\n",
            "epoch 34 | loss: 0.63415 |  0:00:56s\n",
            "epoch 35 | loss: 0.58144 |  0:00:57s\n",
            "epoch 36 | loss: 0.60379 |  0:01:00s\n",
            "epoch 37 | loss: 0.59711 |  0:01:02s\n",
            "epoch 38 | loss: 0.56209 |  0:01:03s\n",
            "epoch 39 | loss: 0.55527 |  0:01:05s\n",
            "epoch 40 | loss: 0.57749 |  0:01:06s\n",
            "epoch 41 | loss: 0.56346 |  0:01:08s\n",
            "epoch 42 | loss: 0.55991 |  0:01:09s\n",
            "epoch 43 | loss: 0.52302 |  0:01:11s\n",
            "epoch 44 | loss: 0.56835 |  0:01:12s\n",
            "epoch 45 | loss: 0.52363 |  0:01:14s\n",
            "epoch 46 | loss: 0.53125 |  0:01:16s\n",
            "epoch 47 | loss: 0.55268 |  0:01:18s\n",
            "epoch 48 | loss: 0.51822 |  0:01:19s\n",
            "epoch 49 | loss: 0.53395 |  0:01:21s\n",
            "epoch 50 | loss: 0.53638 |  0:01:22s\n",
            "epoch 51 | loss: 0.52036 |  0:01:24s\n",
            "epoch 52 | loss: 0.57506 |  0:01:25s\n",
            "epoch 53 | loss: 0.53738 |  0:01:27s\n",
            "epoch 54 | loss: 0.53766 |  0:01:29s\n",
            "epoch 55 | loss: 0.53249 |  0:01:31s\n",
            "epoch 56 | loss: 0.53907 |  0:01:32s\n",
            "epoch 57 | loss: 0.53148 |  0:01:34s\n",
            "epoch 58 | loss: 0.52236 |  0:01:35s\n",
            "epoch 59 | loss: 0.49879 |  0:01:37s\n",
            "epoch 60 | loss: 0.52604 |  0:01:38s\n",
            "epoch 61 | loss: 0.52879 |  0:01:40s\n",
            "epoch 62 | loss: 0.55598 |  0:01:42s\n",
            "epoch 63 | loss: 0.54691 |  0:01:44s\n",
            "epoch 64 | loss: 0.51604 |  0:01:45s\n",
            "epoch 65 | loss: 0.52175 |  0:01:47s\n",
            "epoch 66 | loss: 0.52452 |  0:01:48s\n",
            "epoch 67 | loss: 0.5649  |  0:01:50s\n",
            "epoch 68 | loss: 0.51763 |  0:01:51s\n",
            "epoch 69 | loss: 0.49521 |  0:01:52s\n",
            "epoch 70 | loss: 0.53563 |  0:01:54s\n",
            "epoch 71 | loss: 0.58705 |  0:01:57s\n",
            "epoch 72 | loss: 0.60484 |  0:01:58s\n",
            "epoch 73 | loss: 0.57897 |  0:02:00s\n",
            "epoch 74 | loss: 0.6072  |  0:02:01s\n",
            "epoch 75 | loss: 0.56986 |  0:02:03s\n",
            "epoch 76 | loss: 0.53919 |  0:02:04s\n",
            "epoch 77 | loss: 0.52777 |  0:02:05s\n",
            "epoch 78 | loss: 0.55632 |  0:02:07s\n",
            "epoch 79 | loss: 0.52968 |  0:02:09s\n",
            "epoch 80 | loss: 0.52314 |  0:02:11s\n",
            "epoch 81 | loss: 0.52329 |  0:02:13s\n",
            "epoch 82 | loss: 0.51115 |  0:02:14s\n",
            "epoch 83 | loss: 0.50514 |  0:02:16s\n",
            "epoch 84 | loss: 0.50672 |  0:02:17s\n",
            "epoch 85 | loss: 0.57716 |  0:02:19s\n",
            "epoch 86 | loss: 0.5162  |  0:02:20s\n",
            "epoch 87 | loss: 0.51655 |  0:02:22s\n",
            "epoch 88 | loss: 0.50647 |  0:02:24s\n",
            "epoch 89 | loss: 0.50591 |  0:02:26s\n",
            "epoch 90 | loss: 0.53067 |  0:02:27s\n",
            "epoch 91 | loss: 0.53206 |  0:02:29s\n",
            "epoch 92 | loss: 0.51875 |  0:02:30s\n",
            "epoch 93 | loss: 0.50389 |  0:02:32s\n",
            "epoch 94 | loss: 0.51682 |  0:02:33s\n",
            "epoch 95 | loss: 0.50605 |  0:02:35s\n",
            "epoch 96 | loss: 0.49346 |  0:02:37s\n",
            "epoch 97 | loss: 0.49615 |  0:02:39s\n",
            "epoch 98 | loss: 0.49216 |  0:02:40s\n",
            "epoch 99 | loss: 0.50613 |  0:02:42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.49615|  0:00:01s\n",
            "epoch 1  | loss: 2.39715 |  0:00:02s\n",
            "epoch 2  | loss: 2.24535 |  0:00:04s\n",
            "epoch 3  | loss: 1.48699 |  0:00:05s\n",
            "epoch 4  | loss: 1.47762 |  0:00:07s\n",
            "epoch 5  | loss: 1.34598 |  0:00:10s\n",
            "epoch 6  | loss: 1.35046 |  0:00:11s\n",
            "epoch 7  | loss: 1.24952 |  0:00:13s\n",
            "epoch 8  | loss: 1.22883 |  0:00:14s\n",
            "epoch 9  | loss: 1.32745 |  0:00:16s\n",
            "epoch 10 | loss: 1.2857  |  0:00:17s\n",
            "epoch 11 | loss: 1.25989 |  0:00:18s\n",
            "epoch 12 | loss: 1.21454 |  0:00:20s\n",
            "epoch 13 | loss: 1.18351 |  0:00:23s\n",
            "epoch 14 | loss: 1.21286 |  0:00:25s\n",
            "epoch 15 | loss: 1.18788 |  0:00:26s\n",
            "epoch 16 | loss: 1.20046 |  0:00:27s\n",
            "epoch 17 | loss: 1.23512 |  0:00:29s\n",
            "epoch 18 | loss: 1.16957 |  0:00:30s\n",
            "epoch 19 | loss: 1.17556 |  0:00:32s\n",
            "epoch 20 | loss: 1.15372 |  0:00:33s\n",
            "epoch 21 | loss: 1.17186 |  0:00:35s\n",
            "epoch 22 | loss: 1.24819 |  0:00:37s\n",
            "epoch 23 | loss: 1.19094 |  0:00:38s\n",
            "epoch 24 | loss: 1.15702 |  0:00:40s\n",
            "epoch 25 | loss: 1.21503 |  0:00:41s\n",
            "epoch 26 | loss: 1.20552 |  0:00:43s\n",
            "epoch 27 | loss: 1.14795 |  0:00:44s\n",
            "epoch 28 | loss: 1.17157 |  0:00:46s\n",
            "epoch 29 | loss: 1.21748 |  0:00:47s\n",
            "epoch 30 | loss: 1.18875 |  0:00:49s\n",
            "epoch 31 | loss: 1.13679 |  0:00:51s\n",
            "epoch 32 | loss: 1.13844 |  0:00:53s\n",
            "epoch 33 | loss: 1.16092 |  0:00:54s\n",
            "epoch 34 | loss: 1.19004 |  0:00:55s\n",
            "epoch 35 | loss: 1.15835 |  0:00:57s\n",
            "epoch 36 | loss: 1.23482 |  0:00:58s\n",
            "epoch 37 | loss: 1.17776 |  0:01:00s\n",
            "epoch 38 | loss: 1.20129 |  0:01:01s\n",
            "epoch 39 | loss: 1.19932 |  0:01:03s\n",
            "epoch 40 | loss: 1.18697 |  0:01:05s\n",
            "epoch 41 | loss: 1.1638  |  0:01:06s\n",
            "epoch 42 | loss: 1.2965  |  0:01:08s\n",
            "epoch 43 | loss: 1.20183 |  0:01:09s\n",
            "epoch 44 | loss: 1.15111 |  0:01:11s\n",
            "epoch 45 | loss: 1.13271 |  0:01:13s\n",
            "epoch 46 | loss: 1.15776 |  0:01:14s\n",
            "epoch 47 | loss: 1.17711 |  0:01:15s\n",
            "epoch 48 | loss: 1.16617 |  0:01:17s\n",
            "epoch 49 | loss: 1.11527 |  0:01:19s\n",
            "epoch 50 | loss: 1.13671 |  0:01:21s\n",
            "epoch 51 | loss: 1.18052 |  0:01:22s\n",
            "epoch 52 | loss: 1.18939 |  0:01:24s\n",
            "epoch 53 | loss: 1.1297  |  0:01:25s\n",
            "epoch 54 | loss: 1.12661 |  0:01:27s\n",
            "epoch 55 | loss: 1.1286  |  0:01:28s\n",
            "epoch 56 | loss: 1.12514 |  0:01:30s\n",
            "epoch 57 | loss: 1.11958 |  0:01:32s\n",
            "epoch 58 | loss: 1.14742 |  0:01:34s\n",
            "epoch 59 | loss: 1.14786 |  0:01:36s\n",
            "epoch 60 | loss: 1.14137 |  0:01:37s\n",
            "epoch 61 | loss: 1.14424 |  0:01:39s\n",
            "epoch 62 | loss: 1.16313 |  0:01:40s\n",
            "epoch 63 | loss: 1.25558 |  0:01:41s\n",
            "epoch 64 | loss: 1.20013 |  0:01:43s\n",
            "epoch 65 | loss: 1.15932 |  0:01:44s\n",
            "epoch 66 | loss: 1.16422 |  0:01:47s\n",
            "epoch 67 | loss: 1.14625 |  0:01:48s\n",
            "epoch 68 | loss: 1.16624 |  0:01:50s\n",
            "epoch 69 | loss: 1.14639 |  0:01:51s\n",
            "epoch 70 | loss: 1.12312 |  0:01:53s\n",
            "epoch 71 | loss: 1.18625 |  0:01:54s\n",
            "epoch 72 | loss: 1.2189  |  0:01:56s\n",
            "epoch 73 | loss: 1.16062 |  0:01:57s\n",
            "epoch 74 | loss: 1.12962 |  0:01:59s\n",
            "epoch 75 | loss: 1.12111 |  0:02:01s\n",
            "epoch 76 | loss: 1.12889 |  0:02:03s\n",
            "epoch 77 | loss: 1.13059 |  0:02:04s\n",
            "epoch 78 | loss: 1.16596 |  0:02:05s\n",
            "epoch 79 | loss: 1.11422 |  0:02:07s\n",
            "epoch 80 | loss: 1.1615  |  0:02:08s\n",
            "epoch 81 | loss: 1.21345 |  0:02:10s\n",
            "epoch 82 | loss: 1.16841 |  0:02:11s\n",
            "epoch 83 | loss: 1.19393 |  0:02:13s\n",
            "epoch 84 | loss: 1.1519  |  0:02:15s\n",
            "epoch 85 | loss: 1.13155 |  0:02:17s\n",
            "epoch 86 | loss: 1.13574 |  0:02:18s\n",
            "epoch 87 | loss: 1.13791 |  0:02:19s\n",
            "epoch 88 | loss: 1.1147  |  0:02:21s\n",
            "epoch 89 | loss: 1.13031 |  0:02:22s\n",
            "epoch 90 | loss: 1.14815 |  0:02:24s\n",
            "epoch 91 | loss: 1.12604 |  0:02:25s\n",
            "epoch 92 | loss: 1.13028 |  0:02:27s\n",
            "epoch 93 | loss: 1.12473 |  0:02:29s\n",
            "epoch 94 | loss: 1.11602 |  0:02:31s\n",
            "epoch 95 | loss: 1.12866 |  0:02:32s\n",
            "epoch 96 | loss: 1.13295 |  0:02:34s\n",
            "epoch 97 | loss: 1.1295  |  0:02:35s\n",
            "epoch 98 | loss: 1.12329 |  0:02:36s\n",
            "epoch 99 | loss: 1.11494 |  0:02:38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 17.69316|  0:00:01s\n",
            "epoch 1  | loss: 1.58468 |  0:00:03s\n",
            "epoch 2  | loss: 1.10359 |  0:00:05s\n",
            "epoch 3  | loss: 1.07165 |  0:00:07s\n",
            "epoch 4  | loss: 0.95147 |  0:00:08s\n",
            "epoch 5  | loss: 1.04159 |  0:00:09s\n",
            "epoch 6  | loss: 0.95662 |  0:00:11s\n",
            "epoch 7  | loss: 0.89454 |  0:00:12s\n",
            "epoch 8  | loss: 0.86015 |  0:00:14s\n",
            "epoch 9  | loss: 0.76614 |  0:00:15s\n",
            "epoch 10 | loss: 0.76647 |  0:00:17s\n",
            "epoch 11 | loss: 0.69126 |  0:00:19s\n",
            "epoch 12 | loss: 0.72488 |  0:00:21s\n",
            "epoch 13 | loss: 0.78417 |  0:00:22s\n",
            "epoch 14 | loss: 0.78702 |  0:00:24s\n",
            "epoch 15 | loss: 0.77467 |  0:00:25s\n",
            "epoch 16 | loss: 0.74189 |  0:00:27s\n",
            "epoch 17 | loss: 0.76113 |  0:00:28s\n",
            "epoch 18 | loss: 0.80766 |  0:00:30s\n",
            "epoch 19 | loss: 0.70675 |  0:00:32s\n",
            "epoch 20 | loss: 0.7243  |  0:00:34s\n",
            "epoch 21 | loss: 0.69177 |  0:00:35s\n",
            "epoch 22 | loss: 0.71068 |  0:00:37s\n",
            "epoch 23 | loss: 0.72361 |  0:00:38s\n",
            "epoch 24 | loss: 0.76404 |  0:00:40s\n",
            "epoch 25 | loss: 0.75809 |  0:00:41s\n",
            "epoch 26 | loss: 0.71183 |  0:00:43s\n",
            "epoch 27 | loss: 0.66749 |  0:00:45s\n",
            "epoch 28 | loss: 0.70347 |  0:00:47s\n",
            "epoch 29 | loss: 0.66384 |  0:00:48s\n",
            "epoch 30 | loss: 0.65105 |  0:00:50s\n",
            "epoch 31 | loss: 0.70074 |  0:00:51s\n",
            "epoch 32 | loss: 0.6714  |  0:00:53s\n",
            "epoch 33 | loss: 0.64866 |  0:00:54s\n",
            "epoch 34 | loss: 0.6642  |  0:00:55s\n",
            "epoch 35 | loss: 0.66269 |  0:00:57s\n",
            "epoch 36 | loss: 0.69923 |  0:00:59s\n",
            "epoch 37 | loss: 0.63698 |  0:01:01s\n",
            "epoch 38 | loss: 0.65237 |  0:01:02s\n",
            "epoch 39 | loss: 0.6284  |  0:01:04s\n",
            "epoch 40 | loss: 0.67053 |  0:01:05s\n",
            "epoch 41 | loss: 0.73256 |  0:01:07s\n",
            "epoch 42 | loss: 0.67487 |  0:01:08s\n",
            "epoch 43 | loss: 0.6194  |  0:01:10s\n",
            "epoch 44 | loss: 0.63213 |  0:01:11s\n",
            "epoch 45 | loss: 0.63953 |  0:01:14s\n",
            "epoch 46 | loss: 0.61371 |  0:01:15s\n",
            "epoch 47 | loss: 0.61983 |  0:01:17s\n",
            "epoch 48 | loss: 0.62416 |  0:01:18s\n",
            "epoch 49 | loss: 0.61641 |  0:01:19s\n",
            "epoch 50 | loss: 0.61165 |  0:01:21s\n",
            "epoch 51 | loss: 0.60613 |  0:01:22s\n",
            "epoch 52 | loss: 0.60894 |  0:01:24s\n",
            "epoch 53 | loss: 0.64002 |  0:01:25s\n",
            "epoch 54 | loss: 0.67484 |  0:01:28s\n",
            "epoch 55 | loss: 0.60247 |  0:01:29s\n",
            "epoch 56 | loss: 0.61747 |  0:01:31s\n",
            "epoch 57 | loss: 0.60524 |  0:01:32s\n",
            "epoch 58 | loss: 0.65843 |  0:01:34s\n",
            "epoch 59 | loss: 0.61892 |  0:01:35s\n",
            "epoch 60 | loss: 0.62511 |  0:01:37s\n",
            "epoch 61 | loss: 0.66691 |  0:01:38s\n",
            "epoch 62 | loss: 0.70247 |  0:01:40s\n",
            "epoch 63 | loss: 0.6167  |  0:01:42s\n",
            "epoch 64 | loss: 0.60149 |  0:01:44s\n",
            "epoch 65 | loss: 0.62688 |  0:01:45s\n",
            "epoch 66 | loss: 0.61322 |  0:01:47s\n",
            "epoch 67 | loss: 0.6222  |  0:01:48s\n",
            "epoch 68 | loss: 0.63155 |  0:01:49s\n",
            "epoch 69 | loss: 0.64572 |  0:01:51s\n",
            "epoch 70 | loss: 0.64882 |  0:01:53s\n",
            "epoch 71 | loss: 0.604   |  0:01:55s\n",
            "epoch 72 | loss: 0.60346 |  0:01:57s\n",
            "epoch 73 | loss: 0.61638 |  0:01:58s\n",
            "epoch 74 | loss: 0.63006 |  0:01:59s\n",
            "epoch 75 | loss: 0.6242  |  0:02:01s\n",
            "epoch 76 | loss: 0.59419 |  0:02:02s\n",
            "epoch 77 | loss: 0.59434 |  0:02:04s\n",
            "epoch 78 | loss: 0.61795 |  0:02:05s\n",
            "epoch 79 | loss: 0.60561 |  0:02:07s\n",
            "epoch 80 | loss: 0.63262 |  0:02:09s\n",
            "epoch 81 | loss: 0.62116 |  0:02:11s\n",
            "epoch 82 | loss: 0.57761 |  0:02:12s\n",
            "epoch 83 | loss: 0.68505 |  0:02:14s\n",
            "epoch 84 | loss: 0.64586 |  0:02:15s\n",
            "epoch 85 | loss: 0.5942  |  0:02:17s\n",
            "epoch 86 | loss: 0.57088 |  0:02:18s\n",
            "epoch 87 | loss: 0.59041 |  0:02:19s\n",
            "epoch 88 | loss: 0.64722 |  0:02:21s\n",
            "epoch 89 | loss: 0.6186  |  0:02:24s\n",
            "epoch 90 | loss: 0.64026 |  0:02:25s\n",
            "epoch 91 | loss: 0.64238 |  0:02:27s\n",
            "epoch 92 | loss: 0.64737 |  0:02:28s\n",
            "epoch 93 | loss: 0.68139 |  0:02:29s\n",
            "epoch 94 | loss: 0.70215 |  0:02:31s\n",
            "epoch 95 | loss: 0.67791 |  0:02:33s\n",
            "epoch 96 | loss: 0.70439 |  0:02:34s\n",
            "epoch 97 | loss: 0.64029 |  0:02:36s\n",
            "epoch 98 | loss: 0.67218 |  0:02:38s\n",
            "epoch 99 | loss: 0.61325 |  0:02:39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 19.64529|  0:00:01s\n",
            "epoch 1  | loss: 2.66355 |  0:00:03s\n",
            "epoch 2  | loss: 1.65938 |  0:00:04s\n",
            "epoch 3  | loss: 1.45237 |  0:00:05s\n",
            "epoch 4  | loss: 1.34551 |  0:00:07s\n",
            "epoch 5  | loss: 1.17524 |  0:00:09s\n",
            "epoch 6  | loss: 1.21705 |  0:00:11s\n",
            "epoch 7  | loss: 1.2971  |  0:00:12s\n",
            "epoch 8  | loss: 1.0709  |  0:00:14s\n",
            "epoch 9  | loss: 1.06864 |  0:00:15s\n",
            "epoch 10 | loss: 1.20542 |  0:00:17s\n",
            "epoch 11 | loss: 1.09146 |  0:00:18s\n",
            "epoch 12 | loss: 1.03116 |  0:00:20s\n",
            "epoch 13 | loss: 1.1394  |  0:00:21s\n",
            "epoch 14 | loss: 1.07826 |  0:00:23s\n",
            "epoch 15 | loss: 1.05872 |  0:00:25s\n",
            "epoch 16 | loss: 1.0902  |  0:00:27s\n",
            "epoch 17 | loss: 1.08259 |  0:00:28s\n",
            "epoch 18 | loss: 1.07675 |  0:00:30s\n",
            "epoch 19 | loss: 1.18606 |  0:00:31s\n",
            "epoch 20 | loss: 1.06533 |  0:00:33s\n",
            "epoch 21 | loss: 1.09226 |  0:00:34s\n",
            "epoch 22 | loss: 1.05561 |  0:00:36s\n",
            "epoch 23 | loss: 1.07794 |  0:00:38s\n",
            "epoch 24 | loss: 1.07136 |  0:00:40s\n",
            "epoch 25 | loss: 1.01975 |  0:00:41s\n",
            "epoch 26 | loss: 1.03177 |  0:00:43s\n",
            "epoch 27 | loss: 1.08125 |  0:00:44s\n",
            "epoch 28 | loss: 1.11038 |  0:00:46s\n",
            "epoch 29 | loss: 1.02806 |  0:00:47s\n",
            "epoch 30 | loss: 1.00056 |  0:00:49s\n",
            "epoch 31 | loss: 1.05444 |  0:00:51s\n",
            "epoch 32 | loss: 1.0064  |  0:00:53s\n",
            "epoch 33 | loss: 1.05158 |  0:00:54s\n",
            "epoch 34 | loss: 0.99692 |  0:00:56s\n",
            "epoch 35 | loss: 0.97457 |  0:00:57s\n",
            "epoch 36 | loss: 0.99067 |  0:00:59s\n",
            "epoch 37 | loss: 0.97004 |  0:01:00s\n",
            "epoch 38 | loss: 1.05484 |  0:01:02s\n",
            "epoch 39 | loss: 0.98324 |  0:01:03s\n",
            "epoch 40 | loss: 1.01522 |  0:01:05s\n",
            "epoch 41 | loss: 1.00168 |  0:01:07s\n",
            "epoch 42 | loss: 0.96118 |  0:01:09s\n",
            "epoch 43 | loss: 0.95981 |  0:01:11s\n",
            "epoch 44 | loss: 0.97494 |  0:01:12s\n",
            "epoch 45 | loss: 1.00066 |  0:01:13s\n",
            "epoch 46 | loss: 1.02974 |  0:01:15s\n",
            "epoch 47 | loss: 0.9881  |  0:01:16s\n",
            "epoch 48 | loss: 0.99396 |  0:01:18s\n",
            "epoch 49 | loss: 0.95306 |  0:01:20s\n",
            "epoch 50 | loss: 0.91313 |  0:01:22s\n",
            "epoch 51 | loss: 0.94077 |  0:01:24s\n",
            "epoch 52 | loss: 0.9608  |  0:01:25s\n",
            "epoch 53 | loss: 0.94891 |  0:01:27s\n",
            "epoch 54 | loss: 0.93662 |  0:01:28s\n",
            "epoch 55 | loss: 0.92697 |  0:01:30s\n",
            "epoch 56 | loss: 0.94393 |  0:01:31s\n",
            "epoch 57 | loss: 0.91333 |  0:01:33s\n",
            "epoch 58 | loss: 0.94843 |  0:01:35s\n",
            "epoch 59 | loss: 0.94616 |  0:01:37s\n",
            "epoch 60 | loss: 0.94338 |  0:01:38s\n",
            "epoch 61 | loss: 0.94042 |  0:01:40s\n",
            "epoch 62 | loss: 0.93248 |  0:01:41s\n",
            "epoch 63 | loss: 0.94282 |  0:01:42s\n",
            "epoch 64 | loss: 0.93398 |  0:01:44s\n",
            "epoch 65 | loss: 0.94811 |  0:01:46s\n",
            "epoch 66 | loss: 0.96151 |  0:01:48s\n",
            "epoch 67 | loss: 0.94482 |  0:01:50s\n",
            "epoch 68 | loss: 0.90935 |  0:01:51s\n",
            "epoch 69 | loss: 0.91144 |  0:01:52s\n",
            "epoch 70 | loss: 0.92081 |  0:01:54s\n",
            "epoch 71 | loss: 0.95873 |  0:01:55s\n",
            "epoch 72 | loss: 0.96062 |  0:01:57s\n",
            "epoch 73 | loss: 0.90204 |  0:01:58s\n",
            "epoch 74 | loss: 0.91425 |  0:02:00s\n",
            "epoch 75 | loss: 0.93883 |  0:02:02s\n",
            "epoch 76 | loss: 0.92077 |  0:02:04s\n",
            "epoch 77 | loss: 0.93195 |  0:02:05s\n",
            "epoch 78 | loss: 0.90344 |  0:02:07s\n",
            "epoch 79 | loss: 0.91305 |  0:02:08s\n",
            "epoch 80 | loss: 0.95987 |  0:02:10s\n",
            "epoch 81 | loss: 0.90424 |  0:02:11s\n",
            "epoch 82 | loss: 0.89777 |  0:02:13s\n",
            "epoch 83 | loss: 0.91868 |  0:02:15s\n",
            "epoch 84 | loss: 0.91611 |  0:02:17s\n",
            "epoch 85 | loss: 0.93381 |  0:02:18s\n",
            "epoch 86 | loss: 0.88983 |  0:02:20s\n",
            "epoch 87 | loss: 0.92871 |  0:02:21s\n",
            "epoch 88 | loss: 0.91993 |  0:02:23s\n",
            "epoch 89 | loss: 0.91167 |  0:02:24s\n",
            "epoch 90 | loss: 0.936   |  0:02:26s\n",
            "epoch 91 | loss: 0.91089 |  0:02:27s\n",
            "epoch 92 | loss: 0.89396 |  0:02:29s\n",
            "epoch 93 | loss: 0.90666 |  0:02:31s\n",
            "epoch 94 | loss: 0.92221 |  0:02:33s\n",
            "epoch 95 | loss: 0.89989 |  0:02:34s\n",
            "epoch 96 | loss: 0.89111 |  0:02:36s\n",
            "epoch 97 | loss: 0.90466 |  0:02:37s\n",
            "epoch 98 | loss: 0.91164 |  0:02:39s\n",
            "epoch 99 | loss: 0.93617 |  0:02:40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.55423 |  0:00:02s\n",
            "epoch 1  | loss: 2.95729 |  0:00:04s\n",
            "epoch 2  | loss: 1.97992 |  0:00:05s\n",
            "epoch 3  | loss: 1.23563 |  0:00:07s\n",
            "epoch 4  | loss: 1.13197 |  0:00:08s\n",
            "epoch 5  | loss: 0.99781 |  0:00:09s\n",
            "epoch 6  | loss: 0.8958  |  0:00:11s\n",
            "epoch 7  | loss: 0.82909 |  0:00:12s\n",
            "epoch 8  | loss: 0.88885 |  0:00:14s\n",
            "epoch 9  | loss: 0.85643 |  0:00:16s\n",
            "epoch 10 | loss: 0.81774 |  0:00:18s\n",
            "epoch 11 | loss: 0.76559 |  0:00:20s\n",
            "epoch 12 | loss: 0.7556  |  0:00:21s\n",
            "epoch 13 | loss: 0.77265 |  0:00:23s\n",
            "epoch 14 | loss: 0.81609 |  0:00:24s\n",
            "epoch 15 | loss: 0.77926 |  0:00:25s\n",
            "epoch 16 | loss: 0.89415 |  0:00:27s\n",
            "epoch 17 | loss: 0.77477 |  0:00:29s\n",
            "epoch 18 | loss: 0.76011 |  0:00:31s\n",
            "epoch 19 | loss: 0.77964 |  0:00:33s\n",
            "epoch 20 | loss: 0.76998 |  0:00:34s\n",
            "epoch 21 | loss: 0.74643 |  0:00:36s\n",
            "epoch 22 | loss: 0.7173  |  0:00:37s\n",
            "epoch 23 | loss: 0.67293 |  0:00:39s\n",
            "epoch 24 | loss: 0.74    |  0:00:40s\n",
            "epoch 25 | loss: 0.70852 |  0:00:42s\n",
            "epoch 26 | loss: 0.67475 |  0:00:44s\n",
            "epoch 27 | loss: 0.68981 |  0:00:46s\n",
            "epoch 28 | loss: 0.75215 |  0:00:47s\n",
            "epoch 29 | loss: 0.68901 |  0:00:49s\n",
            "epoch 30 | loss: 0.67343 |  0:00:50s\n",
            "epoch 31 | loss: 0.69184 |  0:00:52s\n",
            "epoch 32 | loss: 0.71507 |  0:00:53s\n",
            "epoch 33 | loss: 0.71538 |  0:00:55s\n",
            "epoch 34 | loss: 0.65018 |  0:00:56s\n",
            "epoch 35 | loss: 0.631   |  0:00:59s\n",
            "epoch 36 | loss: 0.6347  |  0:01:00s\n",
            "epoch 37 | loss: 0.75493 |  0:01:02s\n",
            "epoch 38 | loss: 0.75757 |  0:01:03s\n",
            "epoch 39 | loss: 0.68404 |  0:01:05s\n",
            "epoch 40 | loss: 0.63579 |  0:01:06s\n",
            "epoch 41 | loss: 0.67557 |  0:01:08s\n",
            "epoch 42 | loss: 0.6399  |  0:01:09s\n",
            "epoch 43 | loss: 0.64707 |  0:01:11s\n",
            "epoch 44 | loss: 0.64434 |  0:01:13s\n",
            "epoch 45 | loss: 0.63777 |  0:01:15s\n",
            "epoch 46 | loss: 0.61585 |  0:01:16s\n",
            "epoch 47 | loss: 0.66796 |  0:01:18s\n",
            "epoch 48 | loss: 0.71489 |  0:01:19s\n",
            "epoch 49 | loss: 0.68918 |  0:01:20s\n",
            "epoch 50 | loss: 0.65295 |  0:01:22s\n",
            "epoch 51 | loss: 0.69326 |  0:01:23s\n",
            "epoch 52 | loss: 0.68434 |  0:01:26s\n",
            "epoch 53 | loss: 0.77195 |  0:01:28s\n",
            "epoch 54 | loss: 0.6667  |  0:01:29s\n",
            "epoch 55 | loss: 0.6567  |  0:01:31s\n",
            "epoch 56 | loss: 0.66946 |  0:01:32s\n",
            "epoch 57 | loss: 0.65903 |  0:01:33s\n",
            "epoch 58 | loss: 0.72558 |  0:01:35s\n",
            "epoch 59 | loss: 0.67623 |  0:01:36s\n",
            "epoch 60 | loss: 0.67887 |  0:01:38s\n",
            "epoch 61 | loss: 0.66482 |  0:01:41s\n",
            "epoch 62 | loss: 0.69106 |  0:01:42s\n",
            "epoch 63 | loss: 0.66463 |  0:01:43s\n",
            "epoch 64 | loss: 0.67261 |  0:01:45s\n",
            "epoch 65 | loss: 0.65481 |  0:01:46s\n",
            "epoch 66 | loss: 0.72631 |  0:01:48s\n",
            "epoch 67 | loss: 0.64716 |  0:01:49s\n",
            "epoch 68 | loss: 0.65816 |  0:01:51s\n",
            "epoch 69 | loss: 0.64492 |  0:01:53s\n",
            "epoch 70 | loss: 0.64667 |  0:01:55s\n",
            "epoch 71 | loss: 0.69483 |  0:01:57s\n",
            "epoch 72 | loss: 0.65382 |  0:01:58s\n",
            "epoch 73 | loss: 0.63896 |  0:02:00s\n",
            "epoch 74 | loss: 0.62634 |  0:02:01s\n",
            "epoch 75 | loss: 0.598   |  0:02:03s\n",
            "epoch 76 | loss: 0.61714 |  0:02:04s\n",
            "epoch 77 | loss: 0.62381 |  0:02:06s\n",
            "epoch 78 | loss: 0.64665 |  0:02:08s\n",
            "epoch 79 | loss: 0.61148 |  0:02:10s\n",
            "epoch 80 | loss: 0.6309  |  0:02:11s\n",
            "epoch 81 | loss: 0.57712 |  0:02:13s\n",
            "epoch 82 | loss: 0.63074 |  0:02:14s\n",
            "epoch 83 | loss: 0.60075 |  0:02:16s\n",
            "epoch 84 | loss: 0.5617  |  0:02:18s\n",
            "epoch 85 | loss: 0.56745 |  0:02:19s\n",
            "epoch 86 | loss: 0.60811 |  0:02:21s\n",
            "epoch 87 | loss: 0.57811 |  0:02:23s\n",
            "epoch 88 | loss: 0.60106 |  0:02:25s\n",
            "epoch 89 | loss: 0.58845 |  0:02:26s\n",
            "epoch 90 | loss: 0.60844 |  0:02:28s\n",
            "epoch 91 | loss: 0.65388 |  0:02:29s\n",
            "epoch 92 | loss: 0.59853 |  0:02:30s\n",
            "epoch 93 | loss: 0.59641 |  0:02:32s\n",
            "epoch 94 | loss: 0.60381 |  0:02:34s\n",
            "epoch 95 | loss: 0.60002 |  0:02:36s\n",
            "epoch 96 | loss: 0.62722 |  0:02:38s\n",
            "epoch 97 | loss: 0.60425 |  0:02:39s\n",
            "epoch 98 | loss: 0.57045 |  0:02:41s\n",
            "epoch 99 | loss: 0.59612 |  0:02:42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.38602|  0:00:01s\n",
            "epoch 1  | loss: 2.32916 |  0:00:03s\n",
            "epoch 2  | loss: 1.85258 |  0:00:04s\n",
            "epoch 3  | loss: 1.64872 |  0:00:07s\n",
            "epoch 4  | loss: 1.5987  |  0:00:08s\n",
            "epoch 5  | loss: 1.58584 |  0:00:10s\n",
            "epoch 6  | loss: 1.7045  |  0:00:11s\n",
            "epoch 7  | loss: 1.56639 |  0:00:13s\n",
            "epoch 8  | loss: 1.50557 |  0:00:14s\n",
            "epoch 9  | loss: 1.44425 |  0:00:16s\n",
            "epoch 10 | loss: 1.51132 |  0:00:17s\n",
            "epoch 11 | loss: 1.55136 |  0:00:19s\n",
            "epoch 12 | loss: 1.41148 |  0:00:21s\n",
            "epoch 13 | loss: 1.50965 |  0:00:23s\n",
            "epoch 14 | loss: 1.42752 |  0:00:25s\n",
            "epoch 15 | loss: 1.45076 |  0:00:26s\n",
            "epoch 16 | loss: 1.40515 |  0:00:28s\n",
            "epoch 17 | loss: 1.37173 |  0:00:29s\n",
            "epoch 18 | loss: 1.38778 |  0:00:31s\n",
            "epoch 19 | loss: 1.38693 |  0:00:32s\n",
            "epoch 20 | loss: 1.42614 |  0:00:35s\n",
            "epoch 21 | loss: 1.55538 |  0:00:36s\n",
            "epoch 22 | loss: 1.54619 |  0:00:38s\n",
            "epoch 23 | loss: 1.43831 |  0:00:39s\n",
            "epoch 24 | loss: 1.40164 |  0:00:41s\n",
            "epoch 25 | loss: 1.42159 |  0:00:42s\n",
            "epoch 26 | loss: 1.45175 |  0:00:44s\n",
            "epoch 27 | loss: 1.35125 |  0:00:45s\n",
            "epoch 28 | loss: 1.37288 |  0:00:47s\n",
            "epoch 29 | loss: 1.40831 |  0:00:49s\n",
            "epoch 30 | loss: 1.35893 |  0:00:51s\n",
            "epoch 31 | loss: 1.32859 |  0:00:52s\n",
            "epoch 32 | loss: 1.36992 |  0:00:54s\n",
            "epoch 33 | loss: 1.33649 |  0:00:55s\n",
            "epoch 34 | loss: 1.31566 |  0:00:56s\n",
            "epoch 35 | loss: 1.31458 |  0:00:58s\n",
            "epoch 36 | loss: 1.35942 |  0:01:00s\n",
            "epoch 37 | loss: 1.35496 |  0:01:02s\n",
            "epoch 38 | loss: 1.46654 |  0:01:04s\n",
            "epoch 39 | loss: 1.41075 |  0:01:05s\n",
            "epoch 40 | loss: 1.47047 |  0:01:07s\n",
            "epoch 41 | loss: 1.46462 |  0:01:08s\n",
            "epoch 42 | loss: 1.37943 |  0:01:09s\n",
            "epoch 43 | loss: 1.34911 |  0:01:11s\n",
            "epoch 44 | loss: 1.39155 |  0:01:12s\n",
            "epoch 45 | loss: 1.37933 |  0:01:14s\n",
            "epoch 46 | loss: 1.43467 |  0:01:17s\n",
            "epoch 47 | loss: 1.30951 |  0:01:18s\n",
            "epoch 48 | loss: 1.40866 |  0:01:19s\n",
            "epoch 49 | loss: 1.46471 |  0:01:21s\n",
            "epoch 50 | loss: 1.42405 |  0:01:22s\n",
            "epoch 51 | loss: 1.34759 |  0:01:24s\n",
            "epoch 52 | loss: 1.33466 |  0:01:25s\n",
            "epoch 53 | loss: 1.34934 |  0:01:27s\n",
            "epoch 54 | loss: 1.30643 |  0:01:29s\n",
            "epoch 55 | loss: 1.3328  |  0:01:31s\n",
            "epoch 56 | loss: 1.33553 |  0:01:32s\n",
            "epoch 57 | loss: 1.34294 |  0:01:34s\n",
            "epoch 58 | loss: 1.34897 |  0:01:35s\n",
            "epoch 59 | loss: 1.32832 |  0:01:37s\n",
            "epoch 60 | loss: 1.27309 |  0:01:39s\n",
            "epoch 61 | loss: 1.2937  |  0:01:40s\n",
            "epoch 62 | loss: 1.35748 |  0:01:42s\n",
            "epoch 63 | loss: 1.30098 |  0:01:44s\n",
            "epoch 64 | loss: 1.29027 |  0:01:46s\n",
            "epoch 65 | loss: 1.34147 |  0:01:47s\n",
            "epoch 66 | loss: 1.35418 |  0:01:49s\n",
            "epoch 67 | loss: 1.32042 |  0:01:50s\n",
            "epoch 68 | loss: 1.3264  |  0:01:52s\n",
            "epoch 69 | loss: 1.34934 |  0:01:53s\n",
            "epoch 70 | loss: 1.30913 |  0:01:55s\n",
            "epoch 71 | loss: 1.28478 |  0:01:57s\n",
            "epoch 72 | loss: 1.32434 |  0:01:59s\n",
            "epoch 73 | loss: 1.29171 |  0:02:00s\n",
            "epoch 74 | loss: 1.38443 |  0:02:02s\n",
            "epoch 75 | loss: 1.26431 |  0:02:03s\n",
            "epoch 76 | loss: 1.26606 |  0:02:05s\n",
            "epoch 77 | loss: 1.33063 |  0:02:06s\n",
            "epoch 78 | loss: 1.34078 |  0:02:07s\n",
            "epoch 79 | loss: 1.33261 |  0:02:09s\n",
            "epoch 80 | loss: 1.27536 |  0:02:11s\n",
            "epoch 81 | loss: 1.36284 |  0:02:13s\n",
            "epoch 82 | loss: 1.3352  |  0:02:15s\n",
            "epoch 83 | loss: 1.35914 |  0:02:16s\n",
            "epoch 84 | loss: 1.34022 |  0:02:18s\n",
            "epoch 85 | loss: 1.32861 |  0:02:19s\n",
            "epoch 86 | loss: 1.31483 |  0:02:21s\n",
            "epoch 87 | loss: 1.36964 |  0:02:22s\n",
            "epoch 88 | loss: 1.40462 |  0:02:24s\n",
            "epoch 89 | loss: 1.35544 |  0:02:26s\n",
            "epoch 90 | loss: 1.325   |  0:02:28s\n",
            "epoch 91 | loss: 1.40952 |  0:02:30s\n",
            "epoch 92 | loss: 1.37811 |  0:02:31s\n",
            "epoch 93 | loss: 1.33716 |  0:02:32s\n",
            "epoch 94 | loss: 1.35109 |  0:02:34s\n",
            "epoch 95 | loss: 1.35182 |  0:02:35s\n",
            "epoch 96 | loss: 1.42551 |  0:02:37s\n",
            "epoch 97 | loss: 1.45694 |  0:02:39s\n",
            "epoch 98 | loss: 1.41485 |  0:02:41s\n",
            "epoch 99 | loss: 1.36279 |  0:02:43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 6.6317  |  0:00:01s\n",
            "epoch 1  | loss: 1.42197 |  0:00:02s\n",
            "epoch 2  | loss: 1.11355 |  0:00:03s\n",
            "epoch 3  | loss: 0.96829 |  0:00:05s\n",
            "epoch 4  | loss: 0.89641 |  0:00:06s\n",
            "epoch 5  | loss: 0.9336  |  0:00:08s\n",
            "epoch 6  | loss: 0.92538 |  0:00:10s\n",
            "epoch 7  | loss: 0.88442 |  0:00:11s\n",
            "epoch 8  | loss: 0.87057 |  0:00:13s\n",
            "epoch 9  | loss: 0.88386 |  0:00:14s\n",
            "epoch 10 | loss: 0.91235 |  0:00:15s\n",
            "epoch 11 | loss: 0.86124 |  0:00:17s\n",
            "epoch 12 | loss: 0.95381 |  0:00:18s\n",
            "epoch 13 | loss: 0.83301 |  0:00:19s\n",
            "epoch 14 | loss: 0.87898 |  0:00:21s\n",
            "epoch 15 | loss: 0.90144 |  0:00:23s\n",
            "epoch 16 | loss: 0.85771 |  0:00:25s\n",
            "epoch 17 | loss: 0.93152 |  0:00:26s\n",
            "epoch 18 | loss: 0.84339 |  0:00:27s\n",
            "epoch 19 | loss: 0.83946 |  0:00:29s\n",
            "epoch 20 | loss: 0.83498 |  0:00:30s\n",
            "epoch 21 | loss: 0.88713 |  0:00:31s\n",
            "epoch 22 | loss: 0.80609 |  0:00:32s\n",
            "epoch 23 | loss: 0.82692 |  0:00:34s\n",
            "epoch 24 | loss: 0.86689 |  0:00:35s\n",
            "epoch 25 | loss: 0.80797 |  0:00:37s\n",
            "epoch 26 | loss: 0.84458 |  0:00:39s\n",
            "epoch 27 | loss: 0.79028 |  0:00:40s\n",
            "epoch 28 | loss: 0.79611 |  0:00:42s\n",
            "epoch 29 | loss: 0.78807 |  0:00:43s\n",
            "epoch 30 | loss: 0.86786 |  0:00:44s\n",
            "epoch 31 | loss: 0.89209 |  0:00:45s\n",
            "epoch 32 | loss: 0.84681 |  0:00:47s\n",
            "epoch 33 | loss: 0.86058 |  0:00:48s\n",
            "epoch 34 | loss: 0.80896 |  0:00:50s\n",
            "epoch 35 | loss: 0.79613 |  0:00:52s\n",
            "epoch 36 | loss: 0.7943  |  0:00:54s\n",
            "epoch 37 | loss: 0.76839 |  0:00:55s\n",
            "epoch 38 | loss: 0.76729 |  0:00:56s\n",
            "epoch 39 | loss: 0.76816 |  0:00:58s\n",
            "epoch 40 | loss: 0.76424 |  0:00:59s\n",
            "epoch 41 | loss: 0.75855 |  0:01:00s\n",
            "epoch 42 | loss: 0.80143 |  0:01:02s\n",
            "epoch 43 | loss: 0.77507 |  0:01:03s\n",
            "epoch 44 | loss: 0.7871  |  0:01:05s\n",
            "epoch 45 | loss: 0.78207 |  0:01:07s\n",
            "epoch 46 | loss: 0.79615 |  0:01:08s\n",
            "epoch 47 | loss: 0.80944 |  0:01:10s\n",
            "epoch 48 | loss: 0.77566 |  0:01:11s\n",
            "epoch 49 | loss: 0.75201 |  0:01:12s\n",
            "epoch 50 | loss: 0.77009 |  0:01:14s\n",
            "epoch 51 | loss: 0.76153 |  0:01:15s\n",
            "epoch 52 | loss: 0.78251 |  0:01:16s\n",
            "epoch 53 | loss: 0.7811  |  0:01:18s\n",
            "epoch 54 | loss: 0.7744  |  0:01:20s\n",
            "epoch 55 | loss: 0.75474 |  0:01:21s\n",
            "epoch 56 | loss: 0.7406  |  0:01:23s\n",
            "epoch 57 | loss: 0.76508 |  0:01:24s\n",
            "epoch 58 | loss: 0.76333 |  0:01:25s\n",
            "epoch 59 | loss: 0.77208 |  0:01:27s\n",
            "epoch 60 | loss: 0.77599 |  0:01:28s\n",
            "epoch 61 | loss: 0.78839 |  0:01:29s\n",
            "epoch 62 | loss: 0.81726 |  0:01:31s\n",
            "epoch 63 | loss: 0.77676 |  0:01:33s\n",
            "epoch 64 | loss: 0.75515 |  0:01:35s\n",
            "epoch 65 | loss: 0.77864 |  0:01:36s\n",
            "epoch 66 | loss: 0.81725 |  0:01:37s\n",
            "epoch 67 | loss: 0.78811 |  0:01:39s\n",
            "epoch 68 | loss: 0.77465 |  0:01:40s\n",
            "epoch 69 | loss: 0.7646  |  0:01:41s\n",
            "epoch 70 | loss: 0.78613 |  0:01:42s\n",
            "epoch 71 | loss: 0.74709 |  0:01:44s\n",
            "epoch 72 | loss: 0.80638 |  0:01:45s\n",
            "epoch 73 | loss: 0.76924 |  0:01:47s\n",
            "epoch 74 | loss: 0.76826 |  0:01:49s\n",
            "epoch 75 | loss: 0.75027 |  0:01:50s\n",
            "epoch 76 | loss: 0.76801 |  0:01:52s\n",
            "epoch 77 | loss: 0.77163 |  0:01:53s\n",
            "epoch 78 | loss: 0.77112 |  0:01:54s\n",
            "epoch 79 | loss: 0.74229 |  0:01:56s\n",
            "epoch 80 | loss: 0.75632 |  0:01:57s\n",
            "epoch 81 | loss: 0.78044 |  0:01:58s\n",
            "epoch 82 | loss: 0.78272 |  0:02:00s\n",
            "epoch 83 | loss: 0.74145 |  0:02:02s\n",
            "epoch 84 | loss: 0.75985 |  0:02:04s\n",
            "epoch 85 | loss: 0.75322 |  0:02:05s\n",
            "epoch 86 | loss: 0.7554  |  0:02:06s\n",
            "epoch 87 | loss: 0.76414 |  0:02:07s\n",
            "epoch 88 | loss: 0.74522 |  0:02:09s\n",
            "epoch 89 | loss: 0.75991 |  0:02:10s\n",
            "epoch 90 | loss: 0.76326 |  0:02:11s\n",
            "epoch 91 | loss: 0.80568 |  0:02:13s\n",
            "epoch 92 | loss: 0.76515 |  0:02:14s\n",
            "epoch 93 | loss: 0.77734 |  0:02:16s\n",
            "epoch 94 | loss: 0.7697  |  0:02:18s\n",
            "epoch 95 | loss: 0.77949 |  0:02:19s\n",
            "epoch 96 | loss: 0.78485 |  0:02:21s\n",
            "epoch 97 | loss: 0.7598  |  0:02:22s\n",
            "epoch 98 | loss: 0.75536 |  0:02:23s\n",
            "epoch 99 | loss: 0.73684 |  0:02:25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 7.41501 |  0:00:01s\n",
            "epoch 1  | loss: 1.37466 |  0:00:03s\n",
            "epoch 2  | loss: 1.12626 |  0:00:05s\n",
            "epoch 3  | loss: 0.96748 |  0:00:06s\n",
            "epoch 4  | loss: 0.77781 |  0:00:07s\n",
            "epoch 5  | loss: 0.85139 |  0:00:09s\n",
            "epoch 6  | loss: 0.68716 |  0:00:10s\n",
            "epoch 7  | loss: 0.77201 |  0:00:11s\n",
            "epoch 8  | loss: 0.67749 |  0:00:13s\n",
            "epoch 9  | loss: 0.74237 |  0:00:14s\n",
            "epoch 10 | loss: 0.65325 |  0:00:16s\n",
            "epoch 11 | loss: 0.63765 |  0:00:17s\n",
            "epoch 12 | loss: 0.68916 |  0:00:19s\n",
            "epoch 13 | loss: 0.66931 |  0:00:21s\n",
            "epoch 14 | loss: 0.84411 |  0:00:22s\n",
            "epoch 15 | loss: 0.68752 |  0:00:23s\n",
            "epoch 16 | loss: 0.7306  |  0:00:25s\n",
            "epoch 17 | loss: 0.70227 |  0:00:26s\n",
            "epoch 18 | loss: 0.63087 |  0:00:27s\n",
            "epoch 19 | loss: 0.68023 |  0:00:29s\n",
            "epoch 20 | loss: 0.85622 |  0:00:31s\n",
            "epoch 21 | loss: 0.81557 |  0:00:33s\n",
            "epoch 22 | loss: 0.74613 |  0:00:34s\n",
            "epoch 23 | loss: 0.69406 |  0:00:36s\n",
            "epoch 24 | loss: 0.61394 |  0:00:37s\n",
            "epoch 25 | loss: 0.59766 |  0:00:39s\n",
            "epoch 26 | loss: 0.60644 |  0:00:40s\n",
            "epoch 27 | loss: 0.58705 |  0:00:41s\n",
            "epoch 28 | loss: 0.60873 |  0:00:42s\n",
            "epoch 29 | loss: 0.58317 |  0:00:44s\n",
            "epoch 30 | loss: 0.62072 |  0:00:46s\n",
            "epoch 31 | loss: 0.67989 |  0:00:48s\n",
            "epoch 32 | loss: 0.64403 |  0:00:49s\n",
            "epoch 33 | loss: 0.64398 |  0:00:50s\n",
            "epoch 34 | loss: 0.5957  |  0:00:52s\n",
            "epoch 35 | loss: 0.59271 |  0:00:53s\n",
            "epoch 36 | loss: 0.55688 |  0:00:54s\n",
            "epoch 37 | loss: 0.58595 |  0:00:56s\n",
            "epoch 38 | loss: 0.62882 |  0:00:57s\n",
            "epoch 39 | loss: 0.62063 |  0:00:59s\n",
            "epoch 40 | loss: 0.57474 |  0:01:01s\n",
            "epoch 41 | loss: 0.56027 |  0:01:03s\n",
            "epoch 42 | loss: 0.67804 |  0:01:04s\n",
            "epoch 43 | loss: 0.57976 |  0:01:05s\n",
            "epoch 44 | loss: 0.58026 |  0:01:07s\n",
            "epoch 45 | loss: 0.5867  |  0:01:08s\n",
            "epoch 46 | loss: 0.55908 |  0:01:09s\n",
            "epoch 47 | loss: 0.55065 |  0:01:11s\n",
            "epoch 48 | loss: 0.60687 |  0:01:12s\n",
            "epoch 49 | loss: 0.60629 |  0:01:14s\n",
            "epoch 50 | loss: 0.54058 |  0:01:16s\n",
            "epoch 51 | loss: 0.52936 |  0:01:17s\n",
            "epoch 52 | loss: 0.56048 |  0:01:18s\n",
            "epoch 53 | loss: 0.53706 |  0:01:20s\n",
            "epoch 54 | loss: 0.55453 |  0:01:21s\n",
            "epoch 55 | loss: 0.55725 |  0:01:22s\n",
            "epoch 56 | loss: 0.64296 |  0:01:24s\n",
            "epoch 57 | loss: 0.59994 |  0:01:25s\n",
            "epoch 58 | loss: 0.55349 |  0:01:27s\n",
            "epoch 59 | loss: 0.53548 |  0:01:29s\n",
            "epoch 60 | loss: 0.52357 |  0:01:31s\n",
            "epoch 61 | loss: 0.57793 |  0:01:32s\n",
            "epoch 62 | loss: 0.61623 |  0:01:33s\n",
            "epoch 63 | loss: 0.53642 |  0:01:34s\n",
            "epoch 64 | loss: 0.55561 |  0:01:36s\n",
            "epoch 65 | loss: 0.53203 |  0:01:37s\n",
            "epoch 66 | loss: 0.55411 |  0:01:39s\n",
            "epoch 67 | loss: 0.5434  |  0:01:40s\n",
            "epoch 68 | loss: 0.55851 |  0:01:42s\n",
            "epoch 69 | loss: 0.55516 |  0:01:44s\n",
            "epoch 70 | loss: 0.55814 |  0:01:45s\n",
            "epoch 71 | loss: 0.55275 |  0:01:46s\n",
            "epoch 72 | loss: 0.51955 |  0:01:48s\n",
            "epoch 73 | loss: 0.52477 |  0:01:49s\n",
            "epoch 74 | loss: 0.52504 |  0:01:50s\n",
            "epoch 75 | loss: 0.51676 |  0:01:52s\n",
            "epoch 76 | loss: 0.55027 |  0:01:53s\n",
            "epoch 77 | loss: 0.54666 |  0:01:55s\n",
            "epoch 78 | loss: 0.59764 |  0:01:57s\n",
            "epoch 79 | loss: 0.55522 |  0:01:58s\n",
            "epoch 80 | loss: 0.54713 |  0:02:00s\n",
            "epoch 81 | loss: 0.55336 |  0:02:01s\n",
            "epoch 82 | loss: 0.56817 |  0:02:02s\n",
            "epoch 83 | loss: 0.53664 |  0:02:04s\n",
            "epoch 84 | loss: 0.55461 |  0:02:05s\n",
            "epoch 85 | loss: 0.53895 |  0:02:06s\n",
            "epoch 86 | loss: 0.54546 |  0:02:08s\n",
            "epoch 87 | loss: 0.56957 |  0:02:10s\n",
            "epoch 88 | loss: 0.53923 |  0:02:12s\n",
            "epoch 89 | loss: 0.53102 |  0:02:13s\n",
            "epoch 90 | loss: 0.51412 |  0:02:14s\n",
            "epoch 91 | loss: 0.52662 |  0:02:16s\n",
            "epoch 92 | loss: 0.53408 |  0:02:17s\n",
            "epoch 93 | loss: 0.55569 |  0:02:18s\n",
            "epoch 94 | loss: 0.52112 |  0:02:20s\n",
            "epoch 95 | loss: 0.52459 |  0:02:21s\n",
            "epoch 96 | loss: 0.54226 |  0:02:23s\n",
            "epoch 97 | loss: 0.53632 |  0:02:25s\n",
            "epoch 98 | loss: 0.5557  |  0:02:27s\n",
            "epoch 99 | loss: 0.54809 |  0:02:28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 13.28439|  0:00:01s\n",
            "epoch 1  | loss: 2.22382 |  0:00:02s\n",
            "epoch 2  | loss: 1.70198 |  0:00:03s\n",
            "epoch 3  | loss: 1.54081 |  0:00:05s\n",
            "epoch 4  | loss: 1.47437 |  0:00:06s\n",
            "epoch 5  | loss: 1.4811  |  0:00:08s\n",
            "epoch 6  | loss: 1.41814 |  0:00:10s\n",
            "epoch 7  | loss: 1.40805 |  0:00:11s\n",
            "epoch 8  | loss: 1.37169 |  0:00:13s\n",
            "epoch 9  | loss: 1.30751 |  0:00:14s\n",
            "epoch 10 | loss: 1.21715 |  0:00:16s\n",
            "epoch 11 | loss: 1.22586 |  0:00:17s\n",
            "epoch 12 | loss: 1.21478 |  0:00:18s\n",
            "epoch 13 | loss: 1.21143 |  0:00:20s\n",
            "epoch 14 | loss: 1.1964  |  0:00:21s\n",
            "epoch 15 | loss: 1.24911 |  0:00:23s\n",
            "epoch 16 | loss: 1.23852 |  0:00:25s\n",
            "epoch 17 | loss: 1.17066 |  0:00:26s\n",
            "epoch 18 | loss: 1.14272 |  0:00:27s\n",
            "epoch 19 | loss: 1.1723  |  0:00:29s\n",
            "epoch 20 | loss: 1.18608 |  0:00:30s\n",
            "epoch 21 | loss: 1.199   |  0:00:31s\n",
            "epoch 22 | loss: 1.21681 |  0:00:33s\n",
            "epoch 23 | loss: 1.17776 |  0:00:34s\n",
            "epoch 24 | loss: 1.16638 |  0:00:36s\n",
            "epoch 25 | loss: 1.14298 |  0:00:38s\n",
            "epoch 26 | loss: 1.1537  |  0:00:39s\n",
            "epoch 27 | loss: 1.16079 |  0:00:41s\n",
            "epoch 28 | loss: 1.17484 |  0:00:42s\n",
            "epoch 29 | loss: 1.19945 |  0:00:43s\n",
            "epoch 30 | loss: 1.17458 |  0:00:45s\n",
            "epoch 31 | loss: 1.17639 |  0:00:46s\n",
            "epoch 32 | loss: 1.17258 |  0:00:47s\n",
            "epoch 33 | loss: 1.12948 |  0:00:49s\n",
            "epoch 34 | loss: 1.14287 |  0:00:51s\n",
            "epoch 35 | loss: 1.18424 |  0:00:53s\n",
            "epoch 36 | loss: 1.1619  |  0:00:54s\n",
            "epoch 37 | loss: 1.14855 |  0:00:55s\n",
            "epoch 38 | loss: 1.17973 |  0:00:56s\n",
            "epoch 39 | loss: 1.13548 |  0:00:58s\n",
            "epoch 40 | loss: 1.13899 |  0:00:59s\n",
            "epoch 41 | loss: 1.15669 |  0:01:00s\n",
            "epoch 42 | loss: 1.1558  |  0:01:02s\n",
            "epoch 43 | loss: 1.13898 |  0:01:04s\n",
            "epoch 44 | loss: 1.14285 |  0:01:06s\n",
            "epoch 45 | loss: 1.15866 |  0:01:07s\n",
            "epoch 46 | loss: 1.13706 |  0:01:09s\n",
            "epoch 47 | loss: 1.12464 |  0:01:10s\n",
            "epoch 48 | loss: 1.20327 |  0:01:11s\n",
            "epoch 49 | loss: 1.17508 |  0:01:13s\n",
            "epoch 50 | loss: 1.19338 |  0:01:14s\n",
            "epoch 51 | loss: 1.19784 |  0:01:15s\n",
            "epoch 52 | loss: 1.13006 |  0:01:17s\n",
            "epoch 53 | loss: 1.17229 |  0:01:19s\n",
            "epoch 54 | loss: 1.20364 |  0:01:20s\n",
            "epoch 55 | loss: 1.15673 |  0:01:22s\n",
            "epoch 56 | loss: 1.15482 |  0:01:23s\n",
            "epoch 57 | loss: 1.17067 |  0:01:24s\n",
            "epoch 58 | loss: 1.18448 |  0:01:26s\n",
            "epoch 59 | loss: 1.17637 |  0:01:27s\n",
            "epoch 60 | loss: 1.18294 |  0:01:28s\n",
            "epoch 61 | loss: 1.19102 |  0:01:30s\n",
            "epoch 62 | loss: 1.17388 |  0:01:31s\n",
            "epoch 63 | loss: 1.15555 |  0:01:33s\n",
            "epoch 64 | loss: 1.15949 |  0:01:35s\n",
            "epoch 65 | loss: 1.1593  |  0:01:36s\n",
            "epoch 66 | loss: 1.15494 |  0:01:38s\n",
            "epoch 67 | loss: 1.14702 |  0:01:39s\n",
            "epoch 68 | loss: 1.13356 |  0:01:40s\n",
            "epoch 69 | loss: 1.14195 |  0:01:42s\n",
            "epoch 70 | loss: 1.12847 |  0:01:43s\n",
            "epoch 71 | loss: 1.09315 |  0:01:44s\n",
            "epoch 72 | loss: 1.11591 |  0:01:46s\n",
            "epoch 73 | loss: 1.16784 |  0:01:48s\n",
            "epoch 74 | loss: 1.19315 |  0:01:49s\n",
            "epoch 75 | loss: 1.31455 |  0:01:51s\n",
            "epoch 76 | loss: 1.22807 |  0:01:52s\n",
            "epoch 77 | loss: 1.16661 |  0:01:53s\n",
            "epoch 78 | loss: 1.17209 |  0:01:55s\n",
            "epoch 79 | loss: 1.15782 |  0:01:56s\n",
            "epoch 80 | loss: 1.1816  |  0:01:57s\n",
            "epoch 81 | loss: 1.19206 |  0:01:59s\n",
            "epoch 82 | loss: 1.15593 |  0:02:01s\n",
            "epoch 83 | loss: 1.15732 |  0:02:03s\n",
            "epoch 84 | loss: 1.16049 |  0:02:04s\n",
            "epoch 85 | loss: 1.13833 |  0:02:05s\n",
            "epoch 86 | loss: 1.1272  |  0:02:07s\n",
            "epoch 87 | loss: 1.1387  |  0:02:08s\n",
            "epoch 88 | loss: 1.15206 |  0:02:09s\n",
            "epoch 89 | loss: 1.1478  |  0:02:11s\n",
            "epoch 90 | loss: 1.18102 |  0:02:12s\n",
            "epoch 91 | loss: 1.12859 |  0:02:14s\n",
            "epoch 92 | loss: 1.12181 |  0:02:16s\n",
            "epoch 93 | loss: 1.11803 |  0:02:17s\n",
            "epoch 94 | loss: 1.12496 |  0:02:19s\n",
            "epoch 95 | loss: 1.1848  |  0:02:20s\n",
            "epoch 96 | loss: 1.13072 |  0:02:21s\n",
            "epoch 97 | loss: 1.12246 |  0:02:22s\n",
            "epoch 98 | loss: 1.16278 |  0:02:24s\n",
            "epoch 99 | loss: 1.12588 |  0:02:25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 8.83607 |  0:00:02s\n",
            "epoch 1  | loss: 1.52568 |  0:00:03s\n",
            "epoch 2  | loss: 1.10878 |  0:00:05s\n",
            "epoch 3  | loss: 0.93338 |  0:00:06s\n",
            "epoch 4  | loss: 0.94704 |  0:00:07s\n",
            "epoch 5  | loss: 0.83741 |  0:00:09s\n",
            "epoch 6  | loss: 0.886   |  0:00:10s\n",
            "epoch 7  | loss: 0.83236 |  0:00:11s\n",
            "epoch 8  | loss: 0.77661 |  0:00:13s\n",
            "epoch 9  | loss: 0.8405  |  0:00:15s\n",
            "epoch 10 | loss: 0.80662 |  0:00:17s\n",
            "epoch 11 | loss: 0.9006  |  0:00:18s\n",
            "epoch 12 | loss: 0.75174 |  0:00:19s\n",
            "epoch 13 | loss: 0.70734 |  0:00:21s\n",
            "epoch 14 | loss: 0.75234 |  0:00:22s\n",
            "epoch 15 | loss: 0.74637 |  0:00:23s\n",
            "epoch 16 | loss: 0.70171 |  0:00:25s\n",
            "epoch 17 | loss: 0.71529 |  0:00:26s\n",
            "epoch 18 | loss: 0.84132 |  0:00:28s\n",
            "epoch 19 | loss: 0.77847 |  0:00:30s\n",
            "epoch 20 | loss: 0.73983 |  0:00:32s\n",
            "epoch 21 | loss: 0.7165  |  0:00:33s\n",
            "epoch 22 | loss: 0.69765 |  0:00:34s\n",
            "epoch 23 | loss: 0.73845 |  0:00:36s\n",
            "epoch 24 | loss: 0.7361  |  0:00:37s\n",
            "epoch 25 | loss: 0.65314 |  0:00:38s\n",
            "epoch 26 | loss: 0.65979 |  0:00:40s\n",
            "epoch 27 | loss: 0.64666 |  0:00:41s\n",
            "epoch 28 | loss: 0.65681 |  0:00:43s\n",
            "epoch 29 | loss: 0.64906 |  0:00:45s\n",
            "epoch 30 | loss: 0.68376 |  0:00:47s\n",
            "epoch 31 | loss: 0.70195 |  0:00:48s\n",
            "epoch 32 | loss: 0.63433 |  0:00:49s\n",
            "epoch 33 | loss: 0.64172 |  0:00:51s\n",
            "epoch 34 | loss: 0.64488 |  0:00:52s\n",
            "epoch 35 | loss: 0.63371 |  0:00:54s\n",
            "epoch 36 | loss: 0.64029 |  0:00:55s\n",
            "epoch 37 | loss: 0.65788 |  0:00:57s\n",
            "epoch 38 | loss: 0.62855 |  0:00:59s\n",
            "epoch 39 | loss: 0.65375 |  0:01:00s\n",
            "epoch 40 | loss: 0.6254  |  0:01:02s\n",
            "epoch 41 | loss: 0.75749 |  0:01:03s\n",
            "epoch 42 | loss: 0.67505 |  0:01:04s\n",
            "epoch 43 | loss: 0.72368 |  0:01:06s\n",
            "epoch 44 | loss: 0.68325 |  0:01:07s\n",
            "epoch 45 | loss: 0.63606 |  0:01:08s\n",
            "epoch 46 | loss: 0.63313 |  0:01:10s\n",
            "epoch 47 | loss: 0.65872 |  0:01:12s\n",
            "epoch 48 | loss: 0.63842 |  0:01:14s\n",
            "epoch 49 | loss: 0.69462 |  0:01:15s\n",
            "epoch 50 | loss: 0.67293 |  0:01:16s\n",
            "epoch 51 | loss: 0.67209 |  0:01:18s\n",
            "epoch 52 | loss: 0.68299 |  0:01:19s\n",
            "epoch 53 | loss: 0.66332 |  0:01:20s\n",
            "epoch 54 | loss: 0.65542 |  0:01:22s\n",
            "epoch 55 | loss: 0.60466 |  0:01:23s\n",
            "epoch 56 | loss: 0.62848 |  0:01:25s\n",
            "epoch 57 | loss: 0.66275 |  0:01:27s\n",
            "epoch 58 | loss: 0.67084 |  0:01:28s\n",
            "epoch 59 | loss: 0.66663 |  0:01:30s\n",
            "epoch 60 | loss: 0.61082 |  0:01:31s\n",
            "epoch 61 | loss: 0.60252 |  0:01:32s\n",
            "epoch 62 | loss: 0.62914 |  0:01:34s\n",
            "epoch 63 | loss: 0.69317 |  0:01:35s\n",
            "epoch 64 | loss: 0.59229 |  0:01:36s\n",
            "epoch 65 | loss: 0.61309 |  0:01:38s\n",
            "epoch 66 | loss: 0.61866 |  0:01:40s\n",
            "epoch 67 | loss: 0.60253 |  0:01:42s\n",
            "epoch 68 | loss: 0.60422 |  0:01:43s\n",
            "epoch 69 | loss: 0.6912  |  0:01:44s\n",
            "epoch 70 | loss: 0.70412 |  0:01:46s\n",
            "epoch 71 | loss: 0.71661 |  0:01:47s\n",
            "epoch 72 | loss: 0.62429 |  0:01:48s\n",
            "epoch 73 | loss: 0.63658 |  0:01:50s\n",
            "epoch 74 | loss: 0.65889 |  0:01:51s\n",
            "epoch 75 | loss: 0.61864 |  0:01:53s\n",
            "epoch 76 | loss: 0.63528 |  0:01:55s\n",
            "epoch 77 | loss: 0.66962 |  0:01:57s\n",
            "epoch 78 | loss: 0.60211 |  0:01:58s\n",
            "epoch 79 | loss: 0.58844 |  0:01:59s\n",
            "epoch 80 | loss: 0.596   |  0:02:01s\n",
            "epoch 81 | loss: 0.6215  |  0:02:02s\n",
            "epoch 82 | loss: 0.59977 |  0:02:03s\n",
            "epoch 83 | loss: 0.58905 |  0:02:05s\n",
            "epoch 84 | loss: 0.60432 |  0:02:07s\n",
            "epoch 85 | loss: 0.61218 |  0:02:09s\n",
            "epoch 86 | loss: 0.58977 |  0:02:10s\n",
            "epoch 87 | loss: 0.60486 |  0:02:12s\n",
            "epoch 88 | loss: 0.63804 |  0:02:13s\n",
            "epoch 89 | loss: 0.59973 |  0:02:14s\n",
            "epoch 90 | loss: 0.64197 |  0:02:16s\n",
            "epoch 91 | loss: 0.63956 |  0:02:17s\n",
            "epoch 92 | loss: 0.64655 |  0:02:18s\n",
            "epoch 93 | loss: 0.62585 |  0:02:20s\n",
            "epoch 94 | loss: 0.65192 |  0:02:22s\n",
            "epoch 95 | loss: 0.58328 |  0:02:24s\n",
            "epoch 96 | loss: 0.57258 |  0:02:25s\n",
            "epoch 97 | loss: 0.5748  |  0:02:26s\n",
            "epoch 98 | loss: 0.58379 |  0:02:28s\n",
            "epoch 99 | loss: 0.6029  |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.0326 |  0:00:01s\n",
            "epoch 1  | loss: 1.72017 |  0:00:02s\n",
            "epoch 2  | loss: 1.32629 |  0:00:04s\n",
            "epoch 3  | loss: 1.30469 |  0:00:06s\n",
            "epoch 4  | loss: 1.23503 |  0:00:08s\n",
            "epoch 5  | loss: 1.21933 |  0:00:09s\n",
            "epoch 6  | loss: 1.14931 |  0:00:10s\n",
            "epoch 7  | loss: 1.09364 |  0:00:12s\n",
            "epoch 8  | loss: 1.14789 |  0:00:13s\n",
            "epoch 9  | loss: 1.08822 |  0:00:14s\n",
            "epoch 10 | loss: 1.04644 |  0:00:16s\n",
            "epoch 11 | loss: 1.09456 |  0:00:17s\n",
            "epoch 12 | loss: 1.03934 |  0:00:19s\n",
            "epoch 13 | loss: 1.03824 |  0:00:21s\n",
            "epoch 14 | loss: 1.0376  |  0:00:22s\n",
            "epoch 15 | loss: 1.0333  |  0:00:24s\n",
            "epoch 16 | loss: 1.05539 |  0:00:25s\n",
            "epoch 17 | loss: 1.02702 |  0:00:26s\n",
            "epoch 18 | loss: 1.03001 |  0:00:28s\n",
            "epoch 19 | loss: 1.04977 |  0:00:29s\n",
            "epoch 20 | loss: 0.98166 |  0:00:31s\n",
            "epoch 21 | loss: 0.98322 |  0:00:33s\n",
            "epoch 22 | loss: 0.96331 |  0:00:35s\n",
            "epoch 23 | loss: 0.98546 |  0:00:36s\n",
            "epoch 24 | loss: 1.00123 |  0:00:37s\n",
            "epoch 25 | loss: 1.06746 |  0:00:39s\n",
            "epoch 26 | loss: 0.99581 |  0:00:40s\n",
            "epoch 27 | loss: 1.06037 |  0:00:42s\n",
            "epoch 28 | loss: 1.01302 |  0:00:43s\n",
            "epoch 29 | loss: 1.01307 |  0:00:44s\n",
            "epoch 30 | loss: 1.03441 |  0:00:46s\n",
            "epoch 31 | loss: 0.96865 |  0:00:48s\n",
            "epoch 32 | loss: 0.94495 |  0:00:50s\n",
            "epoch 33 | loss: 0.95885 |  0:00:51s\n",
            "epoch 34 | loss: 0.97795 |  0:00:52s\n",
            "epoch 35 | loss: 0.98982 |  0:00:54s\n",
            "epoch 36 | loss: 1.00853 |  0:00:55s\n",
            "epoch 37 | loss: 0.96821 |  0:00:56s\n",
            "epoch 38 | loss: 0.95662 |  0:00:58s\n",
            "epoch 39 | loss: 0.98566 |  0:00:59s\n",
            "epoch 40 | loss: 0.95478 |  0:01:02s\n",
            "epoch 41 | loss: 0.952   |  0:01:03s\n",
            "epoch 42 | loss: 0.96194 |  0:01:04s\n",
            "epoch 43 | loss: 0.9486  |  0:01:06s\n",
            "epoch 44 | loss: 1.05803 |  0:01:07s\n",
            "epoch 45 | loss: 1.02691 |  0:01:08s\n",
            "epoch 46 | loss: 0.98465 |  0:01:10s\n",
            "epoch 47 | loss: 0.98998 |  0:01:11s\n",
            "epoch 48 | loss: 0.94716 |  0:01:12s\n",
            "epoch 49 | loss: 0.96099 |  0:01:14s\n",
            "epoch 50 | loss: 0.98236 |  0:01:16s\n",
            "epoch 51 | loss: 0.98683 |  0:01:18s\n",
            "epoch 52 | loss: 0.93666 |  0:01:19s\n",
            "epoch 53 | loss: 1.07887 |  0:01:20s\n",
            "epoch 54 | loss: 1.05593 |  0:01:22s\n",
            "epoch 55 | loss: 1.01226 |  0:01:23s\n",
            "epoch 56 | loss: 0.96027 |  0:01:24s\n",
            "epoch 57 | loss: 0.97346 |  0:01:26s\n",
            "epoch 58 | loss: 0.9482  |  0:01:28s\n",
            "epoch 59 | loss: 0.95851 |  0:01:30s\n",
            "epoch 60 | loss: 0.9364  |  0:01:31s\n",
            "epoch 61 | loss: 0.9326  |  0:01:32s\n",
            "epoch 62 | loss: 0.95038 |  0:01:34s\n",
            "epoch 63 | loss: 1.02924 |  0:01:35s\n",
            "epoch 64 | loss: 0.95559 |  0:01:36s\n",
            "epoch 65 | loss: 0.97522 |  0:01:38s\n",
            "epoch 66 | loss: 0.94044 |  0:01:39s\n",
            "epoch 67 | loss: 0.92949 |  0:01:41s\n",
            "epoch 68 | loss: 0.97945 |  0:01:42s\n",
            "epoch 69 | loss: 0.93738 |  0:01:44s\n",
            "epoch 70 | loss: 1.03594 |  0:01:46s\n",
            "epoch 71 | loss: 0.96491 |  0:01:47s\n",
            "epoch 72 | loss: 0.94677 |  0:01:48s\n",
            "epoch 73 | loss: 0.94708 |  0:01:50s\n",
            "epoch 74 | loss: 0.96768 |  0:01:51s\n",
            "epoch 75 | loss: 0.99051 |  0:01:52s\n",
            "epoch 76 | loss: 0.91656 |  0:01:54s\n",
            "epoch 77 | loss: 0.92397 |  0:01:56s\n",
            "epoch 78 | loss: 0.92979 |  0:01:58s\n",
            "epoch 79 | loss: 0.93219 |  0:01:59s\n",
            "epoch 80 | loss: 0.97454 |  0:02:00s\n",
            "epoch 81 | loss: 0.92165 |  0:02:02s\n",
            "epoch 82 | loss: 1.00334 |  0:02:03s\n",
            "epoch 83 | loss: 1.00733 |  0:02:05s\n",
            "epoch 84 | loss: 0.99477 |  0:02:06s\n",
            "epoch 85 | loss: 0.93056 |  0:02:07s\n",
            "epoch 86 | loss: 0.93123 |  0:02:09s\n",
            "epoch 87 | loss: 0.92799 |  0:02:11s\n",
            "epoch 88 | loss: 0.91145 |  0:02:13s\n",
            "epoch 89 | loss: 0.89534 |  0:02:14s\n",
            "epoch 90 | loss: 0.91654 |  0:02:15s\n",
            "epoch 91 | loss: 0.92147 |  0:02:16s\n",
            "epoch 92 | loss: 0.95095 |  0:02:18s\n",
            "epoch 93 | loss: 0.92027 |  0:02:19s\n",
            "epoch 94 | loss: 0.96234 |  0:02:20s\n",
            "epoch 95 | loss: 0.94237 |  0:02:22s\n",
            "epoch 96 | loss: 0.90463 |  0:02:24s\n",
            "epoch 97 | loss: 0.90892 |  0:02:26s\n",
            "epoch 98 | loss: 0.90824 |  0:02:27s\n",
            "epoch 99 | loss: 0.91255 |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 15.46394|  0:00:01s\n",
            "epoch 1  | loss: 1.59632 |  0:00:02s\n",
            "epoch 2  | loss: 1.03749 |  0:00:04s\n",
            "epoch 3  | loss: 0.88463 |  0:00:05s\n",
            "epoch 4  | loss: 0.85835 |  0:00:07s\n",
            "epoch 5  | loss: 0.76619 |  0:00:09s\n",
            "epoch 6  | loss: 0.76795 |  0:00:10s\n",
            "epoch 7  | loss: 0.75616 |  0:00:12s\n",
            "epoch 8  | loss: 0.73658 |  0:00:13s\n",
            "epoch 9  | loss: 0.74332 |  0:00:14s\n",
            "epoch 10 | loss: 0.7553  |  0:00:16s\n",
            "epoch 11 | loss: 0.72942 |  0:00:17s\n",
            "epoch 12 | loss: 0.72206 |  0:00:18s\n",
            "epoch 13 | loss: 0.69239 |  0:00:20s\n",
            "epoch 14 | loss: 0.67192 |  0:00:22s\n",
            "epoch 15 | loss: 0.66725 |  0:00:24s\n",
            "epoch 16 | loss: 0.65077 |  0:00:25s\n",
            "epoch 17 | loss: 0.66555 |  0:00:27s\n",
            "epoch 18 | loss: 0.68892 |  0:00:28s\n",
            "epoch 19 | loss: 0.68586 |  0:00:29s\n",
            "epoch 20 | loss: 0.76494 |  0:00:31s\n",
            "epoch 21 | loss: 0.70278 |  0:00:32s\n",
            "epoch 22 | loss: 0.65689 |  0:00:34s\n",
            "epoch 23 | loss: 0.63942 |  0:00:35s\n",
            "epoch 24 | loss: 0.63126 |  0:00:37s\n",
            "epoch 25 | loss: 0.66375 |  0:00:39s\n",
            "epoch 26 | loss: 0.65329 |  0:00:40s\n",
            "epoch 27 | loss: 0.63915 |  0:00:41s\n",
            "epoch 28 | loss: 0.61252 |  0:00:43s\n",
            "epoch 29 | loss: 0.59407 |  0:00:44s\n",
            "epoch 30 | loss: 0.59856 |  0:00:45s\n",
            "epoch 31 | loss: 0.63382 |  0:00:47s\n",
            "epoch 32 | loss: 0.59687 |  0:00:48s\n",
            "epoch 33 | loss: 0.58238 |  0:00:50s\n",
            "epoch 34 | loss: 0.59094 |  0:00:52s\n",
            "epoch 35 | loss: 0.54919 |  0:00:54s\n",
            "epoch 36 | loss: 0.56435 |  0:00:55s\n",
            "epoch 37 | loss: 0.58746 |  0:00:56s\n",
            "epoch 38 | loss: 0.60872 |  0:00:58s\n",
            "epoch 39 | loss: 0.57632 |  0:00:59s\n",
            "epoch 40 | loss: 0.57452 |  0:01:00s\n",
            "epoch 41 | loss: 0.54508 |  0:01:02s\n",
            "epoch 42 | loss: 0.59273 |  0:01:03s\n",
            "epoch 43 | loss: 0.61193 |  0:01:05s\n",
            "epoch 44 | loss: 0.55438 |  0:01:07s\n",
            "epoch 45 | loss: 0.56238 |  0:01:08s\n",
            "epoch 46 | loss: 0.56788 |  0:01:10s\n",
            "epoch 47 | loss: 0.55432 |  0:01:11s\n",
            "epoch 48 | loss: 0.55936 |  0:01:12s\n",
            "epoch 49 | loss: 0.54419 |  0:01:14s\n",
            "epoch 50 | loss: 0.54525 |  0:01:15s\n",
            "epoch 51 | loss: 0.54874 |  0:01:16s\n",
            "epoch 52 | loss: 0.5877  |  0:01:18s\n",
            "epoch 53 | loss: 0.59023 |  0:01:20s\n",
            "epoch 54 | loss: 0.5486  |  0:01:22s\n",
            "epoch 55 | loss: 0.58176 |  0:01:23s\n",
            "epoch 56 | loss: 0.5689  |  0:01:24s\n",
            "epoch 57 | loss: 0.56337 |  0:01:26s\n",
            "epoch 58 | loss: 0.55511 |  0:01:27s\n",
            "epoch 59 | loss: 0.55157 |  0:01:29s\n",
            "epoch 60 | loss: 0.53414 |  0:01:30s\n",
            "epoch 61 | loss: 0.54242 |  0:01:32s\n",
            "epoch 62 | loss: 0.56617 |  0:01:34s\n",
            "epoch 63 | loss: 0.53441 |  0:01:35s\n",
            "epoch 64 | loss: 0.54302 |  0:01:37s\n",
            "epoch 65 | loss: 0.57952 |  0:01:38s\n",
            "epoch 66 | loss: 0.59192 |  0:01:40s\n",
            "epoch 67 | loss: 0.55074 |  0:01:41s\n",
            "epoch 68 | loss: 0.529   |  0:01:43s\n",
            "epoch 69 | loss: 0.60542 |  0:01:44s\n",
            "epoch 70 | loss: 0.56876 |  0:01:46s\n",
            "epoch 71 | loss: 0.56824 |  0:01:48s\n",
            "epoch 72 | loss: 0.54782 |  0:01:49s\n",
            "epoch 73 | loss: 0.53477 |  0:01:51s\n",
            "epoch 74 | loss: 0.53162 |  0:01:52s\n",
            "epoch 75 | loss: 0.52672 |  0:01:53s\n",
            "epoch 76 | loss: 0.54582 |  0:01:55s\n",
            "epoch 77 | loss: 0.55162 |  0:01:56s\n",
            "epoch 78 | loss: 0.58045 |  0:01:57s\n",
            "epoch 79 | loss: 0.56607 |  0:01:59s\n",
            "epoch 80 | loss: 0.54635 |  0:02:01s\n",
            "epoch 81 | loss: 0.55286 |  0:02:03s\n",
            "epoch 82 | loss: 0.52796 |  0:02:04s\n",
            "epoch 83 | loss: 0.53    |  0:02:06s\n",
            "epoch 84 | loss: 0.57438 |  0:02:07s\n",
            "epoch 85 | loss: 0.52725 |  0:02:08s\n",
            "epoch 86 | loss: 0.53148 |  0:02:10s\n",
            "epoch 87 | loss: 0.52113 |  0:02:11s\n",
            "epoch 88 | loss: 0.57014 |  0:02:12s\n",
            "epoch 89 | loss: 0.58462 |  0:02:14s\n",
            "epoch 90 | loss: 0.55504 |  0:02:16s\n",
            "epoch 91 | loss: 0.59478 |  0:02:18s\n",
            "epoch 92 | loss: 0.55861 |  0:02:19s\n",
            "epoch 93 | loss: 0.56031 |  0:02:20s\n",
            "epoch 94 | loss: 0.54718 |  0:02:22s\n",
            "epoch 95 | loss: 0.51934 |  0:02:23s\n",
            "epoch 96 | loss: 0.53906 |  0:02:24s\n",
            "epoch 97 | loss: 0.54256 |  0:02:26s\n",
            "epoch 98 | loss: 0.58276 |  0:02:27s\n",
            "epoch 99 | loss: 0.55151 |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.26379 |  0:00:01s\n",
            "epoch 1  | loss: 2.11461 |  0:00:02s\n",
            "epoch 2  | loss: 1.86932 |  0:00:04s\n",
            "epoch 3  | loss: 1.68757 |  0:00:05s\n",
            "epoch 4  | loss: 1.80249 |  0:00:06s\n",
            "epoch 5  | loss: 1.51857 |  0:00:08s\n",
            "epoch 6  | loss: 1.44083 |  0:00:09s\n",
            "epoch 7  | loss: 1.43507 |  0:00:11s\n",
            "epoch 8  | loss: 1.43983 |  0:00:13s\n",
            "epoch 9  | loss: 1.42224 |  0:00:14s\n",
            "epoch 10 | loss: 1.40925 |  0:00:16s\n",
            "epoch 11 | loss: 1.41749 |  0:00:17s\n",
            "epoch 12 | loss: 1.40983 |  0:00:18s\n",
            "epoch 13 | loss: 1.38103 |  0:00:20s\n",
            "epoch 14 | loss: 1.41323 |  0:00:21s\n",
            "epoch 15 | loss: 1.47443 |  0:00:22s\n",
            "epoch 16 | loss: 1.37171 |  0:00:24s\n",
            "epoch 17 | loss: 1.37459 |  0:00:26s\n",
            "epoch 18 | loss: 1.47202 |  0:00:28s\n",
            "epoch 19 | loss: 1.39054 |  0:00:29s\n",
            "epoch 20 | loss: 1.3107  |  0:00:30s\n",
            "epoch 21 | loss: 1.36902 |  0:00:32s\n",
            "epoch 22 | loss: 1.35899 |  0:00:33s\n",
            "epoch 23 | loss: 1.36131 |  0:00:34s\n",
            "epoch 24 | loss: 1.34423 |  0:00:36s\n",
            "epoch 25 | loss: 1.29062 |  0:00:37s\n",
            "epoch 26 | loss: 1.33801 |  0:00:39s\n",
            "epoch 27 | loss: 1.34706 |  0:00:41s\n",
            "epoch 28 | loss: 1.32294 |  0:00:42s\n",
            "epoch 29 | loss: 1.31304 |  0:00:44s\n",
            "epoch 30 | loss: 1.32706 |  0:00:45s\n",
            "epoch 31 | loss: 1.32574 |  0:00:46s\n",
            "epoch 32 | loss: 1.2778  |  0:00:48s\n",
            "epoch 33 | loss: 1.29818 |  0:00:49s\n",
            "epoch 34 | loss: 1.2528  |  0:00:50s\n",
            "epoch 35 | loss: 1.28406 |  0:00:52s\n",
            "epoch 36 | loss: 1.3035  |  0:00:54s\n",
            "epoch 37 | loss: 1.282   |  0:00:56s\n",
            "epoch 38 | loss: 1.29733 |  0:00:57s\n",
            "epoch 39 | loss: 1.30955 |  0:00:58s\n",
            "epoch 40 | loss: 1.23903 |  0:01:00s\n",
            "epoch 41 | loss: 1.22977 |  0:01:01s\n",
            "epoch 42 | loss: 1.20234 |  0:01:03s\n",
            "epoch 43 | loss: 1.24957 |  0:01:04s\n",
            "epoch 44 | loss: 1.23215 |  0:01:05s\n",
            "epoch 45 | loss: 1.23494 |  0:01:07s\n",
            "epoch 46 | loss: 1.31297 |  0:01:09s\n",
            "epoch 47 | loss: 1.25766 |  0:01:11s\n",
            "epoch 48 | loss: 1.24982 |  0:01:12s\n",
            "epoch 49 | loss: 1.26711 |  0:01:13s\n",
            "epoch 50 | loss: 1.24215 |  0:01:15s\n",
            "epoch 51 | loss: 1.19618 |  0:01:16s\n",
            "epoch 52 | loss: 1.20722 |  0:01:17s\n",
            "epoch 53 | loss: 1.19517 |  0:01:19s\n",
            "epoch 54 | loss: 1.17561 |  0:01:21s\n",
            "epoch 55 | loss: 1.21761 |  0:01:22s\n",
            "epoch 56 | loss: 1.28768 |  0:01:24s\n",
            "epoch 57 | loss: 1.22155 |  0:01:26s\n",
            "epoch 58 | loss: 1.19075 |  0:01:27s\n",
            "epoch 59 | loss: 1.21324 |  0:01:28s\n",
            "epoch 60 | loss: 1.27312 |  0:01:29s\n",
            "epoch 61 | loss: 1.29842 |  0:01:31s\n",
            "epoch 62 | loss: 1.17307 |  0:01:32s\n",
            "epoch 63 | loss: 1.18146 |  0:01:34s\n",
            "epoch 64 | loss: 1.19687 |  0:01:36s\n",
            "epoch 65 | loss: 1.19085 |  0:01:37s\n",
            "epoch 66 | loss: 1.21482 |  0:01:39s\n",
            "epoch 67 | loss: 1.20851 |  0:01:40s\n",
            "epoch 68 | loss: 1.21453 |  0:01:41s\n",
            "epoch 69 | loss: 1.16416 |  0:01:43s\n",
            "epoch 70 | loss: 1.17102 |  0:01:44s\n",
            "epoch 71 | loss: 1.18797 |  0:01:45s\n",
            "epoch 72 | loss: 1.18344 |  0:01:47s\n",
            "epoch 73 | loss: 1.21804 |  0:01:49s\n",
            "epoch 74 | loss: 1.22225 |  0:01:51s\n",
            "epoch 75 | loss: 1.21529 |  0:01:52s\n",
            "epoch 76 | loss: 1.28046 |  0:01:54s\n",
            "epoch 77 | loss: 1.31472 |  0:01:55s\n",
            "epoch 78 | loss: 1.26338 |  0:01:56s\n",
            "epoch 79 | loss: 1.22268 |  0:01:58s\n",
            "epoch 80 | loss: 1.20038 |  0:01:59s\n",
            "epoch 81 | loss: 1.25215 |  0:02:00s\n",
            "epoch 82 | loss: 1.19645 |  0:02:02s\n",
            "epoch 83 | loss: 1.24133 |  0:02:04s\n",
            "epoch 84 | loss: 1.21524 |  0:02:06s\n",
            "epoch 85 | loss: 1.19801 |  0:02:07s\n",
            "epoch 86 | loss: 1.14188 |  0:02:08s\n",
            "epoch 87 | loss: 1.15915 |  0:02:10s\n",
            "epoch 88 | loss: 1.1368  |  0:02:11s\n",
            "epoch 89 | loss: 1.14405 |  0:02:12s\n",
            "epoch 90 | loss: 1.12607 |  0:02:14s\n",
            "epoch 91 | loss: 1.17307 |  0:02:15s\n",
            "epoch 92 | loss: 1.142   |  0:02:17s\n",
            "epoch 93 | loss: 1.16608 |  0:02:19s\n",
            "epoch 94 | loss: 1.15255 |  0:02:20s\n",
            "epoch 95 | loss: 1.16607 |  0:02:22s\n",
            "epoch 96 | loss: 1.16654 |  0:02:23s\n",
            "epoch 97 | loss: 1.18136 |  0:02:24s\n",
            "epoch 98 | loss: 1.16232 |  0:02:26s\n",
            "epoch 99 | loss: 1.19625 |  0:02:27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 13.45016|  0:00:02s\n",
            "epoch 1  | loss: 2.74457 |  0:00:04s\n",
            "epoch 2  | loss: 1.57134 |  0:00:06s\n",
            "epoch 3  | loss: 1.27417 |  0:00:08s\n",
            "epoch 4  | loss: 1.16176 |  0:00:10s\n",
            "epoch 5  | loss: 1.14651 |  0:00:11s\n",
            "epoch 6  | loss: 1.04145 |  0:00:13s\n",
            "epoch 7  | loss: 1.14039 |  0:00:16s\n",
            "epoch 8  | loss: 1.02278 |  0:00:18s\n",
            "epoch 9  | loss: 0.99359 |  0:00:20s\n",
            "epoch 10 | loss: 0.95394 |  0:00:22s\n",
            "epoch 11 | loss: 0.98731 |  0:00:23s\n",
            "epoch 12 | loss: 0.87405 |  0:00:25s\n",
            "epoch 13 | loss: 0.92619 |  0:00:27s\n",
            "epoch 14 | loss: 0.85921 |  0:00:29s\n",
            "epoch 15 | loss: 0.99808 |  0:00:31s\n",
            "epoch 16 | loss: 0.92218 |  0:00:33s\n",
            "epoch 17 | loss: 0.88359 |  0:00:35s\n",
            "epoch 18 | loss: 0.86618 |  0:00:37s\n",
            "epoch 19 | loss: 0.8438  |  0:00:39s\n",
            "epoch 20 | loss: 0.86215 |  0:00:40s\n",
            "epoch 21 | loss: 0.83304 |  0:00:42s\n",
            "epoch 22 | loss: 0.81819 |  0:00:44s\n",
            "epoch 23 | loss: 0.8607  |  0:00:47s\n",
            "epoch 24 | loss: 0.87508 |  0:00:48s\n",
            "epoch 25 | loss: 0.84873 |  0:00:50s\n",
            "epoch 26 | loss: 0.9936  |  0:00:52s\n",
            "epoch 27 | loss: 0.86278 |  0:00:54s\n",
            "epoch 28 | loss: 0.90361 |  0:00:56s\n",
            "epoch 29 | loss: 0.84654 |  0:00:58s\n",
            "epoch 30 | loss: 0.85775 |  0:01:00s\n",
            "epoch 31 | loss: 0.83993 |  0:01:02s\n",
            "epoch 32 | loss: 0.82991 |  0:01:04s\n",
            "epoch 33 | loss: 0.80253 |  0:01:05s\n",
            "epoch 34 | loss: 0.80886 |  0:01:07s\n",
            "epoch 35 | loss: 0.79104 |  0:01:09s\n",
            "epoch 36 | loss: 0.79058 |  0:01:11s\n",
            "epoch 37 | loss: 0.89953 |  0:01:14s\n",
            "epoch 38 | loss: 0.91075 |  0:01:15s\n",
            "epoch 39 | loss: 0.95162 |  0:01:17s\n",
            "epoch 40 | loss: 0.95568 |  0:01:19s\n",
            "epoch 41 | loss: 0.83565 |  0:01:21s\n",
            "epoch 42 | loss: 0.83953 |  0:01:23s\n",
            "epoch 43 | loss: 0.88938 |  0:01:25s\n",
            "epoch 44 | loss: 0.8169  |  0:01:27s\n",
            "epoch 45 | loss: 0.80249 |  0:01:29s\n",
            "epoch 46 | loss: 0.8045  |  0:01:31s\n",
            "epoch 47 | loss: 0.76204 |  0:01:33s\n",
            "epoch 48 | loss: 0.78259 |  0:01:34s\n",
            "epoch 49 | loss: 0.80202 |  0:01:36s\n",
            "epoch 50 | loss: 0.8311  |  0:01:38s\n",
            "epoch 51 | loss: 0.87116 |  0:01:40s\n",
            "epoch 52 | loss: 0.82743 |  0:01:43s\n",
            "epoch 53 | loss: 0.83091 |  0:01:44s\n",
            "epoch 54 | loss: 0.93153 |  0:01:46s\n",
            "epoch 55 | loss: 0.88121 |  0:01:48s\n",
            "epoch 56 | loss: 0.81708 |  0:01:50s\n",
            "epoch 57 | loss: 0.82732 |  0:01:51s\n",
            "epoch 58 | loss: 0.83444 |  0:01:54s\n",
            "epoch 59 | loss: 0.8053  |  0:01:56s\n",
            "epoch 60 | loss: 0.78903 |  0:01:58s\n",
            "epoch 61 | loss: 0.75875 |  0:02:00s\n",
            "epoch 62 | loss: 0.75133 |  0:02:01s\n",
            "epoch 63 | loss: 0.7719  |  0:02:03s\n",
            "epoch 64 | loss: 0.82504 |  0:02:05s\n",
            "epoch 65 | loss: 0.84442 |  0:02:07s\n",
            "epoch 66 | loss: 0.81989 |  0:02:10s\n",
            "epoch 67 | loss: 0.82658 |  0:02:11s\n",
            "epoch 68 | loss: 0.8479  |  0:02:13s\n",
            "epoch 69 | loss: 0.83549 |  0:02:15s\n",
            "epoch 70 | loss: 0.7844  |  0:02:17s\n",
            "epoch 71 | loss: 0.80032 |  0:02:19s\n",
            "epoch 72 | loss: 0.7874  |  0:02:21s\n",
            "epoch 73 | loss: 0.80885 |  0:02:23s\n",
            "epoch 74 | loss: 0.78521 |  0:02:25s\n",
            "epoch 75 | loss: 0.79539 |  0:02:27s\n",
            "epoch 76 | loss: 0.79942 |  0:02:29s\n",
            "epoch 77 | loss: 0.79395 |  0:02:30s\n",
            "epoch 78 | loss: 0.79334 |  0:02:32s\n",
            "epoch 79 | loss: 0.79366 |  0:02:34s\n",
            "epoch 80 | loss: 0.78283 |  0:02:36s\n",
            "epoch 81 | loss: 0.79381 |  0:02:38s\n",
            "epoch 82 | loss: 0.77782 |  0:02:40s\n",
            "epoch 83 | loss: 0.79929 |  0:02:42s\n",
            "epoch 84 | loss: 0.76712 |  0:02:44s\n",
            "epoch 85 | loss: 0.76459 |  0:02:45s\n",
            "epoch 86 | loss: 0.76105 |  0:02:47s\n",
            "epoch 87 | loss: 0.79036 |  0:02:50s\n",
            "epoch 88 | loss: 0.77575 |  0:02:52s\n",
            "epoch 89 | loss: 0.75435 |  0:02:54s\n",
            "epoch 90 | loss: 0.74571 |  0:02:56s\n",
            "epoch 91 | loss: 0.76112 |  0:02:57s\n",
            "epoch 92 | loss: 0.7875  |  0:02:59s\n",
            "epoch 93 | loss: 0.77145 |  0:03:01s\n",
            "epoch 94 | loss: 0.76073 |  0:03:04s\n",
            "epoch 95 | loss: 0.76983 |  0:03:06s\n",
            "epoch 96 | loss: 0.77363 |  0:03:07s\n",
            "epoch 97 | loss: 0.80723 |  0:03:09s\n",
            "epoch 98 | loss: 0.75    |  0:03:11s\n",
            "epoch 99 | loss: 0.72453 |  0:03:13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14.82157|  0:00:02s\n",
            "epoch 1  | loss: 2.69254 |  0:00:04s\n",
            "epoch 2  | loss: 1.50264 |  0:00:06s\n",
            "epoch 3  | loss: 1.14584 |  0:00:08s\n",
            "epoch 4  | loss: 1.06259 |  0:00:10s\n",
            "epoch 5  | loss: 1.00566 |  0:00:11s\n",
            "epoch 6  | loss: 0.89772 |  0:00:13s\n",
            "epoch 7  | loss: 0.80336 |  0:00:15s\n",
            "epoch 8  | loss: 0.77235 |  0:00:18s\n",
            "epoch 9  | loss: 0.77045 |  0:00:20s\n",
            "epoch 10 | loss: 0.8258  |  0:00:21s\n",
            "epoch 11 | loss: 0.79164 |  0:00:23s\n",
            "epoch 12 | loss: 0.6979  |  0:00:25s\n",
            "epoch 13 | loss: 0.71524 |  0:00:27s\n",
            "epoch 14 | loss: 0.69836 |  0:00:28s\n",
            "epoch 15 | loss: 0.68194 |  0:00:31s\n",
            "epoch 16 | loss: 0.6992  |  0:00:33s\n",
            "epoch 17 | loss: 0.69726 |  0:00:35s\n",
            "epoch 18 | loss: 0.63816 |  0:00:37s\n",
            "epoch 19 | loss: 0.61998 |  0:00:39s\n",
            "epoch 20 | loss: 0.62124 |  0:00:40s\n",
            "epoch 21 | loss: 0.63837 |  0:00:42s\n",
            "epoch 22 | loss: 0.60783 |  0:00:44s\n",
            "epoch 23 | loss: 0.61607 |  0:00:47s\n",
            "epoch 24 | loss: 0.6543  |  0:00:48s\n",
            "epoch 25 | loss: 0.63912 |  0:00:50s\n",
            "epoch 26 | loss: 0.59587 |  0:00:52s\n",
            "epoch 27 | loss: 0.59157 |  0:00:54s\n",
            "epoch 28 | loss: 0.69127 |  0:00:55s\n",
            "epoch 29 | loss: 0.59247 |  0:00:58s\n",
            "epoch 30 | loss: 0.59126 |  0:01:00s\n",
            "epoch 31 | loss: 0.61736 |  0:01:02s\n",
            "epoch 32 | loss: 0.65603 |  0:01:04s\n",
            "epoch 33 | loss: 0.79381 |  0:01:06s\n",
            "epoch 34 | loss: 0.66911 |  0:01:07s\n",
            "epoch 35 | loss: 0.65368 |  0:01:09s\n",
            "epoch 36 | loss: 0.71214 |  0:01:11s\n",
            "epoch 37 | loss: 0.72614 |  0:01:14s\n",
            "epoch 38 | loss: 0.64761 |  0:01:16s\n",
            "epoch 39 | loss: 0.67334 |  0:01:18s\n",
            "epoch 40 | loss: 0.66419 |  0:01:19s\n",
            "epoch 41 | loss: 0.6994  |  0:01:21s\n",
            "epoch 42 | loss: 0.60762 |  0:01:23s\n",
            "epoch 43 | loss: 0.61043 |  0:01:25s\n",
            "epoch 44 | loss: 0.64476 |  0:01:27s\n",
            "epoch 45 | loss: 0.6049  |  0:01:29s\n",
            "epoch 46 | loss: 0.61822 |  0:01:31s\n",
            "epoch 47 | loss: 0.62589 |  0:01:33s\n",
            "epoch 48 | loss: 0.62191 |  0:01:35s\n",
            "epoch 49 | loss: 0.67337 |  0:01:36s\n",
            "epoch 50 | loss: 0.68669 |  0:01:38s\n",
            "epoch 51 | loss: 0.59768 |  0:01:41s\n",
            "epoch 52 | loss: 0.57779 |  0:01:43s\n",
            "epoch 53 | loss: 0.56973 |  0:01:45s\n",
            "epoch 54 | loss: 0.57853 |  0:01:47s\n",
            "epoch 55 | loss: 0.58179 |  0:01:48s\n",
            "epoch 56 | loss: 0.64088 |  0:01:50s\n",
            "epoch 57 | loss: 0.61703 |  0:01:52s\n",
            "epoch 58 | loss: 0.65246 |  0:01:54s\n",
            "epoch 59 | loss: 0.63229 |  0:01:57s\n",
            "epoch 60 | loss: 0.58449 |  0:01:58s\n",
            "epoch 61 | loss: 0.61251 |  0:02:00s\n",
            "epoch 62 | loss: 0.63614 |  0:02:02s\n",
            "epoch 63 | loss: 0.62166 |  0:02:04s\n",
            "epoch 64 | loss: 0.60003 |  0:02:05s\n",
            "epoch 65 | loss: 0.59656 |  0:02:08s\n",
            "epoch 66 | loss: 0.60602 |  0:02:10s\n",
            "epoch 67 | loss: 0.65044 |  0:02:12s\n",
            "epoch 68 | loss: 0.61537 |  0:02:14s\n",
            "epoch 69 | loss: 0.60305 |  0:02:15s\n",
            "epoch 70 | loss: 0.60835 |  0:02:17s\n",
            "epoch 71 | loss: 0.60115 |  0:02:19s\n",
            "epoch 72 | loss: 0.58322 |  0:02:21s\n",
            "epoch 73 | loss: 0.60804 |  0:02:24s\n",
            "epoch 74 | loss: 0.56471 |  0:02:25s\n",
            "epoch 75 | loss: 0.5631  |  0:02:27s\n",
            "epoch 76 | loss: 0.57369 |  0:02:29s\n",
            "epoch 77 | loss: 0.57388 |  0:02:31s\n",
            "epoch 78 | loss: 0.58247 |  0:02:33s\n",
            "epoch 79 | loss: 0.54506 |  0:02:35s\n",
            "epoch 80 | loss: 0.5522  |  0:02:37s\n",
            "epoch 81 | loss: 0.56669 |  0:02:39s\n",
            "epoch 82 | loss: 0.56317 |  0:02:41s\n",
            "epoch 83 | loss: 0.60192 |  0:02:43s\n",
            "epoch 84 | loss: 0.61733 |  0:02:44s\n",
            "epoch 85 | loss: 0.56016 |  0:02:46s\n",
            "epoch 86 | loss: 0.57819 |  0:02:48s\n",
            "epoch 87 | loss: 0.56891 |  0:02:51s\n",
            "epoch 88 | loss: 0.54842 |  0:02:53s\n",
            "epoch 89 | loss: 0.55732 |  0:02:54s\n",
            "epoch 90 | loss: 0.55514 |  0:02:56s\n",
            "epoch 91 | loss: 0.56745 |  0:02:58s\n",
            "epoch 92 | loss: 0.61217 |  0:03:00s\n",
            "epoch 93 | loss: 0.57714 |  0:03:02s\n",
            "epoch 94 | loss: 0.57008 |  0:03:04s\n",
            "epoch 95 | loss: 0.56465 |  0:03:06s\n",
            "epoch 96 | loss: 0.5784  |  0:03:08s\n",
            "epoch 97 | loss: 0.58456 |  0:03:10s\n",
            "epoch 98 | loss: 0.54404 |  0:03:11s\n",
            "epoch 99 | loss: 0.55864 |  0:03:13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 13.81513|  0:00:02s\n",
            "epoch 1  | loss: 2.77558 |  0:00:04s\n",
            "epoch 2  | loss: 1.8459  |  0:00:06s\n",
            "epoch 3  | loss: 1.49403 |  0:00:08s\n",
            "epoch 4  | loss: 1.58755 |  0:00:09s\n",
            "epoch 5  | loss: 1.55845 |  0:00:11s\n",
            "epoch 6  | loss: 1.57669 |  0:00:13s\n",
            "epoch 7  | loss: 1.43394 |  0:00:15s\n",
            "epoch 8  | loss: 1.51564 |  0:00:17s\n",
            "epoch 9  | loss: 1.31132 |  0:00:19s\n",
            "epoch 10 | loss: 1.27919 |  0:00:21s\n",
            "epoch 11 | loss: 1.29782 |  0:00:23s\n",
            "epoch 12 | loss: 1.28993 |  0:00:24s\n",
            "epoch 13 | loss: 1.23802 |  0:00:26s\n",
            "epoch 14 | loss: 1.23897 |  0:00:28s\n",
            "epoch 15 | loss: 1.18115 |  0:00:30s\n",
            "epoch 16 | loss: 1.29333 |  0:00:33s\n",
            "epoch 17 | loss: 1.26245 |  0:00:34s\n",
            "epoch 18 | loss: 1.19489 |  0:00:36s\n",
            "epoch 19 | loss: 1.20672 |  0:00:38s\n",
            "epoch 20 | loss: 1.21645 |  0:00:40s\n",
            "epoch 21 | loss: 1.17693 |  0:00:42s\n",
            "epoch 22 | loss: 1.14301 |  0:00:44s\n",
            "epoch 23 | loss: 1.15341 |  0:00:46s\n",
            "epoch 24 | loss: 1.12065 |  0:00:48s\n",
            "epoch 25 | loss: 1.17125 |  0:00:50s\n",
            "epoch 26 | loss: 1.13049 |  0:00:51s\n",
            "epoch 27 | loss: 1.16232 |  0:00:53s\n",
            "epoch 28 | loss: 1.17233 |  0:00:55s\n",
            "epoch 29 | loss: 1.22614 |  0:00:57s\n",
            "epoch 30 | loss: 1.22539 |  0:00:59s\n",
            "epoch 31 | loss: 1.21035 |  0:01:01s\n",
            "epoch 32 | loss: 1.15339 |  0:01:03s\n",
            "epoch 33 | loss: 1.15954 |  0:01:05s\n",
            "epoch 34 | loss: 1.18219 |  0:01:06s\n",
            "epoch 35 | loss: 1.16959 |  0:01:08s\n",
            "epoch 36 | loss: 1.18024 |  0:01:10s\n",
            "epoch 37 | loss: 1.21522 |  0:01:12s\n",
            "epoch 38 | loss: 1.1798  |  0:01:14s\n",
            "epoch 39 | loss: 1.18154 |  0:01:16s\n",
            "epoch 40 | loss: 1.14219 |  0:01:18s\n",
            "epoch 41 | loss: 1.1639  |  0:01:20s\n",
            "epoch 42 | loss: 1.19182 |  0:01:21s\n",
            "epoch 43 | loss: 1.13458 |  0:01:23s\n",
            "epoch 44 | loss: 1.15625 |  0:01:25s\n",
            "epoch 45 | loss: 1.16008 |  0:01:28s\n",
            "epoch 46 | loss: 1.14755 |  0:01:30s\n",
            "epoch 47 | loss: 1.13885 |  0:01:31s\n",
            "epoch 48 | loss: 1.21778 |  0:01:33s\n",
            "epoch 49 | loss: 1.18852 |  0:01:35s\n",
            "epoch 50 | loss: 1.17957 |  0:01:37s\n",
            "epoch 51 | loss: 1.16402 |  0:01:38s\n",
            "epoch 52 | loss: 1.16709 |  0:01:41s\n",
            "epoch 53 | loss: 1.17506 |  0:01:43s\n",
            "epoch 54 | loss: 1.14965 |  0:01:45s\n",
            "epoch 55 | loss: 1.13123 |  0:01:46s\n",
            "epoch 56 | loss: 1.13031 |  0:01:48s\n",
            "epoch 57 | loss: 1.11208 |  0:01:50s\n",
            "epoch 58 | loss: 1.1095  |  0:01:52s\n",
            "epoch 59 | loss: 1.16737 |  0:01:54s\n",
            "epoch 60 | loss: 1.12501 |  0:01:57s\n",
            "epoch 61 | loss: 1.13458 |  0:01:58s\n",
            "epoch 62 | loss: 1.22255 |  0:02:00s\n",
            "epoch 63 | loss: 1.11508 |  0:02:02s\n",
            "epoch 64 | loss: 1.21325 |  0:02:04s\n",
            "epoch 65 | loss: 1.19263 |  0:02:06s\n",
            "epoch 66 | loss: 1.12709 |  0:02:08s\n",
            "epoch 67 | loss: 1.12445 |  0:02:10s\n",
            "epoch 68 | loss: 1.09758 |  0:02:12s\n",
            "epoch 69 | loss: 1.11965 |  0:02:14s\n",
            "epoch 70 | loss: 1.13348 |  0:02:15s\n",
            "epoch 71 | loss: 1.08933 |  0:02:17s\n",
            "epoch 72 | loss: 1.15447 |  0:02:19s\n",
            "epoch 73 | loss: 1.09626 |  0:02:21s\n",
            "epoch 74 | loss: 1.10428 |  0:02:23s\n",
            "epoch 75 | loss: 1.16096 |  0:02:25s\n",
            "epoch 76 | loss: 1.10843 |  0:02:27s\n",
            "epoch 77 | loss: 1.12211 |  0:02:29s\n",
            "epoch 78 | loss: 1.09286 |  0:02:30s\n",
            "epoch 79 | loss: 1.09295 |  0:02:32s\n",
            "epoch 80 | loss: 1.11522 |  0:02:34s\n",
            "epoch 81 | loss: 1.09932 |  0:02:36s\n",
            "epoch 82 | loss: 1.09269 |  0:02:39s\n",
            "epoch 83 | loss: 1.0721  |  0:02:40s\n",
            "epoch 84 | loss: 1.09161 |  0:02:42s\n",
            "epoch 85 | loss: 1.10578 |  0:02:44s\n",
            "epoch 86 | loss: 1.0671  |  0:02:45s\n",
            "epoch 87 | loss: 1.09456 |  0:02:47s\n",
            "epoch 88 | loss: 1.08465 |  0:02:49s\n",
            "epoch 89 | loss: 1.07346 |  0:02:52s\n",
            "epoch 90 | loss: 1.08614 |  0:02:53s\n",
            "epoch 91 | loss: 1.07335 |  0:02:55s\n",
            "epoch 92 | loss: 1.14408 |  0:02:57s\n",
            "epoch 93 | loss: 1.10487 |  0:02:59s\n",
            "epoch 94 | loss: 1.067   |  0:03:00s\n",
            "epoch 95 | loss: 1.08274 |  0:03:02s\n",
            "epoch 96 | loss: 1.1154  |  0:03:04s\n",
            "epoch 97 | loss: 1.11561 |  0:03:07s\n",
            "epoch 98 | loss: 1.07741 |  0:03:08s\n",
            "epoch 99 | loss: 1.07037 |  0:03:10s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 19.83552|  0:00:01s\n",
            "epoch 1  | loss: 2.09585 |  0:00:03s\n",
            "epoch 2  | loss: 1.38896 |  0:00:05s\n",
            "epoch 3  | loss: 1.00554 |  0:00:08s\n",
            "epoch 4  | loss: 1.24862 |  0:00:10s\n",
            "epoch 5  | loss: 0.91183 |  0:00:11s\n",
            "epoch 6  | loss: 0.87138 |  0:00:13s\n",
            "epoch 7  | loss: 0.95728 |  0:00:15s\n",
            "epoch 8  | loss: 0.79071 |  0:00:17s\n",
            "epoch 9  | loss: 0.76373 |  0:00:19s\n",
            "epoch 10 | loss: 0.76628 |  0:00:21s\n",
            "epoch 11 | loss: 0.79611 |  0:00:23s\n",
            "epoch 12 | loss: 0.71198 |  0:00:25s\n",
            "epoch 13 | loss: 0.69673 |  0:00:27s\n",
            "epoch 14 | loss: 0.70301 |  0:00:28s\n",
            "epoch 15 | loss: 0.70267 |  0:00:30s\n",
            "epoch 16 | loss: 0.72087 |  0:00:32s\n",
            "epoch 17 | loss: 0.72524 |  0:00:35s\n",
            "epoch 18 | loss: 0.72553 |  0:00:37s\n",
            "epoch 19 | loss: 0.80871 |  0:00:39s\n",
            "epoch 20 | loss: 0.8762  |  0:00:40s\n",
            "epoch 21 | loss: 0.7616  |  0:00:42s\n",
            "epoch 22 | loss: 0.77843 |  0:00:44s\n",
            "epoch 23 | loss: 0.8181  |  0:00:46s\n",
            "epoch 24 | loss: 0.66496 |  0:00:48s\n",
            "epoch 25 | loss: 0.65521 |  0:00:51s\n",
            "epoch 26 | loss: 0.67416 |  0:00:52s\n",
            "epoch 27 | loss: 0.68952 |  0:00:54s\n",
            "epoch 28 | loss: 0.72457 |  0:00:56s\n",
            "epoch 29 | loss: 0.68383 |  0:00:58s\n",
            "epoch 30 | loss: 0.6873  |  0:00:59s\n",
            "epoch 31 | loss: 0.64933 |  0:01:02s\n",
            "epoch 32 | loss: 0.65223 |  0:01:04s\n",
            "epoch 33 | loss: 0.70367 |  0:01:06s\n",
            "epoch 34 | loss: 0.70034 |  0:01:08s\n",
            "epoch 35 | loss: 0.70001 |  0:01:09s\n",
            "epoch 36 | loss: 0.66812 |  0:01:11s\n",
            "epoch 37 | loss: 0.63545 |  0:01:13s\n",
            "epoch 38 | loss: 0.65006 |  0:01:15s\n",
            "epoch 39 | loss: 0.65133 |  0:01:17s\n",
            "epoch 40 | loss: 0.69225 |  0:01:19s\n",
            "epoch 41 | loss: 0.67762 |  0:01:21s\n",
            "epoch 42 | loss: 0.64803 |  0:01:23s\n",
            "epoch 43 | loss: 0.6605  |  0:01:25s\n",
            "epoch 44 | loss: 0.62586 |  0:01:26s\n",
            "epoch 45 | loss: 0.72779 |  0:01:28s\n",
            "epoch 46 | loss: 0.71707 |  0:01:31s\n",
            "epoch 47 | loss: 0.64116 |  0:01:33s\n",
            "epoch 48 | loss: 0.63723 |  0:01:35s\n",
            "epoch 49 | loss: 0.65632 |  0:01:37s\n",
            "epoch 50 | loss: 0.65199 |  0:01:38s\n",
            "epoch 51 | loss: 0.59117 |  0:01:40s\n",
            "epoch 52 | loss: 0.6684  |  0:01:42s\n",
            "epoch 53 | loss: 0.82811 |  0:01:44s\n",
            "epoch 54 | loss: 0.74304 |  0:01:47s\n",
            "epoch 55 | loss: 0.71677 |  0:01:48s\n",
            "epoch 56 | loss: 0.63913 |  0:01:50s\n",
            "epoch 57 | loss: 0.68549 |  0:01:52s\n",
            "epoch 58 | loss: 0.66157 |  0:01:54s\n",
            "epoch 59 | loss: 0.65423 |  0:01:55s\n",
            "epoch 60 | loss: 0.63017 |  0:01:58s\n",
            "epoch 61 | loss: 0.64316 |  0:02:00s\n",
            "epoch 62 | loss: 0.65081 |  0:02:02s\n",
            "epoch 63 | loss: 0.66788 |  0:02:04s\n",
            "epoch 64 | loss: 0.6218  |  0:02:06s\n",
            "epoch 65 | loss: 0.63494 |  0:02:07s\n",
            "epoch 66 | loss: 0.62673 |  0:02:09s\n",
            "epoch 67 | loss: 0.61628 |  0:02:11s\n",
            "epoch 68 | loss: 0.62644 |  0:02:14s\n",
            "epoch 69 | loss: 0.61645 |  0:02:16s\n",
            "epoch 70 | loss: 0.63992 |  0:02:17s\n",
            "epoch 71 | loss: 0.6133  |  0:02:19s\n",
            "epoch 72 | loss: 0.60487 |  0:02:21s\n",
            "epoch 73 | loss: 0.63726 |  0:02:23s\n",
            "epoch 74 | loss: 0.68368 |  0:02:25s\n",
            "epoch 75 | loss: 0.65741 |  0:02:27s\n",
            "epoch 76 | loss: 0.5735  |  0:02:29s\n",
            "epoch 77 | loss: 0.6009  |  0:02:31s\n",
            "epoch 78 | loss: 0.5993  |  0:02:33s\n",
            "epoch 79 | loss: 0.61283 |  0:02:35s\n",
            "epoch 80 | loss: 0.588   |  0:02:36s\n",
            "epoch 81 | loss: 0.6341  |  0:02:39s\n",
            "epoch 82 | loss: 0.68078 |  0:02:41s\n",
            "epoch 83 | loss: 0.69815 |  0:02:43s\n",
            "epoch 84 | loss: 0.68378 |  0:02:45s\n",
            "epoch 85 | loss: 0.91326 |  0:02:46s\n",
            "epoch 86 | loss: 0.87426 |  0:02:48s\n",
            "epoch 87 | loss: 0.61911 |  0:02:50s\n",
            "epoch 88 | loss: 0.57688 |  0:02:52s\n",
            "epoch 89 | loss: 0.58784 |  0:02:54s\n",
            "epoch 90 | loss: 0.58146 |  0:02:56s\n",
            "epoch 91 | loss: 0.6473  |  0:02:58s\n",
            "epoch 92 | loss: 0.67462 |  0:03:00s\n",
            "epoch 93 | loss: 0.70363 |  0:03:02s\n",
            "epoch 94 | loss: 0.6032  |  0:03:04s\n",
            "epoch 95 | loss: 0.57264 |  0:03:05s\n",
            "epoch 96 | loss: 0.56742 |  0:03:08s\n",
            "epoch 97 | loss: 0.57604 |  0:03:10s\n",
            "epoch 98 | loss: 0.58017 |  0:03:12s\n",
            "epoch 99 | loss: 0.57382 |  0:03:14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.46385 |  0:00:01s\n",
            "epoch 1  | loss: 3.68299 |  0:00:03s\n",
            "epoch 2  | loss: 1.85716 |  0:00:05s\n",
            "epoch 3  | loss: 1.82606 |  0:00:08s\n",
            "epoch 4  | loss: 1.95394 |  0:00:10s\n",
            "epoch 5  | loss: 1.60868 |  0:00:11s\n",
            "epoch 6  | loss: 1.42008 |  0:00:13s\n",
            "epoch 7  | loss: 1.26573 |  0:00:15s\n",
            "epoch 8  | loss: 1.40218 |  0:00:17s\n",
            "epoch 9  | loss: 1.38537 |  0:00:18s\n",
            "epoch 10 | loss: 1.26655 |  0:00:21s\n",
            "epoch 11 | loss: 1.18239 |  0:00:23s\n",
            "epoch 12 | loss: 1.2594  |  0:00:25s\n",
            "epoch 13 | loss: 1.26728 |  0:00:26s\n",
            "epoch 14 | loss: 1.13499 |  0:00:28s\n",
            "epoch 15 | loss: 1.11807 |  0:00:30s\n",
            "epoch 16 | loss: 1.09136 |  0:00:32s\n",
            "epoch 17 | loss: 1.16063 |  0:00:35s\n",
            "epoch 18 | loss: 1.0643  |  0:00:37s\n",
            "epoch 19 | loss: 1.2936  |  0:00:39s\n",
            "epoch 20 | loss: 1.41145 |  0:00:40s\n",
            "epoch 21 | loss: 1.10983 |  0:00:42s\n",
            "epoch 22 | loss: 1.03626 |  0:00:44s\n",
            "epoch 23 | loss: 1.1023  |  0:00:46s\n",
            "epoch 24 | loss: 1.07682 |  0:00:48s\n",
            "epoch 25 | loss: 1.04754 |  0:00:50s\n",
            "epoch 26 | loss: 1.04994 |  0:00:52s\n",
            "epoch 27 | loss: 1.07723 |  0:00:54s\n",
            "epoch 28 | loss: 1.08388 |  0:00:56s\n",
            "epoch 29 | loss: 1.06238 |  0:00:57s\n",
            "epoch 30 | loss: 1.0845  |  0:00:59s\n",
            "epoch 31 | loss: 1.1664  |  0:01:01s\n",
            "epoch 32 | loss: 1.04728 |  0:01:04s\n",
            "epoch 33 | loss: 1.02571 |  0:01:06s\n",
            "epoch 34 | loss: 1.16146 |  0:01:07s\n",
            "epoch 35 | loss: 1.12276 |  0:01:09s\n",
            "epoch 36 | loss: 1.09618 |  0:01:11s\n",
            "epoch 37 | loss: 1.08534 |  0:01:13s\n",
            "epoch 38 | loss: 1.07939 |  0:01:15s\n",
            "epoch 39 | loss: 1.069   |  0:01:17s\n",
            "epoch 40 | loss: 0.98772 |  0:01:19s\n",
            "epoch 41 | loss: 1.05993 |  0:01:21s\n",
            "epoch 42 | loss: 1.06662 |  0:01:23s\n",
            "epoch 43 | loss: 1.02831 |  0:01:25s\n",
            "epoch 44 | loss: 0.98179 |  0:01:26s\n",
            "epoch 45 | loss: 1.00118 |  0:01:28s\n",
            "epoch 46 | loss: 1.07113 |  0:01:31s\n",
            "epoch 47 | loss: 1.2875  |  0:01:33s\n",
            "epoch 48 | loss: 1.10037 |  0:01:35s\n",
            "epoch 49 | loss: 0.98566 |  0:01:37s\n",
            "epoch 50 | loss: 1.01635 |  0:01:38s\n",
            "epoch 51 | loss: 1.01499 |  0:01:40s\n",
            "epoch 52 | loss: 0.98902 |  0:01:42s\n",
            "epoch 53 | loss: 1.00746 |  0:01:45s\n",
            "epoch 54 | loss: 0.98644 |  0:01:47s\n",
            "epoch 55 | loss: 0.9554  |  0:01:48s\n",
            "epoch 56 | loss: 0.9568  |  0:01:50s\n",
            "epoch 57 | loss: 0.96727 |  0:01:52s\n",
            "epoch 58 | loss: 0.99775 |  0:01:53s\n",
            "epoch 59 | loss: 0.99675 |  0:01:55s\n",
            "epoch 60 | loss: 0.9496  |  0:01:57s\n",
            "epoch 61 | loss: 0.94813 |  0:02:00s\n",
            "epoch 62 | loss: 1.00949 |  0:02:02s\n",
            "epoch 63 | loss: 1.03987 |  0:02:03s\n",
            "epoch 64 | loss: 1.02656 |  0:02:05s\n",
            "epoch 65 | loss: 0.96534 |  0:02:07s\n",
            "epoch 66 | loss: 1.00003 |  0:02:09s\n",
            "epoch 67 | loss: 1.16505 |  0:02:11s\n",
            "epoch 68 | loss: 1.10562 |  0:02:13s\n",
            "epoch 69 | loss: 1.03306 |  0:02:15s\n",
            "epoch 70 | loss: 1.01046 |  0:02:17s\n",
            "epoch 71 | loss: 0.98855 |  0:02:19s\n",
            "epoch 72 | loss: 1.08873 |  0:02:20s\n",
            "epoch 73 | loss: 1.01793 |  0:02:22s\n",
            "epoch 74 | loss: 1.00035 |  0:02:24s\n",
            "epoch 75 | loss: 0.97588 |  0:02:27s\n",
            "epoch 76 | loss: 0.99153 |  0:02:29s\n",
            "epoch 77 | loss: 0.95849 |  0:02:30s\n",
            "epoch 78 | loss: 0.96911 |  0:02:32s\n",
            "epoch 79 | loss: 0.98323 |  0:02:34s\n",
            "epoch 80 | loss: 0.96562 |  0:02:36s\n",
            "epoch 81 | loss: 0.96649 |  0:02:38s\n",
            "epoch 82 | loss: 1.02848 |  0:02:40s\n",
            "epoch 83 | loss: 1.00587 |  0:02:42s\n",
            "epoch 84 | loss: 0.96165 |  0:02:44s\n",
            "epoch 85 | loss: 0.99376 |  0:02:46s\n",
            "epoch 86 | loss: 0.96962 |  0:02:48s\n",
            "epoch 87 | loss: 1.04442 |  0:02:49s\n",
            "epoch 88 | loss: 1.00642 |  0:02:51s\n",
            "epoch 89 | loss: 1.11338 |  0:02:54s\n",
            "epoch 90 | loss: 1.07971 |  0:02:56s\n",
            "epoch 91 | loss: 1.05117 |  0:02:57s\n",
            "epoch 92 | loss: 0.99316 |  0:02:59s\n",
            "epoch 93 | loss: 0.99725 |  0:03:01s\n",
            "epoch 94 | loss: 0.95472 |  0:03:03s\n",
            "epoch 95 | loss: 0.96797 |  0:03:05s\n",
            "epoch 96 | loss: 0.94939 |  0:03:07s\n",
            "epoch 97 | loss: 0.94776 |  0:03:09s\n",
            "epoch 98 | loss: 0.95404 |  0:03:11s\n",
            "epoch 99 | loss: 0.92883 |  0:03:13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 11.16934|  0:00:01s\n",
            "epoch 1  | loss: 3.6903  |  0:00:03s\n",
            "epoch 2  | loss: 1.50526 |  0:00:05s\n",
            "epoch 3  | loss: 1.28422 |  0:00:08s\n",
            "epoch 4  | loss: 1.28606 |  0:00:10s\n",
            "epoch 5  | loss: 1.0577  |  0:00:11s\n",
            "epoch 6  | loss: 0.92043 |  0:00:13s\n",
            "epoch 7  | loss: 0.80503 |  0:00:15s\n",
            "epoch 8  | loss: 0.81919 |  0:00:17s\n",
            "epoch 9  | loss: 0.84392 |  0:00:19s\n",
            "epoch 10 | loss: 0.82839 |  0:00:21s\n",
            "epoch 11 | loss: 0.73885 |  0:00:23s\n",
            "epoch 12 | loss: 0.77761 |  0:00:25s\n",
            "epoch 13 | loss: 0.80003 |  0:00:27s\n",
            "epoch 14 | loss: 0.80037 |  0:00:29s\n",
            "epoch 15 | loss: 0.8881  |  0:00:30s\n",
            "epoch 16 | loss: 0.71318 |  0:00:32s\n",
            "epoch 17 | loss: 0.70737 |  0:00:35s\n",
            "epoch 18 | loss: 0.71088 |  0:00:37s\n",
            "epoch 19 | loss: 0.70244 |  0:00:39s\n",
            "epoch 20 | loss: 0.80517 |  0:00:40s\n",
            "epoch 21 | loss: 0.70269 |  0:00:42s\n",
            "epoch 22 | loss: 0.72442 |  0:00:44s\n",
            "epoch 23 | loss: 0.70815 |  0:00:46s\n",
            "epoch 24 | loss: 0.74372 |  0:00:48s\n",
            "epoch 25 | loss: 0.70362 |  0:00:50s\n",
            "epoch 26 | loss: 0.68829 |  0:00:52s\n",
            "epoch 27 | loss: 0.69706 |  0:00:54s\n",
            "epoch 28 | loss: 0.67261 |  0:00:56s\n",
            "epoch 29 | loss: 0.71023 |  0:00:57s\n",
            "epoch 30 | loss: 0.70797 |  0:00:59s\n",
            "epoch 31 | loss: 0.75191 |  0:01:02s\n",
            "epoch 32 | loss: 0.67907 |  0:01:04s\n",
            "epoch 33 | loss: 0.67271 |  0:01:06s\n",
            "epoch 34 | loss: 0.74249 |  0:01:08s\n",
            "epoch 35 | loss: 0.68718 |  0:01:09s\n",
            "epoch 36 | loss: 0.7288  |  0:01:11s\n",
            "epoch 37 | loss: 0.73225 |  0:01:13s\n",
            "epoch 38 | loss: 0.70558 |  0:01:15s\n",
            "epoch 39 | loss: 0.7075  |  0:01:17s\n",
            "epoch 40 | loss: 0.66145 |  0:01:19s\n",
            "epoch 41 | loss: 0.70044 |  0:01:21s\n",
            "epoch 42 | loss: 0.69462 |  0:01:23s\n",
            "epoch 43 | loss: 0.79271 |  0:01:24s\n",
            "epoch 44 | loss: 0.68705 |  0:01:26s\n",
            "epoch 45 | loss: 0.64633 |  0:01:28s\n",
            "epoch 46 | loss: 0.62241 |  0:01:31s\n",
            "epoch 47 | loss: 0.64093 |  0:01:33s\n",
            "epoch 48 | loss: 0.67784 |  0:01:35s\n",
            "epoch 49 | loss: 0.71502 |  0:01:36s\n",
            "epoch 50 | loss: 0.62301 |  0:01:38s\n",
            "epoch 51 | loss: 0.61047 |  0:01:40s\n",
            "epoch 52 | loss: 0.59056 |  0:01:42s\n",
            "epoch 53 | loss: 0.63148 |  0:01:45s\n",
            "epoch 54 | loss: 0.61733 |  0:01:47s\n",
            "epoch 55 | loss: 0.60515 |  0:01:48s\n",
            "epoch 56 | loss: 0.60462 |  0:01:50s\n",
            "epoch 57 | loss: 0.62647 |  0:01:52s\n",
            "epoch 58 | loss: 0.57554 |  0:01:54s\n",
            "epoch 59 | loss: 0.58994 |  0:01:56s\n",
            "epoch 60 | loss: 0.60246 |  0:01:58s\n",
            "epoch 61 | loss: 0.59992 |  0:02:00s\n",
            "epoch 62 | loss: 0.62964 |  0:02:02s\n",
            "epoch 63 | loss: 0.66656 |  0:02:04s\n",
            "epoch 64 | loss: 0.64792 |  0:02:06s\n",
            "epoch 65 | loss: 0.61277 |  0:02:08s\n",
            "epoch 66 | loss: 0.6513  |  0:02:10s\n",
            "epoch 67 | loss: 0.597   |  0:02:12s\n",
            "epoch 68 | loss: 0.63207 |  0:02:14s\n",
            "epoch 69 | loss: 0.59524 |  0:02:16s\n",
            "epoch 70 | loss: 0.6227  |  0:02:18s\n",
            "epoch 71 | loss: 0.64115 |  0:02:20s\n",
            "epoch 72 | loss: 0.59709 |  0:02:21s\n",
            "epoch 73 | loss: 0.55881 |  0:02:23s\n",
            "epoch 74 | loss: 0.58695 |  0:02:26s\n",
            "epoch 75 | loss: 0.64277 |  0:02:28s\n",
            "epoch 76 | loss: 0.64131 |  0:02:30s\n",
            "epoch 77 | loss: 0.58968 |  0:02:32s\n",
            "epoch 78 | loss: 0.55978 |  0:02:33s\n",
            "epoch 79 | loss: 0.59727 |  0:02:35s\n",
            "epoch 80 | loss: 0.6183  |  0:02:37s\n",
            "epoch 81 | loss: 0.59005 |  0:02:39s\n",
            "epoch 82 | loss: 0.62186 |  0:02:42s\n",
            "epoch 83 | loss: 0.58986 |  0:02:44s\n",
            "epoch 84 | loss: 0.56373 |  0:02:45s\n",
            "epoch 85 | loss: 0.56536 |  0:02:47s\n",
            "epoch 86 | loss: 0.54733 |  0:02:49s\n",
            "epoch 87 | loss: 0.66173 |  0:02:51s\n",
            "epoch 88 | loss: 0.59991 |  0:02:53s\n",
            "epoch 89 | loss: 0.56883 |  0:02:56s\n",
            "epoch 90 | loss: 0.61692 |  0:02:57s\n",
            "epoch 91 | loss: 0.56785 |  0:02:59s\n",
            "epoch 92 | loss: 0.56024 |  0:03:01s\n",
            "epoch 93 | loss: 0.54786 |  0:03:03s\n",
            "epoch 94 | loss: 0.55249 |  0:03:05s\n",
            "epoch 95 | loss: 0.54071 |  0:03:07s\n",
            "epoch 96 | loss: 0.55994 |  0:03:09s\n",
            "epoch 97 | loss: 0.59619 |  0:03:11s\n",
            "epoch 98 | loss: 0.54559 |  0:03:13s\n",
            "epoch 99 | loss: 0.539   |  0:03:15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 7.74663 |  0:00:01s\n",
            "epoch 1  | loss: 2.85317 |  0:00:03s\n",
            "epoch 2  | loss: 2.7815  |  0:00:06s\n",
            "epoch 3  | loss: 2.17848 |  0:00:08s\n",
            "epoch 4  | loss: 1.72126 |  0:00:10s\n",
            "epoch 5  | loss: 1.5552  |  0:00:12s\n",
            "epoch 6  | loss: 1.57446 |  0:00:13s\n",
            "epoch 7  | loss: 1.54303 |  0:00:15s\n",
            "epoch 8  | loss: 1.54207 |  0:00:17s\n",
            "epoch 9  | loss: 1.57644 |  0:00:20s\n",
            "epoch 10 | loss: 1.63975 |  0:00:22s\n",
            "epoch 11 | loss: 1.72512 |  0:00:24s\n",
            "epoch 12 | loss: 1.58038 |  0:00:26s\n",
            "epoch 13 | loss: 1.50221 |  0:00:28s\n",
            "epoch 14 | loss: 1.48057 |  0:00:30s\n",
            "epoch 15 | loss: 1.47653 |  0:00:32s\n",
            "epoch 16 | loss: 1.48572 |  0:00:34s\n",
            "epoch 17 | loss: 1.48707 |  0:00:36s\n",
            "epoch 18 | loss: 1.39664 |  0:00:38s\n",
            "epoch 19 | loss: 1.39182 |  0:00:40s\n",
            "epoch 20 | loss: 1.37861 |  0:00:42s\n",
            "epoch 21 | loss: 1.39297 |  0:00:44s\n",
            "epoch 22 | loss: 1.43773 |  0:00:46s\n",
            "epoch 23 | loss: 1.38738 |  0:00:48s\n",
            "epoch 24 | loss: 1.35486 |  0:00:50s\n",
            "epoch 25 | loss: 1.37964 |  0:00:52s\n",
            "epoch 26 | loss: 1.43518 |  0:00:54s\n",
            "epoch 27 | loss: 1.46666 |  0:00:56s\n",
            "epoch 28 | loss: 1.45537 |  0:00:58s\n",
            "epoch 29 | loss: 1.46549 |  0:01:00s\n",
            "epoch 30 | loss: 1.46858 |  0:01:02s\n",
            "epoch 31 | loss: 1.40779 |  0:01:04s\n",
            "epoch 32 | loss: 1.39976 |  0:01:06s\n",
            "epoch 33 | loss: 1.4502  |  0:01:08s\n",
            "epoch 34 | loss: 1.37207 |  0:01:10s\n",
            "epoch 35 | loss: 1.40453 |  0:01:12s\n",
            "epoch 36 | loss: 1.39697 |  0:01:14s\n",
            "epoch 37 | loss: 1.35998 |  0:01:17s\n",
            "epoch 38 | loss: 1.41167 |  0:01:19s\n",
            "epoch 39 | loss: 1.37929 |  0:01:21s\n",
            "epoch 40 | loss: 1.39206 |  0:01:22s\n",
            "epoch 41 | loss: 1.36127 |  0:01:24s\n",
            "epoch 42 | loss: 1.34633 |  0:01:26s\n",
            "epoch 43 | loss: 1.34142 |  0:01:28s\n",
            "epoch 44 | loss: 1.36762 |  0:01:31s\n",
            "epoch 45 | loss: 1.34279 |  0:01:33s\n",
            "epoch 46 | loss: 1.39539 |  0:01:34s\n",
            "epoch 47 | loss: 1.39082 |  0:01:36s\n",
            "epoch 48 | loss: 1.35363 |  0:01:38s\n",
            "epoch 49 | loss: 1.3598  |  0:01:40s\n",
            "epoch 50 | loss: 1.37341 |  0:01:42s\n",
            "epoch 51 | loss: 1.37576 |  0:01:45s\n",
            "epoch 52 | loss: 1.42669 |  0:01:47s\n",
            "epoch 53 | loss: 1.41548 |  0:01:48s\n",
            "epoch 54 | loss: 1.39475 |  0:01:50s\n",
            "epoch 55 | loss: 1.37678 |  0:01:52s\n",
            "epoch 56 | loss: 1.35611 |  0:01:54s\n",
            "epoch 57 | loss: 1.40661 |  0:01:56s\n",
            "epoch 58 | loss: 1.36274 |  0:01:58s\n",
            "epoch 59 | loss: 1.34846 |  0:02:00s\n",
            "epoch 60 | loss: 1.33305 |  0:02:02s\n",
            "epoch 61 | loss: 1.35426 |  0:02:04s\n",
            "epoch 62 | loss: 1.32061 |  0:02:06s\n",
            "epoch 63 | loss: 1.38927 |  0:02:08s\n",
            "epoch 64 | loss: 1.34575 |  0:02:10s\n",
            "epoch 65 | loss: 1.34567 |  0:02:12s\n",
            "epoch 66 | loss: 1.37021 |  0:02:14s\n",
            "epoch 67 | loss: 1.31685 |  0:02:16s\n",
            "epoch 68 | loss: 1.31623 |  0:02:18s\n",
            "epoch 69 | loss: 1.32059 |  0:02:20s\n",
            "epoch 70 | loss: 1.33924 |  0:02:22s\n",
            "epoch 71 | loss: 1.36007 |  0:02:24s\n",
            "epoch 72 | loss: 1.41385 |  0:02:26s\n",
            "epoch 73 | loss: 1.42715 |  0:02:28s\n",
            "epoch 74 | loss: 1.37104 |  0:02:30s\n",
            "epoch 75 | loss: 1.34633 |  0:02:32s\n",
            "epoch 76 | loss: 1.44991 |  0:02:34s\n",
            "epoch 77 | loss: 1.41856 |  0:02:35s\n",
            "epoch 78 | loss: 1.34548 |  0:02:38s\n",
            "epoch 79 | loss: 1.31583 |  0:02:40s\n",
            "epoch 80 | loss: 1.38103 |  0:02:42s\n",
            "epoch 81 | loss: 1.31736 |  0:02:44s\n",
            "epoch 82 | loss: 1.32972 |  0:02:45s\n",
            "epoch 83 | loss: 1.34035 |  0:02:47s\n",
            "epoch 84 | loss: 1.33265 |  0:02:49s\n",
            "epoch 85 | loss: 1.34279 |  0:02:51s\n",
            "epoch 86 | loss: 1.33187 |  0:02:54s\n",
            "epoch 87 | loss: 1.30346 |  0:02:56s\n",
            "epoch 88 | loss: 1.38776 |  0:02:57s\n",
            "epoch 89 | loss: 1.37127 |  0:02:59s\n",
            "epoch 90 | loss: 1.34805 |  0:03:01s\n",
            "epoch 91 | loss: 1.30521 |  0:03:03s\n",
            "epoch 92 | loss: 1.32961 |  0:03:05s\n",
            "epoch 93 | loss: 1.32742 |  0:03:08s\n",
            "epoch 94 | loss: 1.35497 |  0:03:10s\n",
            "epoch 95 | loss: 1.31583 |  0:03:11s\n",
            "epoch 96 | loss: 1.29893 |  0:03:13s\n",
            "epoch 97 | loss: 1.30349 |  0:03:15s\n",
            "epoch 98 | loss: 1.36754 |  0:03:17s\n",
            "epoch 99 | loss: 1.35876 |  0:03:19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 8.05736 |  0:00:01s\n",
            "epoch 1  | loss: 1.28522 |  0:00:03s\n",
            "epoch 2  | loss: 1.12706 |  0:00:04s\n",
            "epoch 3  | loss: 0.99658 |  0:00:06s\n",
            "epoch 4  | loss: 0.96001 |  0:00:07s\n",
            "epoch 5  | loss: 0.90422 |  0:00:08s\n",
            "epoch 6  | loss: 0.88402 |  0:00:10s\n",
            "epoch 7  | loss: 0.86039 |  0:00:11s\n",
            "epoch 8  | loss: 0.84284 |  0:00:13s\n",
            "epoch 9  | loss: 0.84228 |  0:00:15s\n",
            "epoch 10 | loss: 0.84023 |  0:00:16s\n",
            "epoch 11 | loss: 0.96365 |  0:00:18s\n",
            "epoch 12 | loss: 0.87982 |  0:00:19s\n",
            "epoch 13 | loss: 0.87428 |  0:00:20s\n",
            "epoch 14 | loss: 0.89369 |  0:00:22s\n",
            "epoch 15 | loss: 0.89539 |  0:00:23s\n",
            "epoch 16 | loss: 0.90968 |  0:00:24s\n",
            "epoch 17 | loss: 0.86354 |  0:00:26s\n",
            "epoch 18 | loss: 0.86568 |  0:00:28s\n",
            "epoch 19 | loss: 0.91642 |  0:00:30s\n",
            "epoch 20 | loss: 0.87136 |  0:00:31s\n",
            "epoch 21 | loss: 0.84151 |  0:00:32s\n",
            "epoch 22 | loss: 0.84131 |  0:00:34s\n",
            "epoch 23 | loss: 0.82401 |  0:00:35s\n",
            "epoch 24 | loss: 0.8316  |  0:00:36s\n",
            "epoch 25 | loss: 0.86998 |  0:00:38s\n",
            "epoch 26 | loss: 0.83486 |  0:00:39s\n",
            "epoch 27 | loss: 0.82742 |  0:00:41s\n",
            "epoch 28 | loss: 0.81417 |  0:00:43s\n",
            "epoch 29 | loss: 0.84673 |  0:00:44s\n",
            "epoch 30 | loss: 0.81657 |  0:00:46s\n",
            "epoch 31 | loss: 0.82719 |  0:00:47s\n",
            "epoch 32 | loss: 0.81428 |  0:00:48s\n",
            "epoch 33 | loss: 0.79819 |  0:00:50s\n",
            "epoch 34 | loss: 0.79435 |  0:00:51s\n",
            "epoch 35 | loss: 0.85915 |  0:00:53s\n",
            "epoch 36 | loss: 0.78488 |  0:00:54s\n",
            "epoch 37 | loss: 0.78298 |  0:00:56s\n",
            "epoch 38 | loss: 0.78791 |  0:00:58s\n",
            "epoch 39 | loss: 0.82266 |  0:00:59s\n",
            "epoch 40 | loss: 0.7988  |  0:01:01s\n",
            "epoch 41 | loss: 0.79623 |  0:01:02s\n",
            "epoch 42 | loss: 0.78384 |  0:01:04s\n",
            "epoch 43 | loss: 0.80823 |  0:01:05s\n",
            "epoch 44 | loss: 0.79539 |  0:01:06s\n",
            "epoch 45 | loss: 0.7554  |  0:01:08s\n",
            "epoch 46 | loss: 0.7519  |  0:01:10s\n",
            "epoch 47 | loss: 0.81408 |  0:01:12s\n",
            "epoch 48 | loss: 0.78927 |  0:01:13s\n",
            "epoch 49 | loss: 0.77213 |  0:01:15s\n",
            "epoch 50 | loss: 0.80936 |  0:01:16s\n",
            "epoch 51 | loss: 0.77989 |  0:01:17s\n",
            "epoch 52 | loss: 0.78039 |  0:01:19s\n",
            "epoch 53 | loss: 0.76733 |  0:01:20s\n",
            "epoch 54 | loss: 0.80639 |  0:01:21s\n",
            "epoch 55 | loss: 0.80066 |  0:01:23s\n",
            "epoch 56 | loss: 0.77276 |  0:01:25s\n",
            "epoch 57 | loss: 0.77985 |  0:01:27s\n",
            "epoch 58 | loss: 0.77094 |  0:01:28s\n",
            "epoch 59 | loss: 0.78779 |  0:01:30s\n",
            "epoch 60 | loss: 0.77063 |  0:01:31s\n",
            "epoch 61 | loss: 0.76101 |  0:01:32s\n",
            "epoch 62 | loss: 0.78057 |  0:01:34s\n",
            "epoch 63 | loss: 0.76968 |  0:01:35s\n",
            "epoch 64 | loss: 0.75821 |  0:01:37s\n",
            "epoch 65 | loss: 0.76372 |  0:01:39s\n",
            "epoch 66 | loss: 0.76273 |  0:01:40s\n",
            "epoch 67 | loss: 0.76685 |  0:01:41s\n",
            "epoch 68 | loss: 0.73994 |  0:01:43s\n",
            "epoch 69 | loss: 0.76018 |  0:01:44s\n",
            "epoch 70 | loss: 0.76516 |  0:01:45s\n",
            "epoch 71 | loss: 0.76925 |  0:01:47s\n",
            "epoch 72 | loss: 0.76192 |  0:01:48s\n",
            "epoch 73 | loss: 0.75565 |  0:01:49s\n",
            "epoch 74 | loss: 0.74572 |  0:01:51s\n",
            "epoch 75 | loss: 0.75327 |  0:01:53s\n",
            "epoch 76 | loss: 0.75511 |  0:01:55s\n",
            "epoch 77 | loss: 0.75928 |  0:01:56s\n",
            "epoch 78 | loss: 0.79376 |  0:01:57s\n",
            "epoch 79 | loss: 0.78424 |  0:01:59s\n",
            "epoch 80 | loss: 0.75828 |  0:02:00s\n",
            "epoch 81 | loss: 0.74915 |  0:02:01s\n",
            "epoch 82 | loss: 0.77833 |  0:02:03s\n",
            "epoch 83 | loss: 0.73389 |  0:02:05s\n",
            "epoch 84 | loss: 0.76759 |  0:02:07s\n",
            "epoch 85 | loss: 0.77239 |  0:02:08s\n",
            "epoch 86 | loss: 0.79857 |  0:02:10s\n",
            "epoch 87 | loss: 0.73176 |  0:02:11s\n",
            "epoch 88 | loss: 0.74992 |  0:02:12s\n",
            "epoch 89 | loss: 0.77617 |  0:02:14s\n",
            "epoch 90 | loss: 0.76752 |  0:02:15s\n",
            "epoch 91 | loss: 0.7824  |  0:02:16s\n",
            "epoch 92 | loss: 0.76087 |  0:02:18s\n",
            "epoch 93 | loss: 0.7559  |  0:02:20s\n",
            "epoch 94 | loss: 0.77788 |  0:02:22s\n",
            "epoch 95 | loss: 0.75075 |  0:02:23s\n",
            "epoch 96 | loss: 0.74603 |  0:02:24s\n",
            "epoch 97 | loss: 0.75316 |  0:02:26s\n",
            "epoch 98 | loss: 0.72973 |  0:02:27s\n",
            "epoch 99 | loss: 0.72534 |  0:02:28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 6.75886 |  0:00:01s\n",
            "epoch 1  | loss: 1.27438 |  0:00:02s\n",
            "epoch 2  | loss: 0.88859 |  0:00:04s\n",
            "epoch 3  | loss: 0.80514 |  0:00:06s\n",
            "epoch 4  | loss: 0.81169 |  0:00:07s\n",
            "epoch 5  | loss: 0.87342 |  0:00:09s\n",
            "epoch 6  | loss: 0.7799  |  0:00:10s\n",
            "epoch 7  | loss: 0.72923 |  0:00:12s\n",
            "epoch 8  | loss: 0.73988 |  0:00:13s\n",
            "epoch 9  | loss: 0.68403 |  0:00:14s\n",
            "epoch 10 | loss: 0.66636 |  0:00:16s\n",
            "epoch 11 | loss: 0.61587 |  0:00:18s\n",
            "epoch 12 | loss: 0.63747 |  0:00:20s\n",
            "epoch 13 | loss: 0.64945 |  0:00:21s\n",
            "epoch 14 | loss: 0.62616 |  0:00:22s\n",
            "epoch 15 | loss: 0.6287  |  0:00:24s\n",
            "epoch 16 | loss: 0.66455 |  0:00:25s\n",
            "epoch 17 | loss: 0.65059 |  0:00:26s\n",
            "epoch 18 | loss: 0.62134 |  0:00:27s\n",
            "epoch 19 | loss: 0.64779 |  0:00:29s\n",
            "epoch 20 | loss: 0.63454 |  0:00:31s\n",
            "epoch 21 | loss: 0.70756 |  0:00:33s\n",
            "epoch 22 | loss: 0.68566 |  0:00:34s\n",
            "epoch 23 | loss: 0.63044 |  0:00:36s\n",
            "epoch 24 | loss: 0.63807 |  0:00:37s\n",
            "epoch 25 | loss: 0.59859 |  0:00:38s\n",
            "epoch 26 | loss: 0.62512 |  0:00:40s\n",
            "epoch 27 | loss: 0.61164 |  0:00:41s\n",
            "epoch 28 | loss: 0.64824 |  0:00:43s\n",
            "epoch 29 | loss: 0.64077 |  0:00:44s\n",
            "epoch 30 | loss: 0.61305 |  0:00:46s\n",
            "epoch 31 | loss: 0.59911 |  0:00:48s\n",
            "epoch 32 | loss: 0.58767 |  0:00:49s\n",
            "epoch 33 | loss: 0.62946 |  0:00:51s\n",
            "epoch 34 | loss: 0.60825 |  0:00:52s\n",
            "epoch 35 | loss: 0.59925 |  0:00:54s\n",
            "epoch 36 | loss: 0.57323 |  0:00:55s\n",
            "epoch 37 | loss: 0.56317 |  0:00:56s\n",
            "epoch 38 | loss: 0.56648 |  0:00:58s\n",
            "epoch 39 | loss: 0.57701 |  0:01:00s\n",
            "epoch 40 | loss: 0.56705 |  0:01:01s\n",
            "epoch 41 | loss: 0.59891 |  0:01:03s\n",
            "epoch 42 | loss: 0.57702 |  0:01:04s\n",
            "epoch 43 | loss: 0.57692 |  0:01:06s\n",
            "epoch 44 | loss: 0.56824 |  0:01:07s\n",
            "epoch 45 | loss: 0.55554 |  0:01:08s\n",
            "epoch 46 | loss: 0.54906 |  0:01:10s\n",
            "epoch 47 | loss: 0.55197 |  0:01:11s\n",
            "epoch 48 | loss: 0.54118 |  0:01:13s\n",
            "epoch 49 | loss: 0.55761 |  0:01:15s\n",
            "epoch 50 | loss: 0.54893 |  0:01:16s\n",
            "epoch 51 | loss: 0.55552 |  0:01:18s\n",
            "epoch 52 | loss: 0.55131 |  0:01:19s\n",
            "epoch 53 | loss: 0.58993 |  0:01:20s\n",
            "epoch 54 | loss: 0.56653 |  0:01:22s\n",
            "epoch 55 | loss: 0.5343  |  0:01:23s\n",
            "epoch 56 | loss: 0.53186 |  0:01:24s\n",
            "epoch 57 | loss: 0.5327  |  0:01:26s\n",
            "epoch 58 | loss: 0.54265 |  0:01:28s\n",
            "epoch 59 | loss: 0.5423  |  0:01:29s\n",
            "epoch 60 | loss: 0.61656 |  0:01:31s\n",
            "epoch 61 | loss: 0.60211 |  0:01:32s\n",
            "epoch 62 | loss: 0.57979 |  0:01:34s\n",
            "epoch 63 | loss: 0.55315 |  0:01:35s\n",
            "epoch 64 | loss: 0.53663 |  0:01:37s\n",
            "epoch 65 | loss: 0.5315  |  0:01:38s\n",
            "epoch 66 | loss: 0.52739 |  0:01:39s\n",
            "epoch 67 | loss: 0.52607 |  0:01:41s\n",
            "epoch 68 | loss: 0.53763 |  0:01:43s\n",
            "epoch 69 | loss: 0.53186 |  0:01:45s\n",
            "epoch 70 | loss: 0.56053 |  0:01:46s\n",
            "epoch 71 | loss: 0.60801 |  0:01:47s\n",
            "epoch 72 | loss: 0.57416 |  0:01:49s\n",
            "epoch 73 | loss: 0.52736 |  0:01:50s\n",
            "epoch 74 | loss: 0.51704 |  0:01:51s\n",
            "epoch 75 | loss: 0.51252 |  0:01:53s\n",
            "epoch 76 | loss: 0.52483 |  0:01:55s\n",
            "epoch 77 | loss: 0.56433 |  0:01:57s\n",
            "epoch 78 | loss: 0.52902 |  0:01:58s\n",
            "epoch 79 | loss: 0.54327 |  0:01:59s\n",
            "epoch 80 | loss: 0.55831 |  0:02:01s\n",
            "epoch 81 | loss: 0.53    |  0:02:02s\n",
            "epoch 82 | loss: 0.51393 |  0:02:04s\n",
            "epoch 83 | loss: 0.52836 |  0:02:05s\n",
            "epoch 84 | loss: 0.51248 |  0:02:06s\n",
            "epoch 85 | loss: 0.50424 |  0:02:08s\n",
            "epoch 86 | loss: 0.53053 |  0:02:10s\n",
            "epoch 87 | loss: 0.53836 |  0:02:12s\n",
            "epoch 88 | loss: 0.53474 |  0:02:13s\n",
            "epoch 89 | loss: 0.56373 |  0:02:14s\n",
            "epoch 90 | loss: 0.57896 |  0:02:16s\n",
            "epoch 91 | loss: 0.52117 |  0:02:17s\n",
            "epoch 92 | loss: 0.5478  |  0:02:18s\n",
            "epoch 93 | loss: 0.50225 |  0:02:20s\n",
            "epoch 94 | loss: 0.53056 |  0:02:21s\n",
            "epoch 95 | loss: 0.53592 |  0:02:23s\n",
            "epoch 96 | loss: 0.53898 |  0:02:25s\n",
            "epoch 97 | loss: 0.53543 |  0:02:26s\n",
            "epoch 98 | loss: 0.5134  |  0:02:28s\n",
            "epoch 99 | loss: 0.5041  |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.40579|  0:00:01s\n",
            "epoch 1  | loss: 1.75195 |  0:00:02s\n",
            "epoch 2  | loss: 1.52194 |  0:00:03s\n",
            "epoch 3  | loss: 1.37856 |  0:00:05s\n",
            "epoch 4  | loss: 1.30023 |  0:00:07s\n",
            "epoch 5  | loss: 1.33899 |  0:00:08s\n",
            "epoch 6  | loss: 1.29349 |  0:00:10s\n",
            "epoch 7  | loss: 1.2726  |  0:00:11s\n",
            "epoch 8  | loss: 1.23839 |  0:00:12s\n",
            "epoch 9  | loss: 1.28999 |  0:00:14s\n",
            "epoch 10 | loss: 1.3004  |  0:00:15s\n",
            "epoch 11 | loss: 1.25239 |  0:00:16s\n",
            "epoch 12 | loss: 1.2786  |  0:00:18s\n",
            "epoch 13 | loss: 1.21292 |  0:00:19s\n",
            "epoch 14 | loss: 1.16181 |  0:00:21s\n",
            "epoch 15 | loss: 1.16823 |  0:00:23s\n",
            "epoch 16 | loss: 1.18381 |  0:00:24s\n",
            "epoch 17 | loss: 1.21562 |  0:00:25s\n",
            "epoch 18 | loss: 1.17907 |  0:00:27s\n",
            "epoch 19 | loss: 1.14887 |  0:00:28s\n",
            "epoch 20 | loss: 1.17426 |  0:00:29s\n",
            "epoch 21 | loss: 1.14987 |  0:00:31s\n",
            "epoch 22 | loss: 1.13328 |  0:00:32s\n",
            "epoch 23 | loss: 1.17189 |  0:00:34s\n",
            "epoch 24 | loss: 1.14155 |  0:00:35s\n",
            "epoch 25 | loss: 1.13301 |  0:00:37s\n",
            "epoch 26 | loss: 1.15951 |  0:00:38s\n",
            "epoch 27 | loss: 1.17583 |  0:00:40s\n",
            "epoch 28 | loss: 1.13838 |  0:00:41s\n",
            "epoch 29 | loss: 1.13467 |  0:00:42s\n",
            "epoch 30 | loss: 1.12055 |  0:00:43s\n",
            "epoch 31 | loss: 1.10447 |  0:00:45s\n",
            "epoch 32 | loss: 1.12544 |  0:00:46s\n",
            "epoch 33 | loss: 1.10361 |  0:00:48s\n",
            "epoch 34 | loss: 1.09879 |  0:00:50s\n",
            "epoch 35 | loss: 1.11383 |  0:00:51s\n",
            "epoch 36 | loss: 1.13308 |  0:00:52s\n",
            "epoch 37 | loss: 1.16859 |  0:00:54s\n",
            "epoch 38 | loss: 1.15953 |  0:00:55s\n",
            "epoch 39 | loss: 1.15818 |  0:00:56s\n",
            "epoch 40 | loss: 1.12571 |  0:00:58s\n",
            "epoch 41 | loss: 1.15704 |  0:00:59s\n",
            "epoch 42 | loss: 1.09919 |  0:01:01s\n",
            "epoch 43 | loss: 1.12755 |  0:01:03s\n",
            "epoch 44 | loss: 1.10818 |  0:01:04s\n",
            "epoch 45 | loss: 1.11876 |  0:01:06s\n",
            "epoch 46 | loss: 1.09527 |  0:01:07s\n",
            "epoch 47 | loss: 1.12176 |  0:01:08s\n",
            "epoch 48 | loss: 1.06945 |  0:01:10s\n",
            "epoch 49 | loss: 1.09974 |  0:01:11s\n",
            "epoch 50 | loss: 1.17893 |  0:01:12s\n",
            "epoch 51 | loss: 1.12193 |  0:01:14s\n",
            "epoch 52 | loss: 1.10267 |  0:01:15s\n",
            "epoch 53 | loss: 1.09656 |  0:01:17s\n",
            "epoch 54 | loss: 1.07577 |  0:01:19s\n",
            "epoch 55 | loss: 1.09098 |  0:01:20s\n",
            "epoch 56 | loss: 1.12424 |  0:01:22s\n",
            "epoch 57 | loss: 1.1369  |  0:01:23s\n",
            "epoch 58 | loss: 1.14838 |  0:01:24s\n",
            "epoch 59 | loss: 1.13328 |  0:01:26s\n",
            "epoch 60 | loss: 1.10827 |  0:01:27s\n",
            "epoch 61 | loss: 1.1123  |  0:01:29s\n",
            "epoch 62 | loss: 1.07228 |  0:01:30s\n",
            "epoch 63 | loss: 1.09526 |  0:01:32s\n",
            "epoch 64 | loss: 1.09395 |  0:01:34s\n",
            "epoch 65 | loss: 1.08923 |  0:01:35s\n",
            "epoch 66 | loss: 1.10734 |  0:01:36s\n",
            "epoch 67 | loss: 1.09322 |  0:01:37s\n",
            "epoch 68 | loss: 1.06486 |  0:01:39s\n",
            "epoch 69 | loss: 1.09729 |  0:01:40s\n",
            "epoch 70 | loss: 1.11094 |  0:01:41s\n",
            "epoch 71 | loss: 1.08122 |  0:01:43s\n",
            "epoch 72 | loss: 1.10296 |  0:01:45s\n",
            "epoch 73 | loss: 1.09322 |  0:01:47s\n",
            "epoch 74 | loss: 1.09312 |  0:01:48s\n",
            "epoch 75 | loss: 1.07429 |  0:01:49s\n",
            "epoch 76 | loss: 1.07127 |  0:01:51s\n",
            "epoch 77 | loss: 1.08281 |  0:01:52s\n",
            "epoch 78 | loss: 1.10985 |  0:01:53s\n",
            "epoch 79 | loss: 1.0849  |  0:01:55s\n",
            "epoch 80 | loss: 1.0789  |  0:01:56s\n",
            "epoch 81 | loss: 1.08442 |  0:01:58s\n",
            "epoch 82 | loss: 1.06484 |  0:02:00s\n",
            "epoch 83 | loss: 1.09266 |  0:02:01s\n",
            "epoch 84 | loss: 1.06747 |  0:02:02s\n",
            "epoch 85 | loss: 1.07813 |  0:02:04s\n",
            "epoch 86 | loss: 1.06507 |  0:02:05s\n",
            "epoch 87 | loss: 1.0684  |  0:02:06s\n",
            "epoch 88 | loss: 1.05877 |  0:02:08s\n",
            "epoch 89 | loss: 1.09031 |  0:02:09s\n",
            "epoch 90 | loss: 1.08342 |  0:02:10s\n",
            "epoch 91 | loss: 1.08612 |  0:02:12s\n",
            "epoch 92 | loss: 1.09013 |  0:02:14s\n",
            "epoch 93 | loss: 1.08021 |  0:02:16s\n",
            "epoch 94 | loss: 1.08995 |  0:02:17s\n",
            "epoch 95 | loss: 1.12455 |  0:02:18s\n",
            "epoch 96 | loss: 1.11069 |  0:02:19s\n",
            "epoch 97 | loss: 1.10856 |  0:02:21s\n",
            "epoch 98 | loss: 1.07903 |  0:02:22s\n",
            "epoch 99 | loss: 1.07296 |  0:02:23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14.23789|  0:00:01s\n",
            "epoch 1  | loss: 1.19307 |  0:00:03s\n",
            "epoch 2  | loss: 0.84874 |  0:00:05s\n",
            "epoch 3  | loss: 0.82514 |  0:00:06s\n",
            "epoch 4  | loss: 0.82964 |  0:00:08s\n",
            "epoch 5  | loss: 0.74861 |  0:00:09s\n",
            "epoch 6  | loss: 0.81242 |  0:00:10s\n",
            "epoch 7  | loss: 0.75559 |  0:00:12s\n",
            "epoch 8  | loss: 0.75987 |  0:00:13s\n",
            "epoch 9  | loss: 0.75922 |  0:00:15s\n",
            "epoch 10 | loss: 0.70187 |  0:00:17s\n",
            "epoch 11 | loss: 0.6702  |  0:00:18s\n",
            "epoch 12 | loss: 0.71254 |  0:00:20s\n",
            "epoch 13 | loss: 0.69557 |  0:00:21s\n",
            "epoch 14 | loss: 0.75597 |  0:00:22s\n",
            "epoch 15 | loss: 0.71829 |  0:00:24s\n",
            "epoch 16 | loss: 0.65389 |  0:00:25s\n",
            "epoch 17 | loss: 0.65476 |  0:00:27s\n",
            "epoch 18 | loss: 0.64988 |  0:00:28s\n",
            "epoch 19 | loss: 0.66216 |  0:00:30s\n",
            "epoch 20 | loss: 0.64542 |  0:00:32s\n",
            "epoch 21 | loss: 0.60342 |  0:00:33s\n",
            "epoch 22 | loss: 0.60742 |  0:00:35s\n",
            "epoch 23 | loss: 0.62605 |  0:00:36s\n",
            "epoch 24 | loss: 0.60191 |  0:00:37s\n",
            "epoch 25 | loss: 0.60394 |  0:00:39s\n",
            "epoch 26 | loss: 0.60922 |  0:00:40s\n",
            "epoch 27 | loss: 0.61881 |  0:00:42s\n",
            "epoch 28 | loss: 0.59919 |  0:00:44s\n",
            "epoch 29 | loss: 0.61271 |  0:00:45s\n",
            "epoch 30 | loss: 0.59858 |  0:00:47s\n",
            "epoch 31 | loss: 0.56691 |  0:00:48s\n",
            "epoch 32 | loss: 0.58629 |  0:00:50s\n",
            "epoch 33 | loss: 0.579   |  0:00:51s\n",
            "epoch 34 | loss: 0.5918  |  0:00:52s\n",
            "epoch 35 | loss: 0.57681 |  0:00:54s\n",
            "epoch 36 | loss: 0.57256 |  0:00:55s\n",
            "epoch 37 | loss: 0.56569 |  0:00:57s\n",
            "epoch 38 | loss: 0.56614 |  0:00:59s\n",
            "epoch 39 | loss: 0.53783 |  0:01:00s\n",
            "epoch 40 | loss: 0.54146 |  0:01:02s\n",
            "epoch 41 | loss: 0.58181 |  0:01:03s\n",
            "epoch 42 | loss: 0.55514 |  0:01:04s\n",
            "epoch 43 | loss: 0.54833 |  0:01:06s\n",
            "epoch 44 | loss: 0.57993 |  0:01:07s\n",
            "epoch 45 | loss: 0.55132 |  0:01:09s\n",
            "epoch 46 | loss: 0.52638 |  0:01:11s\n",
            "epoch 47 | loss: 0.56348 |  0:01:13s\n",
            "epoch 48 | loss: 0.53987 |  0:01:14s\n",
            "epoch 49 | loss: 0.57052 |  0:01:15s\n",
            "epoch 50 | loss: 0.61946 |  0:01:16s\n",
            "epoch 51 | loss: 0.6089  |  0:01:18s\n",
            "epoch 52 | loss: 0.5883  |  0:01:19s\n",
            "epoch 53 | loss: 0.58498 |  0:01:21s\n",
            "epoch 54 | loss: 0.54932 |  0:01:22s\n",
            "epoch 55 | loss: 0.57574 |  0:01:24s\n",
            "epoch 56 | loss: 0.54848 |  0:01:26s\n",
            "epoch 57 | loss: 0.56223 |  0:01:27s\n",
            "epoch 58 | loss: 0.59595 |  0:01:29s\n",
            "epoch 59 | loss: 0.58643 |  0:01:30s\n",
            "epoch 60 | loss: 0.52111 |  0:01:32s\n",
            "epoch 61 | loss: 0.58479 |  0:01:33s\n",
            "epoch 62 | loss: 0.62092 |  0:01:34s\n",
            "epoch 63 | loss: 0.58222 |  0:01:36s\n",
            "epoch 64 | loss: 0.5564  |  0:01:37s\n",
            "epoch 65 | loss: 0.56828 |  0:01:39s\n",
            "epoch 66 | loss: 0.6008  |  0:01:41s\n",
            "epoch 67 | loss: 0.54767 |  0:01:42s\n",
            "epoch 68 | loss: 0.53655 |  0:01:43s\n",
            "epoch 69 | loss: 0.5529  |  0:01:45s\n",
            "epoch 70 | loss: 0.53696 |  0:01:46s\n",
            "epoch 71 | loss: 0.52954 |  0:01:47s\n",
            "epoch 72 | loss: 0.54099 |  0:01:49s\n",
            "epoch 73 | loss: 0.53259 |  0:01:50s\n",
            "epoch 74 | loss: 0.56811 |  0:01:52s\n",
            "epoch 75 | loss: 0.52533 |  0:01:54s\n",
            "epoch 76 | loss: 0.55153 |  0:01:56s\n",
            "epoch 77 | loss: 0.54052 |  0:01:57s\n",
            "epoch 78 | loss: 0.5224  |  0:01:58s\n",
            "epoch 79 | loss: 0.53449 |  0:02:00s\n",
            "epoch 80 | loss: 0.53499 |  0:02:01s\n",
            "epoch 81 | loss: 0.52064 |  0:02:02s\n",
            "epoch 82 | loss: 0.50602 |  0:02:04s\n",
            "epoch 83 | loss: 0.51758 |  0:02:06s\n",
            "epoch 84 | loss: 0.50843 |  0:02:08s\n",
            "epoch 85 | loss: 0.51396 |  0:02:09s\n",
            "epoch 86 | loss: 0.51189 |  0:02:10s\n",
            "epoch 87 | loss: 0.5199  |  0:02:12s\n",
            "epoch 88 | loss: 0.51066 |  0:02:13s\n",
            "epoch 89 | loss: 0.50506 |  0:02:14s\n",
            "epoch 90 | loss: 0.51852 |  0:02:16s\n",
            "epoch 91 | loss: 0.49558 |  0:02:17s\n",
            "epoch 92 | loss: 0.52558 |  0:02:18s\n",
            "epoch 93 | loss: 0.51822 |  0:02:20s\n",
            "epoch 94 | loss: 0.50269 |  0:02:22s\n",
            "epoch 95 | loss: 0.52919 |  0:02:23s\n",
            "epoch 96 | loss: 0.5387  |  0:02:25s\n",
            "epoch 97 | loss: 0.49936 |  0:02:26s\n",
            "epoch 98 | loss: 0.49112 |  0:02:27s\n",
            "epoch 99 | loss: 0.51255 |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 16.43465|  0:00:01s\n",
            "epoch 1  | loss: 1.76227 |  0:00:02s\n",
            "epoch 2  | loss: 1.325   |  0:00:04s\n",
            "epoch 3  | loss: 1.2136  |  0:00:06s\n",
            "epoch 4  | loss: 1.20644 |  0:00:07s\n",
            "epoch 5  | loss: 1.25624 |  0:00:09s\n",
            "epoch 6  | loss: 1.13455 |  0:00:10s\n",
            "epoch 7  | loss: 1.17847 |  0:00:12s\n",
            "epoch 8  | loss: 1.10499 |  0:00:13s\n",
            "epoch 9  | loss: 1.13318 |  0:00:14s\n",
            "epoch 10 | loss: 1.1168  |  0:00:16s\n",
            "epoch 11 | loss: 1.19871 |  0:00:18s\n",
            "epoch 12 | loss: 1.09848 |  0:00:20s\n",
            "epoch 13 | loss: 1.06016 |  0:00:21s\n",
            "epoch 14 | loss: 1.05851 |  0:00:23s\n",
            "epoch 15 | loss: 1.07848 |  0:00:24s\n",
            "epoch 16 | loss: 1.03339 |  0:00:25s\n",
            "epoch 17 | loss: 1.01753 |  0:00:27s\n",
            "epoch 18 | loss: 1.05205 |  0:00:28s\n",
            "epoch 19 | loss: 0.98502 |  0:00:29s\n",
            "epoch 20 | loss: 0.96985 |  0:00:31s\n",
            "epoch 21 | loss: 0.96258 |  0:00:33s\n",
            "epoch 22 | loss: 0.98297 |  0:00:35s\n",
            "epoch 23 | loss: 0.962   |  0:00:36s\n",
            "epoch 24 | loss: 1.00265 |  0:00:38s\n",
            "epoch 25 | loss: 0.9852  |  0:00:39s\n",
            "epoch 26 | loss: 0.99667 |  0:00:40s\n",
            "epoch 27 | loss: 0.96593 |  0:00:42s\n",
            "epoch 28 | loss: 0.96631 |  0:00:43s\n",
            "epoch 29 | loss: 0.95921 |  0:00:45s\n",
            "epoch 30 | loss: 0.95065 |  0:00:47s\n",
            "epoch 31 | loss: 0.95013 |  0:00:48s\n",
            "epoch 32 | loss: 0.94297 |  0:00:50s\n",
            "epoch 33 | loss: 0.94085 |  0:00:51s\n",
            "epoch 34 | loss: 0.94023 |  0:00:53s\n",
            "epoch 35 | loss: 0.96316 |  0:00:54s\n",
            "epoch 36 | loss: 0.96993 |  0:00:55s\n",
            "epoch 37 | loss: 0.99348 |  0:00:57s\n",
            "epoch 38 | loss: 0.99621 |  0:00:58s\n",
            "epoch 39 | loss: 0.94905 |  0:01:00s\n",
            "epoch 40 | loss: 0.99078 |  0:01:02s\n",
            "epoch 41 | loss: 1.02892 |  0:01:03s\n",
            "epoch 42 | loss: 0.96977 |  0:01:05s\n",
            "epoch 43 | loss: 0.93837 |  0:01:06s\n",
            "epoch 44 | loss: 0.97682 |  0:01:07s\n",
            "epoch 45 | loss: 0.99493 |  0:01:09s\n",
            "epoch 46 | loss: 0.9481  |  0:01:10s\n",
            "epoch 47 | loss: 0.98967 |  0:01:12s\n",
            "epoch 48 | loss: 0.96334 |  0:01:14s\n",
            "epoch 49 | loss: 0.93649 |  0:01:16s\n",
            "epoch 50 | loss: 0.96025 |  0:01:17s\n",
            "epoch 51 | loss: 0.92683 |  0:01:18s\n",
            "epoch 52 | loss: 0.91722 |  0:01:20s\n",
            "epoch 53 | loss: 0.99299 |  0:01:21s\n",
            "epoch 54 | loss: 0.95233 |  0:01:22s\n",
            "epoch 55 | loss: 0.91957 |  0:01:24s\n",
            "epoch 56 | loss: 0.98151 |  0:01:25s\n",
            "epoch 57 | loss: 0.9895  |  0:01:27s\n",
            "epoch 58 | loss: 0.92596 |  0:01:29s\n",
            "epoch 59 | loss: 0.93897 |  0:01:31s\n",
            "epoch 60 | loss: 0.9365  |  0:01:32s\n",
            "epoch 61 | loss: 0.91881 |  0:01:34s\n",
            "epoch 62 | loss: 0.89798 |  0:01:35s\n",
            "epoch 63 | loss: 0.91347 |  0:01:36s\n",
            "epoch 64 | loss: 0.92931 |  0:01:38s\n",
            "epoch 65 | loss: 0.92378 |  0:01:39s\n",
            "epoch 66 | loss: 0.92652 |  0:01:41s\n",
            "epoch 67 | loss: 0.90335 |  0:01:43s\n",
            "epoch 68 | loss: 0.95475 |  0:01:44s\n",
            "epoch 69 | loss: 0.9865  |  0:01:46s\n",
            "epoch 70 | loss: 0.89995 |  0:01:47s\n",
            "epoch 71 | loss: 0.91723 |  0:01:48s\n",
            "epoch 72 | loss: 0.93565 |  0:01:50s\n",
            "epoch 73 | loss: 0.9067  |  0:01:51s\n",
            "epoch 74 | loss: 0.90808 |  0:01:52s\n",
            "epoch 75 | loss: 0.90364 |  0:01:54s\n",
            "epoch 76 | loss: 0.92938 |  0:01:56s\n",
            "epoch 77 | loss: 0.93562 |  0:01:58s\n",
            "epoch 78 | loss: 0.91544 |  0:01:59s\n",
            "epoch 79 | loss: 0.91898 |  0:02:01s\n",
            "epoch 80 | loss: 0.89497 |  0:02:02s\n",
            "epoch 81 | loss: 0.89841 |  0:02:03s\n",
            "epoch 82 | loss: 0.89819 |  0:02:05s\n",
            "epoch 83 | loss: 0.88815 |  0:02:06s\n",
            "epoch 84 | loss: 0.90477 |  0:02:08s\n",
            "epoch 85 | loss: 0.88574 |  0:02:09s\n",
            "epoch 86 | loss: 0.87301 |  0:02:11s\n",
            "epoch 87 | loss: 0.95743 |  0:02:13s\n",
            "epoch 88 | loss: 0.9077  |  0:02:14s\n",
            "epoch 89 | loss: 0.93251 |  0:02:15s\n",
            "epoch 90 | loss: 0.88081 |  0:02:17s\n",
            "epoch 91 | loss: 0.90203 |  0:02:18s\n",
            "epoch 92 | loss: 0.87983 |  0:02:19s\n",
            "epoch 93 | loss: 0.91471 |  0:02:21s\n",
            "epoch 94 | loss: 0.90404 |  0:02:23s\n",
            "epoch 95 | loss: 0.90765 |  0:02:25s\n",
            "epoch 96 | loss: 0.88316 |  0:02:26s\n",
            "epoch 97 | loss: 0.91624 |  0:02:27s\n",
            "epoch 98 | loss: 0.87654 |  0:02:29s\n",
            "epoch 99 | loss: 0.92892 |  0:02:30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.16521|  0:00:01s\n",
            "epoch 1  | loss: 1.74641 |  0:00:02s\n",
            "epoch 2  | loss: 1.11207 |  0:00:04s\n",
            "epoch 3  | loss: 0.98668 |  0:00:06s\n",
            "epoch 4  | loss: 0.96223 |  0:00:08s\n",
            "epoch 5  | loss: 0.88638 |  0:00:09s\n",
            "epoch 6  | loss: 0.86976 |  0:00:10s\n",
            "epoch 7  | loss: 0.88122 |  0:00:12s\n",
            "epoch 8  | loss: 0.87018 |  0:00:13s\n",
            "epoch 9  | loss: 0.83068 |  0:00:15s\n",
            "epoch 10 | loss: 0.77341 |  0:00:16s\n",
            "epoch 11 | loss: 0.80629 |  0:00:17s\n",
            "epoch 12 | loss: 0.75311 |  0:00:19s\n",
            "epoch 13 | loss: 0.72907 |  0:00:21s\n",
            "epoch 14 | loss: 0.73    |  0:00:23s\n",
            "epoch 15 | loss: 0.68515 |  0:00:24s\n",
            "epoch 16 | loss: 0.70255 |  0:00:26s\n",
            "epoch 17 | loss: 0.76844 |  0:00:27s\n",
            "epoch 18 | loss: 0.80929 |  0:00:28s\n",
            "epoch 19 | loss: 0.72439 |  0:00:30s\n",
            "epoch 20 | loss: 0.69849 |  0:00:31s\n",
            "epoch 21 | loss: 0.64296 |  0:00:33s\n",
            "epoch 22 | loss: 0.6644  |  0:00:35s\n",
            "epoch 23 | loss: 0.66675 |  0:00:36s\n",
            "epoch 24 | loss: 0.64871 |  0:00:38s\n",
            "epoch 25 | loss: 0.63121 |  0:00:39s\n",
            "epoch 26 | loss: 0.68052 |  0:00:40s\n",
            "epoch 27 | loss: 0.64778 |  0:00:42s\n",
            "epoch 28 | loss: 0.69535 |  0:00:43s\n",
            "epoch 29 | loss: 0.75498 |  0:00:44s\n",
            "epoch 30 | loss: 0.66399 |  0:00:46s\n",
            "epoch 31 | loss: 0.61484 |  0:00:48s\n",
            "epoch 32 | loss: 0.64174 |  0:00:50s\n",
            "epoch 33 | loss: 0.64251 |  0:00:51s\n",
            "epoch 34 | loss: 0.61511 |  0:00:52s\n",
            "epoch 35 | loss: 0.63751 |  0:00:54s\n",
            "epoch 36 | loss: 0.61517 |  0:00:55s\n",
            "epoch 37 | loss: 0.64739 |  0:00:56s\n",
            "epoch 38 | loss: 0.61537 |  0:00:58s\n",
            "epoch 39 | loss: 0.62952 |  0:00:59s\n",
            "epoch 40 | loss: 0.59205 |  0:01:01s\n",
            "epoch 41 | loss: 0.59572 |  0:01:03s\n",
            "epoch 42 | loss: 0.5808  |  0:01:05s\n",
            "epoch 43 | loss: 0.57631 |  0:01:06s\n",
            "epoch 44 | loss: 0.60078 |  0:01:07s\n",
            "epoch 45 | loss: 0.58649 |  0:01:09s\n",
            "epoch 46 | loss: 0.59113 |  0:01:10s\n",
            "epoch 47 | loss: 0.57884 |  0:01:11s\n",
            "epoch 48 | loss: 0.60957 |  0:01:13s\n",
            "epoch 49 | loss: 0.56764 |  0:01:15s\n",
            "epoch 50 | loss: 0.59345 |  0:01:17s\n",
            "epoch 51 | loss: 0.58117 |  0:01:18s\n",
            "epoch 52 | loss: 0.59515 |  0:01:19s\n",
            "epoch 53 | loss: 0.58729 |  0:01:21s\n",
            "epoch 54 | loss: 0.5545  |  0:01:22s\n",
            "epoch 55 | loss: 0.57461 |  0:01:23s\n",
            "epoch 56 | loss: 0.54613 |  0:01:25s\n",
            "epoch 57 | loss: 0.55416 |  0:01:26s\n",
            "epoch 58 | loss: 0.56937 |  0:01:28s\n",
            "epoch 59 | loss: 0.56353 |  0:01:30s\n",
            "epoch 60 | loss: 0.59591 |  0:01:32s\n",
            "epoch 61 | loss: 0.62051 |  0:01:33s\n",
            "epoch 62 | loss: 0.58755 |  0:01:34s\n",
            "epoch 63 | loss: 0.61872 |  0:01:36s\n",
            "epoch 64 | loss: 0.56817 |  0:01:37s\n",
            "epoch 65 | loss: 0.60623 |  0:01:38s\n",
            "epoch 66 | loss: 0.59096 |  0:01:40s\n",
            "epoch 67 | loss: 0.58426 |  0:01:41s\n",
            "epoch 68 | loss: 0.55355 |  0:01:43s\n",
            "epoch 69 | loss: 0.56085 |  0:01:45s\n",
            "epoch 70 | loss: 0.56163 |  0:01:46s\n",
            "epoch 71 | loss: 0.5521  |  0:01:48s\n",
            "epoch 72 | loss: 0.55269 |  0:01:49s\n",
            "epoch 73 | loss: 0.55403 |  0:01:50s\n",
            "epoch 74 | loss: 0.54356 |  0:01:52s\n",
            "epoch 75 | loss: 0.57726 |  0:01:53s\n",
            "epoch 76 | loss: 0.53989 |  0:01:54s\n",
            "epoch 77 | loss: 0.54116 |  0:01:56s\n",
            "epoch 78 | loss: 0.55701 |  0:01:58s\n",
            "epoch 79 | loss: 0.55506 |  0:02:00s\n",
            "epoch 80 | loss: 0.54197 |  0:02:01s\n",
            "epoch 81 | loss: 0.59376 |  0:02:02s\n",
            "epoch 82 | loss: 0.59422 |  0:02:04s\n",
            "epoch 83 | loss: 0.53471 |  0:02:05s\n",
            "epoch 84 | loss: 0.55159 |  0:02:06s\n",
            "epoch 85 | loss: 0.52195 |  0:02:08s\n",
            "epoch 86 | loss: 0.52003 |  0:02:10s\n",
            "epoch 87 | loss: 0.52949 |  0:02:12s\n",
            "epoch 88 | loss: 0.53109 |  0:02:13s\n",
            "epoch 89 | loss: 0.49827 |  0:02:15s\n",
            "epoch 90 | loss: 0.52662 |  0:02:16s\n",
            "epoch 91 | loss: 0.53603 |  0:02:17s\n",
            "epoch 92 | loss: 0.53208 |  0:02:19s\n",
            "epoch 93 | loss: 0.52446 |  0:02:20s\n",
            "epoch 94 | loss: 0.51873 |  0:02:21s\n",
            "epoch 95 | loss: 0.53449 |  0:02:23s\n",
            "epoch 96 | loss: 0.52416 |  0:02:25s\n",
            "epoch 97 | loss: 0.50784 |  0:02:27s\n",
            "epoch 98 | loss: 0.52019 |  0:02:28s\n",
            "epoch 99 | loss: 0.53987 |  0:02:29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 10.78992|  0:00:01s\n",
            "epoch 1  | loss: 1.99316 |  0:00:02s\n",
            "epoch 2  | loss: 1.71495 |  0:00:04s\n",
            "epoch 3  | loss: 1.65664 |  0:00:05s\n",
            "epoch 4  | loss: 1.49783 |  0:00:07s\n",
            "epoch 5  | loss: 1.49513 |  0:00:08s\n",
            "epoch 6  | loss: 1.45464 |  0:00:10s\n",
            "epoch 7  | loss: 1.45948 |  0:00:12s\n",
            "epoch 8  | loss: 1.55412 |  0:00:13s\n",
            "epoch 9  | loss: 1.36763 |  0:00:14s\n",
            "epoch 10 | loss: 1.39914 |  0:00:16s\n",
            "epoch 11 | loss: 1.4596  |  0:00:17s\n",
            "epoch 12 | loss: 1.3615  |  0:00:19s\n",
            "epoch 13 | loss: 1.35068 |  0:00:20s\n",
            "epoch 14 | loss: 1.3393  |  0:00:22s\n",
            "epoch 15 | loss: 1.32043 |  0:00:24s\n",
            "epoch 16 | loss: 1.31771 |  0:00:25s\n",
            "epoch 17 | loss: 1.32256 |  0:00:27s\n",
            "epoch 18 | loss: 1.3649  |  0:00:28s\n",
            "epoch 19 | loss: 1.34947 |  0:00:29s\n",
            "epoch 20 | loss: 1.32172 |  0:00:31s\n",
            "epoch 21 | loss: 1.36729 |  0:00:32s\n",
            "epoch 22 | loss: 1.35699 |  0:00:33s\n",
            "epoch 23 | loss: 1.29685 |  0:00:35s\n",
            "epoch 24 | loss: 1.25844 |  0:00:37s\n",
            "epoch 25 | loss: 1.27916 |  0:00:39s\n",
            "epoch 26 | loss: 1.28595 |  0:00:40s\n",
            "epoch 27 | loss: 1.33732 |  0:00:41s\n",
            "epoch 28 | loss: 1.24524 |  0:00:43s\n",
            "epoch 29 | loss: 1.30346 |  0:00:44s\n",
            "epoch 30 | loss: 1.27126 |  0:00:46s\n",
            "epoch 31 | loss: 1.28683 |  0:00:47s\n",
            "epoch 32 | loss: 1.28158 |  0:00:49s\n",
            "epoch 33 | loss: 1.2458  |  0:00:51s\n",
            "epoch 34 | loss: 1.30203 |  0:00:52s\n",
            "epoch 35 | loss: 1.37089 |  0:00:54s\n",
            "epoch 36 | loss: 1.33013 |  0:00:55s\n",
            "epoch 37 | loss: 1.29321 |  0:00:56s\n",
            "epoch 38 | loss: 1.27563 |  0:00:58s\n",
            "epoch 39 | loss: 1.25731 |  0:00:59s\n",
            "epoch 40 | loss: 1.27626 |  0:01:01s\n",
            "epoch 41 | loss: 1.23445 |  0:01:02s\n",
            "epoch 42 | loss: 1.23509 |  0:01:04s\n",
            "epoch 43 | loss: 1.24016 |  0:01:06s\n",
            "epoch 44 | loss: 1.27889 |  0:01:07s\n",
            "epoch 45 | loss: 1.31244 |  0:01:09s\n",
            "epoch 46 | loss: 1.25064 |  0:01:10s\n",
            "epoch 47 | loss: 1.23999 |  0:01:11s\n",
            "epoch 48 | loss: 1.21835 |  0:01:13s\n",
            "epoch 49 | loss: 1.22188 |  0:01:14s\n",
            "epoch 50 | loss: 1.2802  |  0:01:15s\n",
            "epoch 51 | loss: 1.21842 |  0:01:17s\n",
            "epoch 52 | loss: 1.26034 |  0:01:19s\n",
            "epoch 53 | loss: 1.18027 |  0:01:21s\n",
            "epoch 54 | loss: 1.18362 |  0:01:22s\n",
            "epoch 55 | loss: 1.1934  |  0:01:23s\n",
            "epoch 56 | loss: 1.20063 |  0:01:25s\n",
            "epoch 57 | loss: 1.20388 |  0:01:26s\n",
            "epoch 58 | loss: 1.22924 |  0:01:27s\n",
            "epoch 59 | loss: 1.24072 |  0:01:29s\n",
            "epoch 60 | loss: 1.19743 |  0:01:30s\n",
            "epoch 61 | loss: 1.18719 |  0:01:32s\n",
            "epoch 62 | loss: 1.26766 |  0:01:34s\n",
            "epoch 63 | loss: 1.21395 |  0:01:35s\n",
            "epoch 64 | loss: 1.17443 |  0:01:37s\n",
            "epoch 65 | loss: 1.21854 |  0:01:38s\n",
            "epoch 66 | loss: 1.22987 |  0:01:39s\n",
            "epoch 67 | loss: 1.20184 |  0:01:41s\n",
            "epoch 68 | loss: 1.19956 |  0:01:42s\n",
            "epoch 69 | loss: 1.21538 |  0:01:43s\n",
            "epoch 70 | loss: 1.23574 |  0:01:46s\n",
            "epoch 71 | loss: 1.18421 |  0:01:48s\n",
            "epoch 72 | loss: 1.183   |  0:01:49s\n",
            "epoch 73 | loss: 1.19598 |  0:01:50s\n",
            "epoch 74 | loss: 1.17858 |  0:01:52s\n",
            "epoch 75 | loss: 1.17754 |  0:01:53s\n",
            "epoch 76 | loss: 1.15619 |  0:01:54s\n",
            "epoch 77 | loss: 1.16482 |  0:01:56s\n",
            "epoch 78 | loss: 1.16291 |  0:01:57s\n",
            "epoch 79 | loss: 1.12519 |  0:01:59s\n",
            "epoch 80 | loss: 1.14771 |  0:02:01s\n",
            "epoch 81 | loss: 1.13682 |  0:02:02s\n",
            "epoch 82 | loss: 1.14377 |  0:02:04s\n",
            "epoch 83 | loss: 1.10769 |  0:02:05s\n",
            "epoch 84 | loss: 1.1271  |  0:02:07s\n",
            "epoch 85 | loss: 1.12498 |  0:02:08s\n",
            "epoch 86 | loss: 1.12346 |  0:02:10s\n",
            "epoch 87 | loss: 1.13802 |  0:02:11s\n",
            "epoch 88 | loss: 1.14319 |  0:02:13s\n",
            "epoch 89 | loss: 1.13609 |  0:02:15s\n",
            "epoch 90 | loss: 1.10731 |  0:02:16s\n",
            "epoch 91 | loss: 1.13275 |  0:02:18s\n",
            "epoch 92 | loss: 1.17314 |  0:02:19s\n",
            "epoch 93 | loss: 1.14617 |  0:02:20s\n",
            "epoch 94 | loss: 1.16127 |  0:02:22s\n",
            "epoch 95 | loss: 1.1391  |  0:02:23s\n",
            "epoch 96 | loss: 1.12808 |  0:02:24s\n",
            "epoch 97 | loss: 1.15247 |  0:02:26s\n",
            "epoch 98 | loss: 1.15841 |  0:02:28s\n",
            "epoch 99 | loss: 1.14738 |  0:02:30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 34.897  |  0:00:01s\n",
            "epoch 1  | loss: 1.61177 |  0:00:03s\n",
            "epoch 2  | loss: 1.13683 |  0:00:05s\n",
            "epoch 3  | loss: 1.03633 |  0:00:07s\n",
            "epoch 4  | loss: 1.02451 |  0:00:08s\n",
            "epoch 5  | loss: 0.96252 |  0:00:11s\n",
            "epoch 6  | loss: 0.9505  |  0:00:13s\n",
            "epoch 7  | loss: 0.95385 |  0:00:15s\n",
            "epoch 8  | loss: 0.93857 |  0:00:17s\n",
            "epoch 9  | loss: 0.88453 |  0:00:18s\n",
            "epoch 10 | loss: 0.8891  |  0:00:20s\n",
            "epoch 11 | loss: 0.86147 |  0:00:22s\n",
            "epoch 12 | loss: 0.83368 |  0:00:24s\n",
            "epoch 13 | loss: 0.82138 |  0:00:27s\n",
            "epoch 14 | loss: 0.81671 |  0:00:28s\n",
            "epoch 15 | loss: 0.8166  |  0:00:30s\n",
            "epoch 16 | loss: 0.86164 |  0:00:32s\n",
            "epoch 17 | loss: 0.90498 |  0:00:34s\n",
            "epoch 18 | loss: 0.8249  |  0:00:35s\n",
            "epoch 19 | loss: 0.78572 |  0:00:37s\n",
            "epoch 20 | loss: 0.7822  |  0:00:40s\n",
            "epoch 21 | loss: 0.78013 |  0:00:42s\n",
            "epoch 22 | loss: 0.79623 |  0:00:44s\n",
            "epoch 23 | loss: 0.79076 |  0:00:45s\n",
            "epoch 24 | loss: 0.83945 |  0:00:47s\n",
            "epoch 25 | loss: 0.77873 |  0:00:49s\n",
            "epoch 26 | loss: 0.76252 |  0:00:51s\n",
            "epoch 27 | loss: 0.77857 |  0:00:53s\n",
            "epoch 28 | loss: 0.76603 |  0:00:55s\n",
            "epoch 29 | loss: 0.8065  |  0:00:57s\n",
            "epoch 30 | loss: 0.83366 |  0:00:59s\n",
            "epoch 31 | loss: 0.7912  |  0:01:01s\n",
            "epoch 32 | loss: 0.78893 |  0:01:02s\n",
            "epoch 33 | loss: 0.82451 |  0:01:04s\n",
            "epoch 34 | loss: 0.81017 |  0:01:07s\n",
            "epoch 35 | loss: 0.8176  |  0:01:09s\n",
            "epoch 36 | loss: 0.79741 |  0:01:11s\n",
            "epoch 37 | loss: 0.80084 |  0:01:12s\n",
            "epoch 38 | loss: 0.78057 |  0:01:14s\n",
            "epoch 39 | loss: 0.76499 |  0:01:16s\n",
            "epoch 40 | loss: 0.81578 |  0:01:17s\n",
            "epoch 41 | loss: 0.8247  |  0:01:20s\n",
            "epoch 42 | loss: 0.77029 |  0:01:22s\n",
            "epoch 43 | loss: 0.80765 |  0:01:24s\n",
            "epoch 44 | loss: 0.77569 |  0:01:26s\n",
            "epoch 45 | loss: 0.78571 |  0:01:27s\n",
            "epoch 46 | loss: 0.81244 |  0:01:29s\n",
            "epoch 47 | loss: 0.74712 |  0:01:31s\n",
            "epoch 48 | loss: 0.78986 |  0:01:33s\n",
            "epoch 49 | loss: 0.78877 |  0:01:35s\n",
            "epoch 50 | loss: 0.75316 |  0:01:37s\n",
            "epoch 51 | loss: 0.79056 |  0:01:39s\n",
            "epoch 52 | loss: 0.81429 |  0:01:41s\n",
            "epoch 53 | loss: 0.82579 |  0:01:43s\n",
            "epoch 54 | loss: 0.83826 |  0:01:44s\n",
            "epoch 55 | loss: 0.79319 |  0:01:46s\n",
            "epoch 56 | loss: 0.81763 |  0:01:49s\n",
            "epoch 57 | loss: 0.83993 |  0:01:51s\n",
            "epoch 58 | loss: 0.8673  |  0:01:52s\n",
            "epoch 59 | loss: 0.8847  |  0:01:54s\n",
            "epoch 60 | loss: 0.83463 |  0:01:56s\n",
            "epoch 61 | loss: 0.86682 |  0:01:57s\n",
            "epoch 62 | loss: 0.86546 |  0:01:59s\n",
            "epoch 63 | loss: 0.89702 |  0:02:01s\n",
            "epoch 64 | loss: 0.83492 |  0:02:04s\n",
            "epoch 65 | loss: 0.82135 |  0:02:06s\n",
            "epoch 66 | loss: 0.79478 |  0:02:07s\n",
            "epoch 67 | loss: 0.7925  |  0:02:09s\n",
            "epoch 68 | loss: 0.78651 |  0:02:11s\n",
            "epoch 69 | loss: 0.79863 |  0:02:13s\n",
            "epoch 70 | loss: 0.80937 |  0:02:15s\n",
            "epoch 71 | loss: 0.81462 |  0:02:17s\n",
            "epoch 72 | loss: 0.85941 |  0:02:19s\n",
            "epoch 73 | loss: 0.82981 |  0:02:21s\n",
            "epoch 74 | loss: 0.77725 |  0:02:22s\n",
            "epoch 75 | loss: 0.76913 |  0:02:24s\n",
            "epoch 76 | loss: 0.77518 |  0:02:26s\n",
            "epoch 77 | loss: 0.80223 |  0:02:28s\n",
            "epoch 78 | loss: 0.81355 |  0:02:30s\n",
            "epoch 79 | loss: 0.74932 |  0:02:32s\n",
            "epoch 80 | loss: 0.78965 |  0:02:34s\n",
            "epoch 81 | loss: 0.77368 |  0:02:36s\n",
            "epoch 82 | loss: 0.80946 |  0:02:38s\n",
            "epoch 83 | loss: 0.83816 |  0:02:39s\n",
            "epoch 84 | loss: 0.8662  |  0:02:41s\n",
            "epoch 85 | loss: 0.83204 |  0:02:43s\n",
            "epoch 86 | loss: 0.7844  |  0:02:46s\n",
            "epoch 87 | loss: 0.80154 |  0:02:48s\n",
            "epoch 88 | loss: 0.80199 |  0:02:49s\n",
            "epoch 89 | loss: 0.79147 |  0:02:51s\n",
            "epoch 90 | loss: 0.79374 |  0:02:53s\n",
            "epoch 91 | loss: 0.78393 |  0:02:54s\n",
            "epoch 92 | loss: 0.74913 |  0:02:57s\n",
            "epoch 93 | loss: 0.74931 |  0:02:59s\n",
            "epoch 94 | loss: 0.75992 |  0:03:01s\n",
            "epoch 95 | loss: 0.76795 |  0:03:03s\n",
            "epoch 96 | loss: 0.82963 |  0:03:04s\n",
            "epoch 97 | loss: 0.7795  |  0:03:06s\n",
            "epoch 98 | loss: 0.80033 |  0:03:08s\n",
            "epoch 99 | loss: 0.78856 |  0:03:10s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.74154 |  0:00:02s\n",
            "epoch 1  | loss: 1.33291 |  0:00:04s\n",
            "epoch 2  | loss: 1.18027 |  0:00:05s\n",
            "epoch 3  | loss: 0.8984  |  0:00:07s\n",
            "epoch 4  | loss: 0.87191 |  0:00:09s\n",
            "epoch 5  | loss: 0.71598 |  0:00:11s\n",
            "epoch 6  | loss: 0.77742 |  0:00:13s\n",
            "epoch 7  | loss: 0.79935 |  0:00:15s\n",
            "epoch 8  | loss: 0.82338 |  0:00:17s\n",
            "epoch 9  | loss: 0.76692 |  0:00:19s\n",
            "epoch 10 | loss: 0.75518 |  0:00:21s\n",
            "epoch 11 | loss: 0.72935 |  0:00:23s\n",
            "epoch 12 | loss: 0.7302  |  0:00:24s\n",
            "epoch 13 | loss: 0.69008 |  0:00:26s\n",
            "epoch 14 | loss: 0.74449 |  0:00:29s\n",
            "epoch 15 | loss: 0.65536 |  0:00:31s\n",
            "epoch 16 | loss: 0.70182 |  0:00:33s\n",
            "epoch 17 | loss: 0.68262 |  0:00:35s\n",
            "epoch 18 | loss: 0.65762 |  0:00:36s\n",
            "epoch 19 | loss: 0.67889 |  0:00:38s\n",
            "epoch 20 | loss: 0.7502  |  0:00:40s\n",
            "epoch 21 | loss: 0.72665 |  0:00:42s\n",
            "epoch 22 | loss: 0.6654  |  0:00:45s\n",
            "epoch 23 | loss: 0.63748 |  0:00:46s\n",
            "epoch 24 | loss: 0.64285 |  0:00:48s\n",
            "epoch 25 | loss: 0.62396 |  0:00:50s\n",
            "epoch 26 | loss: 0.6198  |  0:00:51s\n",
            "epoch 27 | loss: 0.6424  |  0:00:53s\n",
            "epoch 28 | loss: 0.67375 |  0:00:55s\n",
            "epoch 29 | loss: 0.67109 |  0:00:58s\n",
            "epoch 30 | loss: 0.63728 |  0:01:00s\n",
            "epoch 31 | loss: 0.6082  |  0:01:01s\n",
            "epoch 32 | loss: 0.64965 |  0:01:03s\n",
            "epoch 33 | loss: 0.61791 |  0:01:05s\n",
            "epoch 34 | loss: 0.60835 |  0:01:07s\n",
            "epoch 35 | loss: 0.60313 |  0:01:09s\n",
            "epoch 36 | loss: 0.58838 |  0:01:11s\n",
            "epoch 37 | loss: 0.61639 |  0:01:13s\n",
            "epoch 38 | loss: 0.60245 |  0:01:15s\n",
            "epoch 39 | loss: 0.64487 |  0:01:17s\n",
            "epoch 40 | loss: 0.65314 |  0:01:18s\n",
            "epoch 41 | loss: 0.59807 |  0:01:20s\n",
            "epoch 42 | loss: 0.58063 |  0:01:22s\n",
            "epoch 43 | loss: 0.5816  |  0:01:25s\n",
            "epoch 44 | loss: 0.55238 |  0:01:27s\n",
            "epoch 45 | loss: 0.58512 |  0:01:28s\n",
            "epoch 46 | loss: 0.56973 |  0:01:30s\n",
            "epoch 47 | loss: 0.57699 |  0:01:32s\n",
            "epoch 48 | loss: 0.55464 |  0:01:34s\n",
            "epoch 49 | loss: 0.60875 |  0:01:35s\n",
            "epoch 50 | loss: 0.62747 |  0:01:38s\n",
            "epoch 51 | loss: 0.6454  |  0:01:40s\n",
            "epoch 52 | loss: 0.62371 |  0:01:42s\n",
            "epoch 53 | loss: 0.56098 |  0:01:44s\n",
            "epoch 54 | loss: 0.55078 |  0:01:45s\n",
            "epoch 55 | loss: 0.58987 |  0:01:47s\n",
            "epoch 56 | loss: 0.59908 |  0:01:49s\n",
            "epoch 57 | loss: 0.63787 |  0:01:51s\n",
            "epoch 58 | loss: 0.57622 |  0:01:54s\n",
            "epoch 59 | loss: 0.58245 |  0:01:55s\n",
            "epoch 60 | loss: 0.5835  |  0:01:57s\n",
            "epoch 61 | loss: 0.56978 |  0:01:59s\n",
            "epoch 62 | loss: 0.57904 |  0:02:00s\n",
            "epoch 63 | loss: 0.64114 |  0:02:02s\n",
            "epoch 64 | loss: 0.58975 |  0:02:04s\n",
            "epoch 65 | loss: 0.55084 |  0:02:07s\n",
            "epoch 66 | loss: 0.54028 |  0:02:09s\n",
            "epoch 67 | loss: 0.53521 |  0:02:10s\n",
            "epoch 68 | loss: 0.56038 |  0:02:12s\n",
            "epoch 69 | loss: 0.59723 |  0:02:14s\n",
            "epoch 70 | loss: 0.63082 |  0:02:15s\n",
            "epoch 71 | loss: 0.52996 |  0:02:18s\n",
            "epoch 72 | loss: 0.53754 |  0:02:20s\n",
            "epoch 73 | loss: 0.57649 |  0:02:22s\n",
            "epoch 74 | loss: 0.6044  |  0:02:23s\n",
            "epoch 75 | loss: 0.55901 |  0:02:25s\n",
            "epoch 76 | loss: 0.51534 |  0:02:27s\n",
            "epoch 77 | loss: 0.52763 |  0:02:29s\n",
            "epoch 78 | loss: 0.52867 |  0:02:31s\n",
            "epoch 79 | loss: 0.56418 |  0:02:33s\n",
            "epoch 80 | loss: 0.53006 |  0:02:35s\n",
            "epoch 81 | loss: 0.5438  |  0:02:37s\n",
            "epoch 82 | loss: 0.59273 |  0:02:39s\n",
            "epoch 83 | loss: 0.56732 |  0:02:41s\n",
            "epoch 84 | loss: 0.53918 |  0:02:42s\n",
            "epoch 85 | loss: 0.57614 |  0:02:44s\n",
            "epoch 86 | loss: 0.546   |  0:02:47s\n",
            "epoch 87 | loss: 0.5348  |  0:02:49s\n",
            "epoch 88 | loss: 0.53872 |  0:02:51s\n",
            "epoch 89 | loss: 0.52885 |  0:02:53s\n",
            "epoch 90 | loss: 0.55279 |  0:02:54s\n",
            "epoch 91 | loss: 0.54401 |  0:02:56s\n",
            "epoch 92 | loss: 0.54676 |  0:02:58s\n",
            "epoch 93 | loss: 0.50524 |  0:03:00s\n",
            "epoch 94 | loss: 0.52174 |  0:03:02s\n",
            "epoch 95 | loss: 0.52533 |  0:03:04s\n",
            "epoch 96 | loss: 0.54459 |  0:03:06s\n",
            "epoch 97 | loss: 0.60517 |  0:03:08s\n",
            "epoch 98 | loss: 0.552   |  0:03:09s\n",
            "epoch 99 | loss: 0.56612 |  0:03:11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 11.64464|  0:00:02s\n",
            "epoch 1  | loss: 2.23544 |  0:00:04s\n",
            "epoch 2  | loss: 1.80579 |  0:00:06s\n",
            "epoch 3  | loss: 1.58594 |  0:00:08s\n",
            "epoch 4  | loss: 1.55448 |  0:00:09s\n",
            "epoch 5  | loss: 1.38408 |  0:00:11s\n",
            "epoch 6  | loss: 1.38916 |  0:00:13s\n",
            "epoch 7  | loss: 1.35893 |  0:00:16s\n",
            "epoch 8  | loss: 1.34893 |  0:00:18s\n",
            "epoch 9  | loss: 1.41446 |  0:00:20s\n",
            "epoch 10 | loss: 1.51157 |  0:00:21s\n",
            "epoch 11 | loss: 1.24742 |  0:00:23s\n",
            "epoch 12 | loss: 1.27393 |  0:00:25s\n",
            "epoch 13 | loss: 1.23675 |  0:00:26s\n",
            "epoch 14 | loss: 1.22141 |  0:00:29s\n",
            "epoch 15 | loss: 1.29415 |  0:00:31s\n",
            "epoch 16 | loss: 1.2819  |  0:00:33s\n",
            "epoch 17 | loss: 1.25234 |  0:00:35s\n",
            "epoch 18 | loss: 1.28734 |  0:00:36s\n",
            "epoch 19 | loss: 1.24099 |  0:00:38s\n",
            "epoch 20 | loss: 1.19832 |  0:00:40s\n",
            "epoch 21 | loss: 1.21547 |  0:00:41s\n",
            "epoch 22 | loss: 1.21928 |  0:00:44s\n",
            "epoch 23 | loss: 1.21935 |  0:00:46s\n",
            "epoch 24 | loss: 1.22717 |  0:00:48s\n",
            "epoch 25 | loss: 1.16225 |  0:00:49s\n",
            "epoch 26 | loss: 1.1823  |  0:00:51s\n",
            "epoch 27 | loss: 1.20087 |  0:00:53s\n",
            "epoch 28 | loss: 1.17309 |  0:00:54s\n",
            "epoch 29 | loss: 1.21227 |  0:00:57s\n",
            "epoch 30 | loss: 1.18536 |  0:00:59s\n",
            "epoch 31 | loss: 1.16484 |  0:01:01s\n",
            "epoch 32 | loss: 1.15224 |  0:01:03s\n",
            "epoch 33 | loss: 1.2044  |  0:01:04s\n",
            "epoch 34 | loss: 1.1651  |  0:01:06s\n",
            "epoch 35 | loss: 1.23468 |  0:01:08s\n",
            "epoch 36 | loss: 1.24693 |  0:01:10s\n",
            "epoch 37 | loss: 1.22185 |  0:01:12s\n",
            "epoch 38 | loss: 1.21016 |  0:01:14s\n",
            "epoch 39 | loss: 1.24413 |  0:01:16s\n",
            "epoch 40 | loss: 1.19138 |  0:01:17s\n",
            "epoch 41 | loss: 1.14491 |  0:01:19s\n",
            "epoch 42 | loss: 1.17624 |  0:01:21s\n",
            "epoch 43 | loss: 1.18938 |  0:01:23s\n",
            "epoch 44 | loss: 1.1648  |  0:01:25s\n",
            "epoch 45 | loss: 1.18659 |  0:01:28s\n",
            "epoch 46 | loss: 1.15374 |  0:01:29s\n",
            "epoch 47 | loss: 1.17596 |  0:01:31s\n",
            "epoch 48 | loss: 1.16992 |  0:01:33s\n",
            "epoch 49 | loss: 1.15281 |  0:01:34s\n",
            "epoch 50 | loss: 1.14786 |  0:01:36s\n",
            "epoch 51 | loss: 1.16564 |  0:01:38s\n",
            "epoch 52 | loss: 1.17826 |  0:01:41s\n",
            "epoch 53 | loss: 1.16289 |  0:01:42s\n",
            "epoch 54 | loss: 1.14664 |  0:01:44s\n",
            "epoch 55 | loss: 1.13446 |  0:01:46s\n",
            "epoch 56 | loss: 1.13965 |  0:01:48s\n",
            "epoch 57 | loss: 1.19628 |  0:01:49s\n",
            "epoch 58 | loss: 1.15099 |  0:01:51s\n",
            "epoch 59 | loss: 1.14789 |  0:01:54s\n",
            "epoch 60 | loss: 1.14849 |  0:01:56s\n",
            "epoch 61 | loss: 1.14447 |  0:01:58s\n",
            "epoch 62 | loss: 1.17656 |  0:02:00s\n",
            "epoch 63 | loss: 1.15262 |  0:02:02s\n",
            "epoch 64 | loss: 1.13424 |  0:02:03s\n",
            "epoch 65 | loss: 1.19563 |  0:02:05s\n",
            "epoch 66 | loss: 1.14178 |  0:02:08s\n",
            "epoch 67 | loss: 1.1517  |  0:02:10s\n",
            "epoch 68 | loss: 1.15681 |  0:02:12s\n",
            "epoch 69 | loss: 1.22089 |  0:02:13s\n",
            "epoch 70 | loss: 1.22323 |  0:02:15s\n",
            "epoch 71 | loss: 1.21589 |  0:02:17s\n",
            "epoch 72 | loss: 1.14857 |  0:02:18s\n",
            "epoch 73 | loss: 1.13505 |  0:02:21s\n",
            "epoch 74 | loss: 1.22142 |  0:02:23s\n",
            "epoch 75 | loss: 1.17735 |  0:02:25s\n",
            "epoch 76 | loss: 1.16416 |  0:02:26s\n",
            "epoch 77 | loss: 1.15484 |  0:02:28s\n",
            "epoch 78 | loss: 1.17426 |  0:02:30s\n",
            "epoch 79 | loss: 1.16337 |  0:02:31s\n",
            "epoch 80 | loss: 1.20734 |  0:02:34s\n",
            "epoch 81 | loss: 1.20149 |  0:02:36s\n",
            "epoch 82 | loss: 1.27055 |  0:02:38s\n",
            "epoch 83 | loss: 1.16165 |  0:02:40s\n",
            "epoch 84 | loss: 1.16331 |  0:02:41s\n",
            "epoch 85 | loss: 1.18227 |  0:02:43s\n",
            "epoch 86 | loss: 1.1673  |  0:02:45s\n",
            "epoch 87 | loss: 1.1828  |  0:02:47s\n",
            "epoch 88 | loss: 1.16361 |  0:02:49s\n",
            "epoch 89 | loss: 1.20758 |  0:02:51s\n",
            "epoch 90 | loss: 1.22297 |  0:02:53s\n",
            "epoch 91 | loss: 1.18996 |  0:02:55s\n",
            "epoch 92 | loss: 1.14669 |  0:02:57s\n",
            "epoch 93 | loss: 1.14925 |  0:02:58s\n",
            "epoch 94 | loss: 1.16168 |  0:03:00s\n",
            "epoch 95 | loss: 1.19094 |  0:03:03s\n",
            "epoch 96 | loss: 1.15837 |  0:03:05s\n",
            "epoch 97 | loss: 1.1281  |  0:03:07s\n",
            "epoch 98 | loss: 1.13233 |  0:03:08s\n",
            "epoch 99 | loss: 1.12057 |  0:03:10s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 73.84819|  0:00:01s\n",
            "epoch 1  | loss: 1.98249 |  0:00:03s\n",
            "epoch 2  | loss: 1.30913 |  0:00:06s\n",
            "epoch 3  | loss: 0.97763 |  0:00:08s\n",
            "epoch 4  | loss: 1.00497 |  0:00:10s\n",
            "epoch 5  | loss: 0.89855 |  0:00:11s\n",
            "epoch 6  | loss: 0.97807 |  0:00:13s\n",
            "epoch 7  | loss: 0.9376  |  0:00:15s\n",
            "epoch 8  | loss: 0.94447 |  0:00:17s\n",
            "epoch 9  | loss: 0.84122 |  0:00:19s\n",
            "epoch 10 | loss: 0.7465  |  0:00:21s\n",
            "epoch 11 | loss: 0.76464 |  0:00:23s\n",
            "epoch 12 | loss: 0.80387 |  0:00:25s\n",
            "epoch 13 | loss: 0.76923 |  0:00:27s\n",
            "epoch 14 | loss: 0.82807 |  0:00:28s\n",
            "epoch 15 | loss: 0.73874 |  0:00:30s\n",
            "epoch 16 | loss: 0.68335 |  0:00:32s\n",
            "epoch 17 | loss: 0.67178 |  0:00:35s\n",
            "epoch 18 | loss: 0.6632  |  0:00:37s\n",
            "epoch 19 | loss: 0.64063 |  0:00:38s\n",
            "epoch 20 | loss: 0.67774 |  0:00:40s\n",
            "epoch 21 | loss: 0.63765 |  0:00:42s\n",
            "epoch 22 | loss: 0.65482 |  0:00:44s\n",
            "epoch 23 | loss: 0.69213 |  0:00:46s\n",
            "epoch 24 | loss: 0.6976  |  0:00:48s\n",
            "epoch 25 | loss: 0.67768 |  0:00:50s\n",
            "epoch 26 | loss: 0.65594 |  0:00:52s\n",
            "epoch 27 | loss: 0.68529 |  0:00:54s\n",
            "epoch 28 | loss: 0.66595 |  0:00:55s\n",
            "epoch 29 | loss: 0.68744 |  0:00:57s\n",
            "epoch 30 | loss: 0.67673 |  0:00:59s\n",
            "epoch 31 | loss: 0.7625  |  0:01:02s\n",
            "epoch 32 | loss: 0.73736 |  0:01:04s\n",
            "epoch 33 | loss: 0.72235 |  0:01:06s\n",
            "epoch 34 | loss: 0.70945 |  0:01:08s\n",
            "epoch 35 | loss: 0.66134 |  0:01:09s\n",
            "epoch 36 | loss: 0.69976 |  0:01:11s\n",
            "epoch 37 | loss: 0.65796 |  0:01:13s\n",
            "epoch 38 | loss: 0.64772 |  0:01:16s\n",
            "epoch 39 | loss: 0.67349 |  0:01:18s\n",
            "epoch 40 | loss: 0.65002 |  0:01:20s\n",
            "epoch 41 | loss: 0.64948 |  0:01:21s\n",
            "epoch 42 | loss: 0.6496  |  0:01:23s\n",
            "epoch 43 | loss: 0.67147 |  0:01:25s\n",
            "epoch 44 | loss: 0.7148  |  0:01:27s\n",
            "epoch 45 | loss: 0.68906 |  0:01:29s\n",
            "epoch 46 | loss: 0.65623 |  0:01:31s\n",
            "epoch 47 | loss: 0.62472 |  0:01:33s\n",
            "epoch 48 | loss: 0.69047 |  0:01:35s\n",
            "epoch 49 | loss: 0.663   |  0:01:37s\n",
            "epoch 50 | loss: 0.64447 |  0:01:38s\n",
            "epoch 51 | loss: 0.63876 |  0:01:40s\n",
            "epoch 52 | loss: 0.62959 |  0:01:43s\n",
            "epoch 53 | loss: 0.6032  |  0:01:45s\n",
            "epoch 54 | loss: 0.60995 |  0:01:47s\n",
            "epoch 55 | loss: 0.61966 |  0:01:48s\n",
            "epoch 56 | loss: 0.62845 |  0:01:50s\n",
            "epoch 57 | loss: 0.66583 |  0:01:52s\n",
            "epoch 58 | loss: 0.60666 |  0:01:53s\n",
            "epoch 59 | loss: 0.60266 |  0:01:56s\n",
            "epoch 60 | loss: 0.58854 |  0:01:58s\n",
            "epoch 61 | loss: 0.59859 |  0:02:00s\n",
            "epoch 62 | loss: 0.62413 |  0:02:02s\n",
            "epoch 63 | loss: 0.62648 |  0:02:03s\n",
            "epoch 64 | loss: 0.60771 |  0:02:05s\n",
            "epoch 65 | loss: 0.60448 |  0:02:07s\n",
            "epoch 66 | loss: 0.63511 |  0:02:09s\n",
            "epoch 67 | loss: 0.61643 |  0:02:12s\n",
            "epoch 68 | loss: 0.61229 |  0:02:14s\n",
            "epoch 69 | loss: 0.5949  |  0:02:15s\n",
            "epoch 70 | loss: 0.60289 |  0:02:17s\n",
            "epoch 71 | loss: 0.63414 |  0:02:19s\n",
            "epoch 72 | loss: 0.62945 |  0:02:21s\n",
            "epoch 73 | loss: 0.62839 |  0:02:22s\n",
            "epoch 74 | loss: 0.64435 |  0:02:25s\n",
            "epoch 75 | loss: 0.61849 |  0:02:27s\n",
            "epoch 76 | loss: 0.63549 |  0:02:29s\n",
            "epoch 77 | loss: 0.59922 |  0:02:31s\n",
            "epoch 78 | loss: 0.58757 |  0:02:32s\n",
            "epoch 79 | loss: 0.57506 |  0:02:34s\n",
            "epoch 80 | loss: 0.6169  |  0:02:36s\n",
            "epoch 81 | loss: 0.57823 |  0:02:39s\n",
            "epoch 82 | loss: 0.58927 |  0:02:41s\n",
            "epoch 83 | loss: 0.63154 |  0:02:43s\n",
            "epoch 84 | loss: 0.61663 |  0:02:45s\n",
            "epoch 85 | loss: 0.60251 |  0:02:46s\n",
            "epoch 86 | loss: 0.61174 |  0:02:48s\n",
            "epoch 87 | loss: 0.62869 |  0:02:50s\n",
            "epoch 88 | loss: 0.68183 |  0:02:53s\n",
            "epoch 89 | loss: 0.62753 |  0:02:55s\n",
            "epoch 90 | loss: 0.62605 |  0:02:56s\n",
            "epoch 91 | loss: 0.62782 |  0:02:58s\n",
            "epoch 92 | loss: 0.64246 |  0:03:00s\n",
            "epoch 93 | loss: 0.60369 |  0:03:02s\n",
            "epoch 94 | loss: 0.59675 |  0:03:03s\n",
            "epoch 95 | loss: 0.58416 |  0:03:06s\n",
            "epoch 96 | loss: 0.59377 |  0:03:08s\n",
            "epoch 97 | loss: 0.59589 |  0:03:10s\n",
            "epoch 98 | loss: 0.56275 |  0:03:11s\n",
            "epoch 99 | loss: 0.57401 |  0:03:13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 14.87119|  0:00:01s\n",
            "epoch 1  | loss: 3.18437 |  0:00:03s\n",
            "epoch 2  | loss: 1.94635 |  0:00:06s\n",
            "epoch 3  | loss: 1.35469 |  0:00:08s\n",
            "epoch 4  | loss: 1.34886 |  0:00:10s\n",
            "epoch 5  | loss: 1.19017 |  0:00:11s\n",
            "epoch 6  | loss: 1.25773 |  0:00:13s\n",
            "epoch 7  | loss: 1.3258  |  0:00:15s\n",
            "epoch 8  | loss: 1.15857 |  0:00:17s\n",
            "epoch 9  | loss: 1.10335 |  0:00:19s\n",
            "epoch 10 | loss: 1.07921 |  0:00:21s\n",
            "epoch 11 | loss: 1.04793 |  0:00:23s\n",
            "epoch 12 | loss: 1.08005 |  0:00:25s\n",
            "epoch 13 | loss: 1.04319 |  0:00:27s\n",
            "epoch 14 | loss: 1.1177  |  0:00:29s\n",
            "epoch 15 | loss: 1.12701 |  0:00:31s\n",
            "epoch 16 | loss: 1.13485 |  0:00:33s\n",
            "epoch 17 | loss: 1.04084 |  0:00:36s\n",
            "epoch 18 | loss: 1.05874 |  0:00:37s\n",
            "epoch 19 | loss: 1.10013 |  0:00:39s\n",
            "epoch 20 | loss: 1.05787 |  0:00:41s\n",
            "epoch 21 | loss: 1.01964 |  0:00:43s\n",
            "epoch 22 | loss: 1.02024 |  0:00:45s\n",
            "epoch 23 | loss: 1.02743 |  0:00:47s\n",
            "epoch 24 | loss: 1.03276 |  0:00:49s\n",
            "epoch 25 | loss: 1.05911 |  0:00:51s\n",
            "epoch 26 | loss: 1.04461 |  0:00:53s\n",
            "epoch 27 | loss: 1.01811 |  0:00:55s\n",
            "epoch 28 | loss: 1.02023 |  0:00:56s\n",
            "epoch 29 | loss: 1.02168 |  0:00:58s\n",
            "epoch 30 | loss: 1.07262 |  0:01:01s\n",
            "epoch 31 | loss: 1.01971 |  0:01:03s\n",
            "epoch 32 | loss: 0.99619 |  0:01:05s\n",
            "epoch 33 | loss: 1.00165 |  0:01:06s\n",
            "epoch 34 | loss: 0.98721 |  0:01:08s\n",
            "epoch 35 | loss: 0.98266 |  0:01:10s\n",
            "epoch 36 | loss: 0.99386 |  0:01:12s\n",
            "epoch 37 | loss: 0.97803 |  0:01:14s\n",
            "epoch 38 | loss: 1.00685 |  0:01:16s\n",
            "epoch 39 | loss: 1.04248 |  0:01:18s\n",
            "epoch 40 | loss: 1.02935 |  0:01:20s\n",
            "epoch 41 | loss: 1.03601 |  0:01:22s\n",
            "epoch 42 | loss: 1.04361 |  0:01:23s\n",
            "epoch 43 | loss: 0.9979  |  0:01:25s\n",
            "epoch 44 | loss: 0.97605 |  0:01:27s\n",
            "epoch 45 | loss: 1.03267 |  0:01:30s\n",
            "epoch 46 | loss: 1.01772 |  0:01:32s\n",
            "epoch 47 | loss: 0.96807 |  0:01:33s\n",
            "epoch 48 | loss: 1.01875 |  0:01:35s\n",
            "epoch 49 | loss: 1.06045 |  0:01:37s\n",
            "epoch 50 | loss: 1.03442 |  0:01:39s\n",
            "epoch 51 | loss: 1.08554 |  0:01:41s\n",
            "epoch 52 | loss: 0.99385 |  0:01:44s\n",
            "epoch 53 | loss: 0.98475 |  0:01:46s\n",
            "epoch 54 | loss: 0.99166 |  0:01:47s\n",
            "epoch 55 | loss: 0.95691 |  0:01:49s\n",
            "epoch 56 | loss: 0.98685 |  0:01:51s\n",
            "epoch 57 | loss: 1.02741 |  0:01:53s\n",
            "epoch 58 | loss: 0.99106 |  0:01:55s\n",
            "epoch 59 | loss: 1.00153 |  0:01:57s\n",
            "epoch 60 | loss: 0.95366 |  0:01:59s\n",
            "epoch 61 | loss: 0.95574 |  0:02:01s\n",
            "epoch 62 | loss: 0.95711 |  0:02:03s\n",
            "epoch 63 | loss: 0.97224 |  0:02:05s\n",
            "epoch 64 | loss: 1.00582 |  0:02:06s\n",
            "epoch 65 | loss: 0.98695 |  0:02:09s\n",
            "epoch 66 | loss: 0.94056 |  0:02:11s\n",
            "epoch 67 | loss: 0.94147 |  0:02:13s\n",
            "epoch 68 | loss: 0.97491 |  0:02:15s\n",
            "epoch 69 | loss: 0.97172 |  0:02:17s\n",
            "epoch 70 | loss: 1.04979 |  0:02:19s\n",
            "epoch 71 | loss: 1.06268 |  0:02:20s\n",
            "epoch 72 | loss: 1.00694 |  0:02:23s\n",
            "epoch 73 | loss: 0.98277 |  0:02:25s\n",
            "epoch 74 | loss: 0.97298 |  0:02:27s\n",
            "epoch 75 | loss: 0.97225 |  0:02:29s\n",
            "epoch 76 | loss: 0.95182 |  0:02:31s\n",
            "epoch 77 | loss: 0.94    |  0:02:33s\n",
            "epoch 78 | loss: 0.91362 |  0:02:34s\n",
            "epoch 79 | loss: 0.96882 |  0:02:36s\n",
            "epoch 80 | loss: 0.96763 |  0:02:39s\n",
            "epoch 81 | loss: 0.93477 |  0:02:41s\n",
            "epoch 82 | loss: 0.95776 |  0:02:43s\n",
            "epoch 83 | loss: 0.94625 |  0:02:44s\n",
            "epoch 84 | loss: 0.93549 |  0:02:46s\n",
            "epoch 85 | loss: 0.98582 |  0:02:48s\n",
            "epoch 86 | loss: 0.92688 |  0:02:50s\n",
            "epoch 87 | loss: 0.98366 |  0:02:52s\n",
            "epoch 88 | loss: 0.95397 |  0:02:55s\n",
            "epoch 89 | loss: 0.9669  |  0:02:56s\n",
            "epoch 90 | loss: 0.97581 |  0:02:58s\n",
            "epoch 91 | loss: 0.96428 |  0:03:00s\n",
            "epoch 92 | loss: 1.03103 |  0:03:01s\n",
            "epoch 93 | loss: 1.03992 |  0:03:03s\n",
            "epoch 94 | loss: 0.96736 |  0:03:06s\n",
            "epoch 95 | loss: 0.93788 |  0:03:08s\n",
            "epoch 96 | loss: 0.92765 |  0:03:10s\n",
            "epoch 97 | loss: 0.93344 |  0:03:12s\n",
            "epoch 98 | loss: 0.93238 |  0:03:13s\n",
            "epoch 99 | loss: 0.98178 |  0:03:15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 12.08413|  0:00:01s\n",
            "epoch 1  | loss: 3.76621 |  0:00:04s\n",
            "epoch 2  | loss: 1.54031 |  0:00:06s\n",
            "epoch 3  | loss: 1.25841 |  0:00:08s\n",
            "epoch 4  | loss: 0.9901  |  0:00:10s\n",
            "epoch 5  | loss: 0.88853 |  0:00:11s\n",
            "epoch 6  | loss: 0.91294 |  0:00:13s\n",
            "epoch 7  | loss: 0.77313 |  0:00:15s\n",
            "epoch 8  | loss: 0.74236 |  0:00:18s\n",
            "epoch 9  | loss: 0.73968 |  0:00:20s\n",
            "epoch 10 | loss: 0.72898 |  0:00:22s\n",
            "epoch 11 | loss: 0.77239 |  0:00:23s\n",
            "epoch 12 | loss: 0.75588 |  0:00:25s\n",
            "epoch 13 | loss: 0.73974 |  0:00:27s\n",
            "epoch 14 | loss: 0.6934  |  0:00:29s\n",
            "epoch 15 | loss: 0.68024 |  0:00:31s\n",
            "epoch 16 | loss: 0.69304 |  0:00:34s\n",
            "epoch 17 | loss: 0.68106 |  0:00:36s\n",
            "epoch 18 | loss: 0.68774 |  0:00:37s\n",
            "epoch 19 | loss: 0.72655 |  0:00:39s\n",
            "epoch 20 | loss: 0.70417 |  0:00:41s\n",
            "epoch 21 | loss: 0.6687  |  0:00:43s\n",
            "epoch 22 | loss: 0.65639 |  0:00:45s\n",
            "epoch 23 | loss: 0.66662 |  0:00:48s\n",
            "epoch 24 | loss: 0.73426 |  0:00:49s\n",
            "epoch 25 | loss: 0.71282 |  0:00:51s\n",
            "epoch 26 | loss: 0.65836 |  0:00:53s\n",
            "epoch 27 | loss: 0.72217 |  0:00:55s\n",
            "epoch 28 | loss: 0.65112 |  0:00:56s\n",
            "epoch 29 | loss: 0.64482 |  0:00:59s\n",
            "epoch 30 | loss: 0.63553 |  0:01:01s\n",
            "epoch 31 | loss: 0.63756 |  0:01:03s\n",
            "epoch 32 | loss: 0.60783 |  0:01:05s\n",
            "epoch 33 | loss: 0.5979  |  0:01:07s\n",
            "epoch 34 | loss: 0.60199 |  0:01:09s\n",
            "epoch 35 | loss: 0.60075 |  0:01:11s\n",
            "epoch 36 | loss: 0.67157 |  0:01:13s\n",
            "epoch 37 | loss: 0.66478 |  0:01:15s\n",
            "epoch 38 | loss: 0.6197  |  0:01:17s\n",
            "epoch 39 | loss: 0.65006 |  0:01:19s\n",
            "epoch 40 | loss: 0.65977 |  0:01:21s\n",
            "epoch 41 | loss: 0.61926 |  0:01:22s\n",
            "epoch 42 | loss: 0.61342 |  0:01:24s\n",
            "epoch 43 | loss: 0.58996 |  0:01:26s\n",
            "epoch 44 | loss: 0.60492 |  0:01:29s\n",
            "epoch 45 | loss: 0.57487 |  0:01:31s\n",
            "epoch 46 | loss: 0.59001 |  0:01:33s\n",
            "epoch 47 | loss: 0.60431 |  0:01:34s\n",
            "epoch 48 | loss: 0.5958  |  0:01:36s\n",
            "epoch 49 | loss: 0.56971 |  0:01:38s\n",
            "epoch 50 | loss: 0.62517 |  0:01:40s\n",
            "epoch 51 | loss: 0.63724 |  0:01:43s\n",
            "epoch 52 | loss: 0.61905 |  0:01:45s\n",
            "epoch 53 | loss: 0.5781  |  0:01:47s\n",
            "epoch 54 | loss: 0.56831 |  0:01:49s\n",
            "epoch 55 | loss: 0.60505 |  0:01:50s\n",
            "epoch 56 | loss: 0.60461 |  0:01:52s\n",
            "epoch 57 | loss: 0.59732 |  0:01:54s\n",
            "epoch 58 | loss: 0.58634 |  0:01:57s\n",
            "epoch 59 | loss: 0.63488 |  0:01:59s\n",
            "epoch 60 | loss: 0.61581 |  0:02:00s\n",
            "epoch 61 | loss: 0.60295 |  0:02:02s\n",
            "epoch 62 | loss: 0.56535 |  0:02:04s\n",
            "epoch 63 | loss: 0.55686 |  0:02:06s\n",
            "epoch 64 | loss: 0.54257 |  0:02:08s\n",
            "epoch 65 | loss: 0.56233 |  0:02:10s\n",
            "epoch 66 | loss: 0.56507 |  0:02:12s\n",
            "epoch 67 | loss: 0.57983 |  0:02:14s\n",
            "epoch 68 | loss: 0.5745  |  0:02:16s\n",
            "epoch 69 | loss: 0.59408 |  0:02:18s\n",
            "epoch 70 | loss: 0.60927 |  0:02:19s\n",
            "epoch 71 | loss: 0.59286 |  0:02:21s\n",
            "epoch 72 | loss: 0.58118 |  0:02:23s\n",
            "epoch 73 | loss: 0.55528 |  0:02:26s\n",
            "epoch 74 | loss: 0.54889 |  0:02:27s\n",
            "epoch 75 | loss: 0.54918 |  0:02:29s\n",
            "epoch 76 | loss: 0.56298 |  0:02:31s\n",
            "epoch 77 | loss: 0.57642 |  0:02:32s\n",
            "epoch 78 | loss: 0.56174 |  0:02:34s\n",
            "epoch 79 | loss: 0.58257 |  0:02:37s\n",
            "epoch 80 | loss: 0.56255 |  0:02:39s\n",
            "epoch 81 | loss: 0.53906 |  0:02:41s\n",
            "epoch 82 | loss: 0.55668 |  0:02:43s\n",
            "epoch 83 | loss: 0.54124 |  0:02:44s\n",
            "epoch 84 | loss: 0.54376 |  0:02:46s\n",
            "epoch 85 | loss: 0.52848 |  0:02:48s\n",
            "epoch 86 | loss: 0.54812 |  0:02:50s\n",
            "epoch 87 | loss: 0.56248 |  0:02:53s\n",
            "epoch 88 | loss: 0.56978 |  0:02:55s\n",
            "epoch 89 | loss: 0.56942 |  0:02:56s\n",
            "epoch 90 | loss: 0.55117 |  0:02:58s\n",
            "epoch 91 | loss: 0.55655 |  0:03:00s\n",
            "epoch 92 | loss: 0.56404 |  0:03:02s\n",
            "epoch 93 | loss: 0.51728 |  0:03:04s\n",
            "epoch 94 | loss: 0.51721 |  0:03:06s\n",
            "epoch 95 | loss: 0.52806 |  0:03:08s\n",
            "epoch 96 | loss: 0.53628 |  0:03:10s\n",
            "epoch 97 | loss: 0.51332 |  0:03:12s\n",
            "epoch 98 | loss: 0.57223 |  0:03:13s\n",
            "epoch 99 | loss: 0.5139  |  0:03:15s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 35.19386|  0:00:02s\n",
            "epoch 1  | loss: 2.71661 |  0:00:04s\n",
            "epoch 2  | loss: 2.3548  |  0:00:06s\n",
            "epoch 3  | loss: 1.90087 |  0:00:08s\n",
            "epoch 4  | loss: 1.70095 |  0:00:10s\n",
            "epoch 5  | loss: 1.66667 |  0:00:12s\n",
            "epoch 6  | loss: 1.74436 |  0:00:13s\n",
            "epoch 7  | loss: 1.71686 |  0:00:15s\n",
            "epoch 8  | loss: 1.57116 |  0:00:18s\n",
            "epoch 9  | loss: 1.53549 |  0:00:20s\n",
            "epoch 10 | loss: 1.50831 |  0:00:22s\n",
            "epoch 11 | loss: 1.54715 |  0:00:23s\n",
            "epoch 12 | loss: 1.61914 |  0:00:25s\n",
            "epoch 13 | loss: 1.53751 |  0:00:27s\n",
            "epoch 14 | loss: 1.4779  |  0:00:29s\n",
            "epoch 15 | loss: 1.42213 |  0:00:31s\n",
            "epoch 16 | loss: 1.40576 |  0:00:33s\n",
            "epoch 17 | loss: 1.40084 |  0:00:35s\n",
            "epoch 18 | loss: 1.35572 |  0:00:37s\n",
            "epoch 19 | loss: 1.4057  |  0:00:39s\n",
            "epoch 20 | loss: 1.39437 |  0:00:41s\n",
            "epoch 21 | loss: 1.39943 |  0:00:42s\n",
            "epoch 22 | loss: 1.54812 |  0:00:45s\n",
            "epoch 23 | loss: 1.54949 |  0:00:47s\n",
            "epoch 24 | loss: 1.4982  |  0:00:49s\n",
            "epoch 25 | loss: 1.43157 |  0:00:51s\n",
            "epoch 26 | loss: 1.4029  |  0:00:53s\n",
            "epoch 27 | loss: 1.39572 |  0:00:54s\n",
            "epoch 28 | loss: 1.39243 |  0:00:56s\n",
            "epoch 29 | loss: 1.41813 |  0:00:59s\n",
            "epoch 30 | loss: 1.44285 |  0:01:01s\n",
            "epoch 31 | loss: 1.38947 |  0:01:03s\n",
            "epoch 32 | loss: 1.39491 |  0:01:04s\n",
            "epoch 33 | loss: 1.39281 |  0:01:06s\n",
            "epoch 34 | loss: 1.41556 |  0:01:08s\n",
            "epoch 35 | loss: 1.34743 |  0:01:10s\n",
            "epoch 36 | loss: 1.37981 |  0:01:12s\n",
            "epoch 37 | loss: 1.41152 |  0:01:14s\n",
            "epoch 38 | loss: 1.42481 |  0:01:16s\n",
            "epoch 39 | loss: 1.35648 |  0:01:18s\n",
            "epoch 40 | loss: 1.40144 |  0:01:20s\n",
            "epoch 41 | loss: 1.344   |  0:01:21s\n",
            "epoch 42 | loss: 1.33538 |  0:01:23s\n",
            "epoch 43 | loss: 1.35671 |  0:01:25s\n",
            "epoch 44 | loss: 1.32139 |  0:01:28s\n",
            "epoch 45 | loss: 1.38093 |  0:01:30s\n",
            "epoch 46 | loss: 1.36131 |  0:01:31s\n",
            "epoch 47 | loss: 1.37275 |  0:01:33s\n",
            "epoch 48 | loss: 1.36377 |  0:01:35s\n",
            "epoch 49 | loss: 1.32239 |  0:01:37s\n",
            "epoch 50 | loss: 1.43171 |  0:01:38s\n",
            "epoch 51 | loss: 1.36509 |  0:01:41s\n",
            "epoch 52 | loss: 1.35254 |  0:01:43s\n",
            "epoch 53 | loss: 1.31883 |  0:01:45s\n",
            "epoch 54 | loss: 1.32144 |  0:01:46s\n",
            "epoch 55 | loss: 1.29803 |  0:01:48s\n",
            "epoch 56 | loss: 1.31176 |  0:01:50s\n",
            "epoch 57 | loss: 1.35646 |  0:01:52s\n",
            "epoch 58 | loss: 1.34251 |  0:01:55s\n",
            "epoch 59 | loss: 1.31923 |  0:01:57s\n",
            "epoch 60 | loss: 1.31023 |  0:01:58s\n",
            "epoch 61 | loss: 1.28288 |  0:02:00s\n",
            "epoch 62 | loss: 1.3236  |  0:02:02s\n",
            "epoch 63 | loss: 1.35629 |  0:02:04s\n",
            "epoch 64 | loss: 1.29103 |  0:02:05s\n",
            "epoch 65 | loss: 1.30573 |  0:02:08s\n",
            "epoch 66 | loss: 1.28537 |  0:02:10s\n",
            "epoch 67 | loss: 1.28288 |  0:02:12s\n",
            "epoch 68 | loss: 1.28895 |  0:02:14s\n",
            "epoch 69 | loss: 1.28397 |  0:02:16s\n",
            "epoch 70 | loss: 1.27284 |  0:02:17s\n",
            "epoch 71 | loss: 1.29403 |  0:02:19s\n",
            "epoch 72 | loss: 1.27464 |  0:02:21s\n",
            "epoch 73 | loss: 1.23619 |  0:02:24s\n",
            "epoch 74 | loss: 1.27716 |  0:02:25s\n",
            "epoch 75 | loss: 1.27348 |  0:02:27s\n",
            "epoch 76 | loss: 1.28284 |  0:02:29s\n",
            "epoch 77 | loss: 1.24631 |  0:02:31s\n",
            "epoch 78 | loss: 1.23963 |  0:02:32s\n",
            "epoch 79 | loss: 1.23632 |  0:02:35s\n",
            "epoch 80 | loss: 1.23965 |  0:02:37s\n",
            "epoch 81 | loss: 1.25141 |  0:02:39s\n",
            "epoch 82 | loss: 1.27908 |  0:02:41s\n",
            "epoch 83 | loss: 1.30206 |  0:02:43s\n",
            "epoch 84 | loss: 1.32342 |  0:02:44s\n",
            "epoch 85 | loss: 1.25632 |  0:02:46s\n",
            "epoch 86 | loss: 1.29404 |  0:02:48s\n",
            "epoch 87 | loss: 1.27109 |  0:02:50s\n",
            "epoch 88 | loss: 1.28194 |  0:02:53s\n",
            "epoch 89 | loss: 1.28352 |  0:02:54s\n",
            "epoch 90 | loss: 1.28532 |  0:02:56s\n",
            "epoch 91 | loss: 1.25174 |  0:02:58s\n",
            "epoch 92 | loss: 1.28604 |  0:03:00s\n",
            "epoch 93 | loss: 1.26519 |  0:03:01s\n",
            "epoch 94 | loss: 1.29039 |  0:03:04s\n",
            "epoch 95 | loss: 1.2978  |  0:03:06s\n",
            "epoch 96 | loss: 1.28401 |  0:03:08s\n",
            "epoch 97 | loss: 1.2945  |  0:03:10s\n",
            "epoch 98 | loss: 1.26    |  0:03:11s\n",
            "epoch 99 | loss: 1.23584 |  0:03:13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.94278 |  0:00:01s\n",
            "epoch 1  | loss: 1.23575 |  0:00:03s\n",
            "epoch 2  | loss: 1.08423 |  0:00:05s\n",
            "epoch 3  | loss: 0.97681 |  0:00:07s\n",
            "epoch 4  | loss: 1.01249 |  0:00:08s\n",
            "epoch 5  | loss: 0.99448 |  0:00:10s\n",
            "epoch 6  | loss: 0.9559  |  0:00:11s\n",
            "epoch 7  | loss: 0.89715 |  0:00:13s\n",
            "epoch 8  | loss: 0.93641 |  0:00:14s\n",
            "epoch 9  | loss: 0.86426 |  0:00:16s\n",
            "epoch 10 | loss: 0.82494 |  0:00:18s\n",
            "epoch 11 | loss: 0.81942 |  0:00:20s\n",
            "epoch 12 | loss: 0.86512 |  0:00:21s\n",
            "epoch 13 | loss: 0.8526  |  0:00:23s\n",
            "epoch 14 | loss: 0.84175 |  0:00:25s\n",
            "epoch 15 | loss: 0.83211 |  0:00:26s\n",
            "epoch 16 | loss: 0.80725 |  0:00:28s\n",
            "epoch 17 | loss: 0.81556 |  0:00:29s\n",
            "epoch 18 | loss: 0.8176  |  0:00:31s\n",
            "epoch 19 | loss: 0.80689 |  0:00:34s\n",
            "epoch 20 | loss: 0.89659 |  0:00:35s\n",
            "epoch 21 | loss: 0.87134 |  0:00:36s\n",
            "epoch 22 | loss: 0.80381 |  0:00:38s\n",
            "epoch 23 | loss: 0.83381 |  0:00:39s\n",
            "epoch 24 | loss: 0.86739 |  0:00:41s\n",
            "epoch 25 | loss: 0.86714 |  0:00:43s\n",
            "epoch 26 | loss: 0.87901 |  0:00:45s\n",
            "epoch 27 | loss: 0.87653 |  0:00:47s\n",
            "epoch 28 | loss: 0.82673 |  0:00:48s\n",
            "epoch 29 | loss: 0.82545 |  0:00:50s\n",
            "epoch 30 | loss: 0.79356 |  0:00:51s\n",
            "epoch 31 | loss: 0.7673  |  0:00:53s\n",
            "epoch 32 | loss: 0.82102 |  0:00:54s\n",
            "epoch 33 | loss: 0.83827 |  0:00:56s\n",
            "epoch 34 | loss: 0.86895 |  0:00:58s\n",
            "epoch 35 | loss: 0.79584 |  0:01:00s\n",
            "epoch 36 | loss: 0.78138 |  0:01:02s\n",
            "epoch 37 | loss: 0.78448 |  0:01:03s\n",
            "epoch 38 | loss: 0.78193 |  0:01:05s\n",
            "epoch 39 | loss: 0.77627 |  0:01:06s\n",
            "epoch 40 | loss: 0.81242 |  0:01:08s\n",
            "epoch 41 | loss: 0.79152 |  0:01:09s\n",
            "epoch 42 | loss: 0.82145 |  0:01:11s\n",
            "epoch 43 | loss: 0.79331 |  0:01:13s\n",
            "epoch 44 | loss: 0.83222 |  0:01:15s\n",
            "epoch 45 | loss: 0.8689  |  0:01:16s\n",
            "epoch 46 | loss: 0.81636 |  0:01:18s\n",
            "epoch 47 | loss: 0.88451 |  0:01:20s\n",
            "epoch 48 | loss: 0.85666 |  0:01:21s\n",
            "epoch 49 | loss: 0.86701 |  0:01:23s\n",
            "epoch 50 | loss: 0.82649 |  0:01:24s\n",
            "epoch 51 | loss: 0.80808 |  0:01:26s\n",
            "epoch 52 | loss: 0.85498 |  0:01:29s\n",
            "epoch 53 | loss: 0.78273 |  0:01:30s\n",
            "epoch 54 | loss: 0.79259 |  0:01:32s\n",
            "epoch 55 | loss: 0.79852 |  0:01:33s\n",
            "epoch 56 | loss: 0.83629 |  0:01:35s\n",
            "epoch 57 | loss: 0.80927 |  0:01:36s\n",
            "epoch 58 | loss: 0.78684 |  0:01:38s\n",
            "epoch 59 | loss: 0.7912  |  0:01:40s\n",
            "epoch 60 | loss: 0.78852 |  0:01:42s\n",
            "epoch 61 | loss: 0.7638  |  0:01:44s\n",
            "epoch 62 | loss: 0.76707 |  0:01:45s\n",
            "epoch 63 | loss: 0.76531 |  0:01:47s\n",
            "epoch 64 | loss: 0.77129 |  0:01:48s\n",
            "epoch 65 | loss: 0.783   |  0:01:50s\n",
            "epoch 66 | loss: 0.79236 |  0:01:51s\n",
            "epoch 67 | loss: 0.80089 |  0:01:53s\n",
            "epoch 68 | loss: 0.79365 |  0:01:55s\n",
            "epoch 69 | loss: 0.77676 |  0:01:57s\n",
            "epoch 70 | loss: 0.75878 |  0:01:59s\n",
            "epoch 71 | loss: 0.76641 |  0:02:00s\n",
            "epoch 72 | loss: 0.74015 |  0:02:02s\n",
            "epoch 73 | loss: 0.73822 |  0:02:03s\n",
            "epoch 74 | loss: 0.7515  |  0:02:05s\n",
            "epoch 75 | loss: 0.8684  |  0:02:07s\n",
            "epoch 76 | loss: 0.76816 |  0:02:08s\n",
            "epoch 77 | loss: 0.7676  |  0:02:11s\n",
            "epoch 78 | loss: 0.7359  |  0:02:12s\n",
            "epoch 79 | loss: 0.74041 |  0:02:14s\n",
            "epoch 80 | loss: 0.75529 |  0:02:15s\n",
            "epoch 81 | loss: 0.74862 |  0:02:17s\n",
            "epoch 82 | loss: 0.76795 |  0:02:18s\n",
            "epoch 83 | loss: 0.73614 |  0:02:20s\n",
            "epoch 84 | loss: 0.73545 |  0:02:22s\n",
            "epoch 85 | loss: 0.74148 |  0:02:24s\n",
            "epoch 86 | loss: 0.74211 |  0:02:26s\n",
            "epoch 87 | loss: 0.73905 |  0:02:27s\n",
            "epoch 88 | loss: 0.74523 |  0:02:29s\n",
            "epoch 89 | loss: 0.74545 |  0:02:30s\n",
            "epoch 90 | loss: 0.72981 |  0:02:32s\n",
            "epoch 91 | loss: 0.75644 |  0:02:33s\n",
            "epoch 92 | loss: 0.79863 |  0:02:35s\n",
            "epoch 93 | loss: 0.74426 |  0:02:37s\n",
            "epoch 94 | loss: 0.74129 |  0:02:39s\n",
            "epoch 95 | loss: 0.75644 |  0:02:41s\n",
            "epoch 96 | loss: 0.74114 |  0:02:42s\n",
            "epoch 97 | loss: 0.72988 |  0:02:44s\n",
            "epoch 98 | loss: 0.73863 |  0:02:45s\n",
            "epoch 99 | loss: 0.7531  |  0:02:46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 8.96542 |  0:00:01s\n",
            "epoch 1  | loss: 1.31862 |  0:00:03s\n",
            "epoch 2  | loss: 0.94503 |  0:00:05s\n",
            "epoch 3  | loss: 0.88158 |  0:00:07s\n",
            "epoch 4  | loss: 0.76804 |  0:00:08s\n",
            "epoch 5  | loss: 0.68417 |  0:00:10s\n",
            "epoch 6  | loss: 0.69093 |  0:00:11s\n",
            "epoch 7  | loss: 0.72878 |  0:00:13s\n",
            "epoch 8  | loss: 0.73294 |  0:00:14s\n",
            "epoch 9  | loss: 0.82843 |  0:00:16s\n",
            "epoch 10 | loss: 0.7342  |  0:00:18s\n",
            "epoch 11 | loss: 0.83219 |  0:00:20s\n",
            "epoch 12 | loss: 0.76816 |  0:00:21s\n",
            "epoch 13 | loss: 0.67992 |  0:00:23s\n",
            "epoch 14 | loss: 0.69792 |  0:00:25s\n",
            "epoch 15 | loss: 0.68167 |  0:00:26s\n",
            "epoch 16 | loss: 0.72651 |  0:00:28s\n",
            "epoch 17 | loss: 0.66771 |  0:00:30s\n",
            "epoch 18 | loss: 0.67647 |  0:00:32s\n",
            "epoch 19 | loss: 0.72734 |  0:00:34s\n",
            "epoch 20 | loss: 0.79848 |  0:00:35s\n",
            "epoch 21 | loss: 0.67037 |  0:00:36s\n",
            "epoch 22 | loss: 0.66455 |  0:00:38s\n",
            "epoch 23 | loss: 0.65336 |  0:00:40s\n",
            "epoch 24 | loss: 0.60562 |  0:00:41s\n",
            "epoch 25 | loss: 0.63847 |  0:00:43s\n",
            "epoch 26 | loss: 0.61446 |  0:00:45s\n",
            "epoch 27 | loss: 0.63761 |  0:00:47s\n",
            "epoch 28 | loss: 0.69956 |  0:00:48s\n",
            "epoch 29 | loss: 0.76765 |  0:00:50s\n",
            "epoch 30 | loss: 0.72927 |  0:00:51s\n",
            "epoch 31 | loss: 0.66774 |  0:00:53s\n",
            "epoch 32 | loss: 0.62947 |  0:00:54s\n",
            "epoch 33 | loss: 0.73145 |  0:00:56s\n",
            "epoch 34 | loss: 0.77338 |  0:00:58s\n",
            "epoch 35 | loss: 0.72417 |  0:01:00s\n",
            "epoch 36 | loss: 0.58439 |  0:01:02s\n",
            "epoch 37 | loss: 0.60772 |  0:01:03s\n",
            "epoch 38 | loss: 0.63582 |  0:01:05s\n",
            "epoch 39 | loss: 0.63397 |  0:01:06s\n",
            "epoch 40 | loss: 0.61898 |  0:01:08s\n",
            "epoch 41 | loss: 0.62002 |  0:01:09s\n",
            "epoch 42 | loss: 0.64992 |  0:01:11s\n",
            "epoch 43 | loss: 0.67471 |  0:01:13s\n",
            "epoch 44 | loss: 0.66454 |  0:01:15s\n",
            "epoch 45 | loss: 0.68026 |  0:01:17s\n",
            "epoch 46 | loss: 0.6686  |  0:01:18s\n",
            "epoch 47 | loss: 0.59545 |  0:01:20s\n",
            "epoch 48 | loss: 0.60415 |  0:01:22s\n",
            "epoch 49 | loss: 0.59858 |  0:01:23s\n",
            "epoch 50 | loss: 0.62392 |  0:01:25s\n",
            "epoch 51 | loss: 0.59554 |  0:01:27s\n",
            "epoch 52 | loss: 0.55827 |  0:01:29s\n",
            "epoch 53 | loss: 0.55784 |  0:01:31s\n",
            "epoch 54 | loss: 0.55389 |  0:01:32s\n",
            "epoch 55 | loss: 0.57419 |  0:01:34s\n",
            "epoch 56 | loss: 0.61628 |  0:01:35s\n",
            "epoch 57 | loss: 0.69867 |  0:01:37s\n",
            "epoch 58 | loss: 0.60093 |  0:01:38s\n",
            "epoch 59 | loss: 0.59554 |  0:01:40s\n",
            "epoch 60 | loss: 0.59735 |  0:01:43s\n",
            "epoch 61 | loss: 0.61925 |  0:01:44s\n",
            "epoch 62 | loss: 0.57863 |  0:01:46s\n",
            "epoch 63 | loss: 0.56018 |  0:01:47s\n",
            "epoch 64 | loss: 0.5814  |  0:01:49s\n",
            "epoch 65 | loss: 0.60887 |  0:01:50s\n",
            "epoch 66 | loss: 0.60175 |  0:01:52s\n",
            "epoch 67 | loss: 0.60664 |  0:01:53s\n",
            "epoch 68 | loss: 0.56571 |  0:01:56s\n",
            "epoch 69 | loss: 0.54488 |  0:01:58s\n",
            "epoch 70 | loss: 0.57062 |  0:01:59s\n",
            "epoch 71 | loss: 0.56943 |  0:02:01s\n",
            "epoch 72 | loss: 0.59514 |  0:02:02s\n",
            "epoch 73 | loss: 0.60144 |  0:02:04s\n",
            "epoch 74 | loss: 0.63994 |  0:02:05s\n",
            "epoch 75 | loss: 0.5872  |  0:02:07s\n",
            "epoch 76 | loss: 0.58787 |  0:02:09s\n",
            "epoch 77 | loss: 0.59231 |  0:02:11s\n",
            "epoch 78 | loss: 0.61946 |  0:02:12s\n",
            "epoch 79 | loss: 0.79197 |  0:02:14s\n",
            "epoch 80 | loss: 0.65799 |  0:02:15s\n",
            "epoch 81 | loss: 0.64107 |  0:02:17s\n",
            "epoch 82 | loss: 0.59888 |  0:02:18s\n",
            "epoch 83 | loss: 0.54189 |  0:02:20s\n",
            "epoch 84 | loss: 0.54441 |  0:02:22s\n",
            "epoch 85 | loss: 0.5458  |  0:02:24s\n",
            "epoch 86 | loss: 0.54566 |  0:02:26s\n",
            "epoch 87 | loss: 0.53809 |  0:02:28s\n",
            "epoch 88 | loss: 0.53996 |  0:02:29s\n",
            "epoch 89 | loss: 0.55371 |  0:02:31s\n",
            "epoch 90 | loss: 0.55433 |  0:02:32s\n",
            "epoch 91 | loss: 0.55911 |  0:02:34s\n",
            "epoch 92 | loss: 0.52641 |  0:02:35s\n",
            "epoch 93 | loss: 0.53616 |  0:02:38s\n",
            "epoch 94 | loss: 0.52781 |  0:02:40s\n",
            "epoch 95 | loss: 0.5489  |  0:02:41s\n",
            "epoch 96 | loss: 0.57033 |  0:02:43s\n",
            "epoch 97 | loss: 0.57003 |  0:02:44s\n",
            "epoch 98 | loss: 0.57791 |  0:02:46s\n",
            "epoch 99 | loss: 0.59643 |  0:02:47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 17.31647|  0:00:01s\n",
            "epoch 1  | loss: 3.20364 |  0:00:04s\n",
            "epoch 2  | loss: 1.67119 |  0:00:06s\n",
            "epoch 3  | loss: 1.59109 |  0:00:07s\n",
            "epoch 4  | loss: 1.38145 |  0:00:09s\n",
            "epoch 5  | loss: 1.35665 |  0:00:10s\n",
            "epoch 6  | loss: 1.30328 |  0:00:12s\n",
            "epoch 7  | loss: 1.29627 |  0:00:13s\n",
            "epoch 8  | loss: 1.23639 |  0:00:14s\n",
            "epoch 9  | loss: 1.2651  |  0:00:17s\n",
            "epoch 10 | loss: 1.22719 |  0:00:19s\n",
            "epoch 11 | loss: 1.16436 |  0:00:20s\n",
            "epoch 12 | loss: 1.22909 |  0:00:22s\n",
            "epoch 13 | loss: 1.19269 |  0:00:23s\n",
            "epoch 14 | loss: 1.24208 |  0:00:25s\n",
            "epoch 15 | loss: 1.18697 |  0:00:26s\n",
            "epoch 16 | loss: 1.26789 |  0:00:28s\n",
            "epoch 17 | loss: 1.16823 |  0:00:30s\n",
            "epoch 18 | loss: 1.17726 |  0:00:32s\n",
            "epoch 19 | loss: 1.1767  |  0:00:34s\n",
            "epoch 20 | loss: 1.15187 |  0:00:35s\n",
            "epoch 21 | loss: 1.12748 |  0:00:37s\n",
            "epoch 22 | loss: 1.16606 |  0:00:38s\n",
            "epoch 23 | loss: 1.1788  |  0:00:40s\n",
            "epoch 24 | loss: 1.14182 |  0:00:41s\n",
            "epoch 25 | loss: 1.12727 |  0:00:43s\n",
            "epoch 26 | loss: 1.1635  |  0:00:45s\n",
            "epoch 27 | loss: 1.14776 |  0:00:47s\n",
            "epoch 28 | loss: 1.1218  |  0:00:49s\n",
            "epoch 29 | loss: 1.09508 |  0:00:50s\n",
            "epoch 30 | loss: 1.12239 |  0:00:51s\n",
            "epoch 31 | loss: 1.12443 |  0:00:53s\n",
            "epoch 32 | loss: 1.16771 |  0:00:55s\n",
            "epoch 33 | loss: 1.21821 |  0:00:56s\n",
            "epoch 34 | loss: 1.19865 |  0:00:58s\n",
            "epoch 35 | loss: 1.13929 |  0:01:00s\n",
            "epoch 36 | loss: 1.10244 |  0:01:02s\n",
            "epoch 37 | loss: 1.08899 |  0:01:03s\n",
            "epoch 38 | loss: 1.10324 |  0:01:05s\n",
            "epoch 39 | loss: 1.10864 |  0:01:06s\n",
            "epoch 40 | loss: 1.11346 |  0:01:08s\n",
            "epoch 41 | loss: 1.13306 |  0:01:09s\n",
            "epoch 42 | loss: 1.16323 |  0:01:11s\n",
            "epoch 43 | loss: 1.12275 |  0:01:13s\n",
            "epoch 44 | loss: 1.12544 |  0:01:15s\n",
            "epoch 45 | loss: 1.09963 |  0:01:17s\n",
            "epoch 46 | loss: 1.10689 |  0:01:18s\n",
            "epoch 47 | loss: 1.0537  |  0:01:20s\n",
            "epoch 48 | loss: 1.06815 |  0:01:21s\n",
            "epoch 49 | loss: 1.1412  |  0:01:23s\n",
            "epoch 50 | loss: 1.17337 |  0:01:24s\n",
            "epoch 51 | loss: 1.11799 |  0:01:27s\n",
            "epoch 52 | loss: 1.08183 |  0:01:29s\n",
            "epoch 53 | loss: 1.09391 |  0:01:30s\n",
            "epoch 54 | loss: 1.08917 |  0:01:32s\n",
            "epoch 55 | loss: 1.08094 |  0:01:33s\n",
            "epoch 56 | loss: 1.0741  |  0:01:35s\n",
            "epoch 57 | loss: 1.05243 |  0:01:36s\n",
            "epoch 58 | loss: 1.07135 |  0:01:38s\n",
            "epoch 59 | loss: 1.08342 |  0:01:40s\n",
            "epoch 60 | loss: 1.09361 |  0:01:42s\n",
            "epoch 61 | loss: 1.0917  |  0:01:43s\n",
            "epoch 62 | loss: 1.06934 |  0:01:45s\n",
            "epoch 63 | loss: 1.10202 |  0:01:46s\n",
            "epoch 64 | loss: 1.1086  |  0:01:48s\n",
            "epoch 65 | loss: 1.12773 |  0:01:49s\n",
            "epoch 66 | loss: 1.17306 |  0:01:51s\n",
            "epoch 67 | loss: 1.1095  |  0:01:52s\n",
            "epoch 68 | loss: 1.06894 |  0:01:54s\n",
            "epoch 69 | loss: 1.06458 |  0:01:57s\n",
            "epoch 70 | loss: 1.07416 |  0:01:58s\n",
            "epoch 71 | loss: 1.11292 |  0:02:00s\n",
            "epoch 72 | loss: 1.10955 |  0:02:01s\n",
            "epoch 73 | loss: 1.09456 |  0:02:03s\n",
            "epoch 74 | loss: 1.09091 |  0:02:04s\n",
            "epoch 75 | loss: 1.09019 |  0:02:06s\n",
            "epoch 76 | loss: 1.08137 |  0:02:08s\n",
            "epoch 77 | loss: 1.06323 |  0:02:10s\n",
            "epoch 78 | loss: 1.05087 |  0:02:11s\n",
            "epoch 79 | loss: 1.05821 |  0:02:13s\n",
            "epoch 80 | loss: 1.08225 |  0:02:14s\n",
            "epoch 81 | loss: 1.09215 |  0:02:16s\n",
            "epoch 82 | loss: 1.09069 |  0:02:17s\n",
            "epoch 83 | loss: 1.05368 |  0:02:19s\n",
            "epoch 84 | loss: 1.06144 |  0:02:20s\n",
            "epoch 85 | loss: 1.05603 |  0:02:23s\n",
            "epoch 86 | loss: 1.08821 |  0:02:25s\n",
            "epoch 87 | loss: 1.08894 |  0:02:26s\n",
            "epoch 88 | loss: 1.08286 |  0:02:28s\n",
            "epoch 89 | loss: 1.08344 |  0:02:29s\n",
            "epoch 90 | loss: 1.07389 |  0:02:31s\n",
            "epoch 91 | loss: 1.09419 |  0:02:33s\n",
            "epoch 92 | loss: 1.09844 |  0:02:34s\n",
            "epoch 93 | loss: 1.10269 |  0:02:36s\n",
            "epoch 94 | loss: 1.05621 |  0:02:39s\n",
            "epoch 95 | loss: 1.03969 |  0:02:40s\n",
            "epoch 96 | loss: 1.06506 |  0:02:42s\n",
            "epoch 97 | loss: 1.04368 |  0:02:43s\n",
            "epoch 98 | loss: 1.06621 |  0:02:45s\n",
            "epoch 99 | loss: 1.08559 |  0:02:46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 10.91836|  0:00:01s\n",
            "epoch 1  | loss: 1.53385 |  0:00:03s\n",
            "epoch 2  | loss: 1.34029 |  0:00:05s\n",
            "epoch 3  | loss: 1.01202 |  0:00:07s\n",
            "epoch 4  | loss: 0.85837 |  0:00:08s\n",
            "epoch 5  | loss: 0.84384 |  0:00:10s\n",
            "epoch 6  | loss: 0.88199 |  0:00:11s\n",
            "epoch 7  | loss: 0.76492 |  0:00:13s\n",
            "epoch 8  | loss: 0.78695 |  0:00:14s\n",
            "epoch 9  | loss: 0.80251 |  0:00:17s\n",
            "epoch 10 | loss: 0.79447 |  0:00:19s\n",
            "epoch 11 | loss: 0.71135 |  0:00:20s\n",
            "epoch 12 | loss: 0.71882 |  0:00:22s\n",
            "epoch 13 | loss: 0.706   |  0:00:23s\n",
            "epoch 14 | loss: 0.67045 |  0:00:25s\n",
            "epoch 15 | loss: 0.7022  |  0:00:26s\n",
            "epoch 16 | loss: 0.70941 |  0:00:28s\n",
            "epoch 17 | loss: 0.68735 |  0:00:30s\n",
            "epoch 18 | loss: 0.67324 |  0:00:32s\n",
            "epoch 19 | loss: 0.70386 |  0:00:34s\n",
            "epoch 20 | loss: 0.66044 |  0:00:35s\n",
            "epoch 21 | loss: 0.71118 |  0:00:37s\n",
            "epoch 22 | loss: 0.72479 |  0:00:38s\n",
            "epoch 23 | loss: 0.69876 |  0:00:40s\n",
            "epoch 24 | loss: 0.68368 |  0:00:41s\n",
            "epoch 25 | loss: 0.72757 |  0:00:43s\n",
            "epoch 26 | loss: 0.68524 |  0:00:45s\n",
            "epoch 27 | loss: 0.63522 |  0:00:47s\n",
            "epoch 28 | loss: 0.63281 |  0:00:49s\n",
            "epoch 29 | loss: 0.66839 |  0:00:50s\n",
            "epoch 30 | loss: 0.65591 |  0:00:52s\n",
            "epoch 31 | loss: 0.6624  |  0:00:53s\n",
            "epoch 32 | loss: 0.61455 |  0:00:55s\n",
            "epoch 33 | loss: 0.61236 |  0:00:57s\n",
            "epoch 34 | loss: 0.62186 |  0:00:59s\n",
            "epoch 35 | loss: 0.6543  |  0:01:01s\n",
            "epoch 36 | loss: 0.63307 |  0:01:02s\n",
            "epoch 37 | loss: 0.60727 |  0:01:04s\n",
            "epoch 38 | loss: 0.64321 |  0:01:05s\n",
            "epoch 39 | loss: 0.64663 |  0:01:07s\n",
            "epoch 40 | loss: 0.61061 |  0:01:09s\n",
            "epoch 41 | loss: 0.6746  |  0:01:10s\n",
            "epoch 42 | loss: 0.64078 |  0:01:12s\n",
            "epoch 43 | loss: 0.62979 |  0:01:14s\n",
            "epoch 44 | loss: 0.60406 |  0:01:16s\n",
            "epoch 45 | loss: 0.61961 |  0:01:18s\n",
            "epoch 46 | loss: 0.64263 |  0:01:19s\n",
            "epoch 47 | loss: 0.64017 |  0:01:21s\n",
            "epoch 48 | loss: 0.59796 |  0:01:22s\n",
            "epoch 49 | loss: 0.6305  |  0:01:24s\n",
            "epoch 50 | loss: 0.59692 |  0:01:26s\n",
            "epoch 51 | loss: 0.61641 |  0:01:28s\n",
            "epoch 52 | loss: 0.59417 |  0:01:30s\n",
            "epoch 53 | loss: 0.63462 |  0:01:31s\n",
            "epoch 54 | loss: 0.65809 |  0:01:33s\n",
            "epoch 55 | loss: 0.65061 |  0:01:34s\n",
            "epoch 56 | loss: 0.68909 |  0:01:36s\n",
            "epoch 57 | loss: 0.61396 |  0:01:37s\n",
            "epoch 58 | loss: 0.6089  |  0:01:39s\n",
            "epoch 59 | loss: 0.62207 |  0:01:41s\n",
            "epoch 60 | loss: 0.59856 |  0:01:43s\n",
            "epoch 61 | loss: 0.62901 |  0:01:45s\n",
            "epoch 62 | loss: 0.66347 |  0:01:46s\n",
            "epoch 63 | loss: 0.64238 |  0:01:48s\n",
            "epoch 64 | loss: 0.58811 |  0:01:49s\n",
            "epoch 65 | loss: 0.62687 |  0:01:51s\n",
            "epoch 66 | loss: 0.60602 |  0:01:52s\n",
            "epoch 67 | loss: 0.59537 |  0:01:54s\n",
            "epoch 68 | loss: 0.60224 |  0:01:57s\n",
            "epoch 69 | loss: 0.61247 |  0:01:58s\n",
            "epoch 70 | loss: 0.59306 |  0:02:00s\n",
            "epoch 71 | loss: 0.57523 |  0:02:01s\n",
            "epoch 72 | loss: 0.58921 |  0:02:03s\n",
            "epoch 73 | loss: 0.60648 |  0:02:04s\n",
            "epoch 74 | loss: 0.61424 |  0:02:06s\n",
            "epoch 75 | loss: 0.63163 |  0:02:08s\n",
            "epoch 76 | loss: 0.61933 |  0:02:10s\n",
            "epoch 77 | loss: 0.62419 |  0:02:12s\n",
            "epoch 78 | loss: 0.62895 |  0:02:13s\n",
            "epoch 79 | loss: 0.64761 |  0:02:15s\n",
            "epoch 80 | loss: 0.61784 |  0:02:17s\n",
            "epoch 81 | loss: 0.62527 |  0:02:18s\n",
            "epoch 82 | loss: 0.63462 |  0:02:20s\n",
            "epoch 83 | loss: 0.6763  |  0:02:21s\n",
            "epoch 84 | loss: 0.6406  |  0:02:24s\n",
            "epoch 85 | loss: 0.62451 |  0:02:26s\n",
            "epoch 86 | loss: 0.63476 |  0:02:27s\n",
            "epoch 87 | loss: 0.68115 |  0:02:29s\n",
            "epoch 88 | loss: 0.64498 |  0:02:30s\n",
            "epoch 89 | loss: 0.60596 |  0:02:32s\n",
            "epoch 90 | loss: 0.63865 |  0:02:33s\n",
            "epoch 91 | loss: 0.63427 |  0:02:35s\n",
            "epoch 92 | loss: 0.59655 |  0:02:37s\n",
            "epoch 93 | loss: 0.61498 |  0:02:39s\n",
            "epoch 94 | loss: 0.5984  |  0:02:41s\n",
            "epoch 95 | loss: 0.64848 |  0:02:42s\n",
            "epoch 96 | loss: 0.59395 |  0:02:44s\n",
            "epoch 97 | loss: 0.58891 |  0:02:45s\n",
            "epoch 98 | loss: 0.59697 |  0:02:47s\n",
            "epoch 99 | loss: 0.58798 |  0:02:48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 10.36222|  0:00:02s\n",
            "epoch 1  | loss: 1.88693 |  0:00:04s\n",
            "epoch 2  | loss: 1.43039 |  0:00:05s\n",
            "epoch 3  | loss: 1.31793 |  0:00:07s\n",
            "epoch 4  | loss: 1.24672 |  0:00:08s\n",
            "epoch 5  | loss: 1.14753 |  0:00:10s\n",
            "epoch 6  | loss: 1.12647 |  0:00:12s\n",
            "epoch 7  | loss: 1.18858 |  0:00:13s\n",
            "epoch 8  | loss: 1.07984 |  0:00:15s\n",
            "epoch 9  | loss: 1.11988 |  0:00:17s\n",
            "epoch 10 | loss: 1.18781 |  0:00:19s\n",
            "epoch 11 | loss: 1.08947 |  0:00:21s\n",
            "epoch 12 | loss: 1.10903 |  0:00:22s\n",
            "epoch 13 | loss: 1.08599 |  0:00:24s\n",
            "epoch 14 | loss: 1.0522  |  0:00:25s\n",
            "epoch 15 | loss: 1.02123 |  0:00:27s\n",
            "epoch 16 | loss: 1.06803 |  0:00:29s\n",
            "epoch 17 | loss: 1.0718  |  0:00:31s\n",
            "epoch 18 | loss: 1.0501  |  0:00:33s\n",
            "epoch 19 | loss: 1.01232 |  0:00:34s\n",
            "epoch 20 | loss: 1.01973 |  0:00:36s\n",
            "epoch 21 | loss: 1.06405 |  0:00:38s\n",
            "epoch 22 | loss: 0.97754 |  0:00:39s\n",
            "epoch 23 | loss: 1.00652 |  0:00:41s\n",
            "epoch 24 | loss: 1.06786 |  0:00:43s\n",
            "epoch 25 | loss: 1.00036 |  0:00:45s\n",
            "epoch 26 | loss: 1.00001 |  0:00:46s\n",
            "epoch 27 | loss: 1.02041 |  0:00:48s\n",
            "epoch 28 | loss: 0.97918 |  0:00:50s\n",
            "epoch 29 | loss: 0.99954 |  0:00:51s\n",
            "epoch 30 | loss: 0.96128 |  0:00:53s\n",
            "epoch 31 | loss: 0.96759 |  0:00:54s\n",
            "epoch 32 | loss: 1.04713 |  0:00:56s\n",
            "epoch 33 | loss: 0.99062 |  0:00:59s\n",
            "epoch 34 | loss: 1.01332 |  0:01:00s\n",
            "epoch 35 | loss: 0.97685 |  0:01:02s\n",
            "epoch 36 | loss: 0.97898 |  0:01:04s\n",
            "epoch 37 | loss: 0.99176 |  0:01:05s\n",
            "epoch 38 | loss: 0.96333 |  0:01:07s\n",
            "epoch 39 | loss: 0.97243 |  0:01:08s\n",
            "epoch 40 | loss: 0.9891  |  0:01:10s\n",
            "epoch 41 | loss: 1.02338 |  0:01:13s\n",
            "epoch 42 | loss: 0.97144 |  0:01:14s\n",
            "epoch 43 | loss: 0.96779 |  0:01:16s\n",
            "epoch 44 | loss: 0.96967 |  0:01:17s\n",
            "epoch 45 | loss: 0.96342 |  0:01:19s\n",
            "epoch 46 | loss: 0.95955 |  0:01:20s\n",
            "epoch 47 | loss: 0.93191 |  0:01:22s\n",
            "epoch 48 | loss: 0.94209 |  0:01:24s\n",
            "epoch 49 | loss: 0.93458 |  0:01:26s\n",
            "epoch 50 | loss: 0.95322 |  0:01:28s\n",
            "epoch 51 | loss: 0.97805 |  0:01:29s\n",
            "epoch 52 | loss: 0.96714 |  0:01:31s\n",
            "epoch 53 | loss: 0.91706 |  0:01:32s\n",
            "epoch 54 | loss: 0.95163 |  0:01:34s\n",
            "epoch 55 | loss: 0.97846 |  0:01:36s\n",
            "epoch 56 | loss: 0.98869 |  0:01:37s\n",
            "epoch 57 | loss: 0.97538 |  0:01:39s\n",
            "epoch 58 | loss: 0.95961 |  0:01:42s\n",
            "epoch 59 | loss: 0.97524 |  0:01:43s\n",
            "epoch 60 | loss: 0.93147 |  0:01:45s\n",
            "epoch 61 | loss: 0.94048 |  0:01:46s\n",
            "epoch 62 | loss: 0.93167 |  0:01:48s\n",
            "epoch 63 | loss: 0.93955 |  0:01:49s\n",
            "epoch 64 | loss: 0.95561 |  0:01:51s\n",
            "epoch 65 | loss: 0.98152 |  0:01:53s\n",
            "epoch 66 | loss: 0.96417 |  0:01:55s\n",
            "epoch 67 | loss: 0.9671  |  0:01:57s\n",
            "epoch 68 | loss: 0.95134 |  0:01:58s\n",
            "epoch 69 | loss: 0.97575 |  0:02:00s\n",
            "epoch 70 | loss: 0.9387  |  0:02:01s\n",
            "epoch 71 | loss: 0.94694 |  0:02:03s\n",
            "epoch 72 | loss: 0.97281 |  0:02:05s\n",
            "epoch 73 | loss: 0.96182 |  0:02:07s\n",
            "epoch 74 | loss: 0.95881 |  0:02:09s\n",
            "epoch 75 | loss: 0.99165 |  0:02:10s\n",
            "epoch 76 | loss: 0.98126 |  0:02:12s\n",
            "epoch 77 | loss: 0.96403 |  0:02:14s\n",
            "epoch 78 | loss: 0.93196 |  0:02:15s\n",
            "epoch 79 | loss: 0.95196 |  0:02:17s\n",
            "epoch 80 | loss: 0.95931 |  0:02:18s\n",
            "epoch 81 | loss: 0.96025 |  0:02:20s\n",
            "epoch 82 | loss: 0.93576 |  0:02:22s\n",
            "epoch 83 | loss: 0.94867 |  0:02:24s\n",
            "epoch 84 | loss: 0.92465 |  0:02:26s\n",
            "epoch 85 | loss: 0.93098 |  0:02:27s\n",
            "epoch 86 | loss: 0.92371 |  0:02:29s\n",
            "epoch 87 | loss: 0.92126 |  0:02:30s\n",
            "epoch 88 | loss: 0.93134 |  0:02:32s\n",
            "epoch 89 | loss: 0.94485 |  0:02:34s\n",
            "epoch 90 | loss: 0.91772 |  0:02:36s\n",
            "epoch 91 | loss: 0.93508 |  0:02:38s\n",
            "epoch 92 | loss: 0.91319 |  0:02:39s\n",
            "epoch 93 | loss: 0.94247 |  0:02:41s\n",
            "epoch 94 | loss: 0.94757 |  0:02:43s\n",
            "epoch 95 | loss: 0.93661 |  0:02:44s\n",
            "epoch 96 | loss: 0.95423 |  0:02:46s\n",
            "epoch 97 | loss: 0.93067 |  0:02:47s\n",
            "epoch 98 | loss: 0.94159 |  0:02:49s\n",
            "epoch 99 | loss: 0.93255 |  0:02:51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 8.14371 |  0:00:01s\n",
            "epoch 1  | loss: 1.61397 |  0:00:03s\n",
            "epoch 2  | loss: 1.43775 |  0:00:04s\n",
            "epoch 3  | loss: 0.88763 |  0:00:06s\n",
            "epoch 4  | loss: 0.8674  |  0:00:07s\n",
            "epoch 5  | loss: 0.80086 |  0:00:09s\n",
            "epoch 6  | loss: 0.89067 |  0:00:11s\n",
            "epoch 7  | loss: 0.74415 |  0:00:13s\n",
            "epoch 8  | loss: 0.72272 |  0:00:15s\n",
            "epoch 9  | loss: 0.74089 |  0:00:17s\n",
            "epoch 10 | loss: 0.76571 |  0:00:18s\n",
            "epoch 11 | loss: 0.76361 |  0:00:20s\n",
            "epoch 12 | loss: 0.89465 |  0:00:21s\n",
            "epoch 13 | loss: 0.84752 |  0:00:23s\n",
            "epoch 14 | loss: 0.75226 |  0:00:25s\n",
            "epoch 15 | loss: 0.6631  |  0:00:27s\n",
            "epoch 16 | loss: 0.68692 |  0:00:28s\n",
            "epoch 17 | loss: 0.65991 |  0:00:30s\n",
            "epoch 18 | loss: 0.63661 |  0:00:32s\n",
            "epoch 19 | loss: 0.60337 |  0:00:33s\n",
            "epoch 20 | loss: 0.61552 |  0:00:35s\n",
            "epoch 21 | loss: 0.62516 |  0:00:36s\n",
            "epoch 22 | loss: 0.61981 |  0:00:38s\n",
            "epoch 23 | loss: 0.60735 |  0:00:41s\n",
            "epoch 24 | loss: 0.61606 |  0:00:42s\n",
            "epoch 25 | loss: 0.59659 |  0:00:44s\n",
            "epoch 26 | loss: 0.59023 |  0:00:45s\n",
            "epoch 27 | loss: 0.58262 |  0:00:47s\n",
            "epoch 28 | loss: 0.58621 |  0:00:49s\n",
            "epoch 29 | loss: 0.61773 |  0:00:50s\n",
            "epoch 30 | loss: 0.67714 |  0:00:52s\n",
            "epoch 31 | loss: 0.63743 |  0:00:54s\n",
            "epoch 32 | loss: 0.56667 |  0:00:56s\n",
            "epoch 33 | loss: 0.57834 |  0:00:58s\n",
            "epoch 34 | loss: 0.60152 |  0:00:59s\n",
            "epoch 35 | loss: 0.57541 |  0:01:01s\n",
            "epoch 36 | loss: 0.61408 |  0:01:02s\n",
            "epoch 37 | loss: 0.5698  |  0:01:04s\n",
            "epoch 38 | loss: 0.55907 |  0:01:06s\n",
            "epoch 39 | loss: 0.55588 |  0:01:08s\n",
            "epoch 40 | loss: 0.53645 |  0:01:10s\n",
            "epoch 41 | loss: 0.58534 |  0:01:11s\n",
            "epoch 42 | loss: 0.58653 |  0:01:13s\n",
            "epoch 43 | loss: 0.5221  |  0:01:14s\n",
            "epoch 44 | loss: 0.56425 |  0:01:16s\n",
            "epoch 45 | loss: 0.53737 |  0:01:17s\n",
            "epoch 46 | loss: 0.52498 |  0:01:19s\n",
            "epoch 47 | loss: 0.54018 |  0:01:21s\n",
            "epoch 48 | loss: 0.54787 |  0:01:23s\n",
            "epoch 49 | loss: 0.62008 |  0:01:25s\n",
            "epoch 50 | loss: 0.58049 |  0:01:26s\n",
            "epoch 51 | loss: 0.57199 |  0:01:28s\n",
            "epoch 52 | loss: 0.52688 |  0:01:29s\n",
            "epoch 53 | loss: 0.53589 |  0:01:31s\n",
            "epoch 54 | loss: 0.53827 |  0:01:32s\n",
            "epoch 55 | loss: 0.59616 |  0:01:34s\n",
            "epoch 56 | loss: 0.5754  |  0:01:37s\n",
            "epoch 57 | loss: 0.54488 |  0:01:38s\n",
            "epoch 58 | loss: 0.54759 |  0:01:40s\n",
            "epoch 59 | loss: 0.51284 |  0:01:41s\n",
            "epoch 60 | loss: 0.50974 |  0:01:43s\n",
            "epoch 61 | loss: 0.5548  |  0:01:44s\n",
            "epoch 62 | loss: 0.55181 |  0:01:46s\n",
            "epoch 63 | loss: 0.50622 |  0:01:48s\n",
            "epoch 64 | loss: 0.50064 |  0:01:50s\n",
            "epoch 65 | loss: 0.53802 |  0:01:52s\n",
            "epoch 66 | loss: 0.51395 |  0:01:53s\n",
            "epoch 67 | loss: 0.49404 |  0:01:55s\n",
            "epoch 68 | loss: 0.49892 |  0:01:56s\n",
            "epoch 69 | loss: 0.52776 |  0:01:58s\n",
            "epoch 70 | loss: 0.51265 |  0:01:59s\n",
            "epoch 71 | loss: 0.4988  |  0:02:01s\n",
            "epoch 72 | loss: 0.53339 |  0:02:03s\n",
            "epoch 73 | loss: 0.53461 |  0:02:05s\n",
            "epoch 74 | loss: 0.4957  |  0:02:07s\n",
            "epoch 75 | loss: 0.49468 |  0:02:08s\n",
            "epoch 76 | loss: 0.49215 |  0:02:10s\n",
            "epoch 77 | loss: 0.50746 |  0:02:11s\n",
            "epoch 78 | loss: 0.4936  |  0:02:13s\n",
            "epoch 79 | loss: 0.48588 |  0:02:15s\n",
            "epoch 80 | loss: 0.47066 |  0:02:17s\n",
            "epoch 81 | loss: 0.50066 |  0:02:19s\n",
            "epoch 82 | loss: 0.49615 |  0:02:20s\n",
            "epoch 83 | loss: 0.50759 |  0:02:22s\n",
            "epoch 84 | loss: 0.48434 |  0:02:23s\n",
            "epoch 85 | loss: 0.51061 |  0:02:25s\n",
            "epoch 86 | loss: 0.49737 |  0:02:26s\n",
            "epoch 87 | loss: 0.50489 |  0:02:28s\n",
            "epoch 88 | loss: 0.56774 |  0:02:30s\n",
            "epoch 89 | loss: 0.71399 |  0:02:32s\n",
            "epoch 90 | loss: 0.56293 |  0:02:34s\n",
            "epoch 91 | loss: 0.50993 |  0:02:35s\n",
            "epoch 92 | loss: 0.57469 |  0:02:37s\n",
            "epoch 93 | loss: 0.51375 |  0:02:39s\n",
            "epoch 94 | loss: 0.51233 |  0:02:40s\n",
            "epoch 95 | loss: 0.54167 |  0:02:42s\n",
            "epoch 96 | loss: 0.49846 |  0:02:44s\n",
            "epoch 97 | loss: 0.55058 |  0:02:46s\n",
            "epoch 98 | loss: 0.51063 |  0:02:48s\n",
            "epoch 99 | loss: 0.47545 |  0:02:49s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 19.0596 |  0:00:01s\n",
            "epoch 1  | loss: 2.86388 |  0:00:03s\n",
            "epoch 2  | loss: 2.44191 |  0:00:04s\n",
            "epoch 3  | loss: 1.92016 |  0:00:06s\n",
            "epoch 4  | loss: 1.76338 |  0:00:08s\n",
            "epoch 5  | loss: 1.79259 |  0:00:10s\n",
            "epoch 6  | loss: 1.662   |  0:00:12s\n",
            "epoch 7  | loss: 1.56958 |  0:00:13s\n",
            "epoch 8  | loss: 1.49898 |  0:00:15s\n",
            "epoch 9  | loss: 1.4566  |  0:00:16s\n",
            "epoch 10 | loss: 1.41928 |  0:00:18s\n",
            "epoch 11 | loss: 1.44262 |  0:00:19s\n",
            "epoch 12 | loss: 1.44989 |  0:00:21s\n",
            "epoch 13 | loss: 1.40431 |  0:00:24s\n",
            "epoch 14 | loss: 1.37958 |  0:00:25s\n",
            "epoch 15 | loss: 1.41919 |  0:00:27s\n",
            "epoch 16 | loss: 1.36982 |  0:00:28s\n",
            "epoch 17 | loss: 1.32897 |  0:00:30s\n",
            "epoch 18 | loss: 1.33965 |  0:00:32s\n",
            "epoch 19 | loss: 1.37558 |  0:00:33s\n",
            "epoch 20 | loss: 1.39893 |  0:00:35s\n",
            "epoch 21 | loss: 1.32436 |  0:00:38s\n",
            "epoch 22 | loss: 1.34004 |  0:00:39s\n",
            "epoch 23 | loss: 1.32479 |  0:00:41s\n",
            "epoch 24 | loss: 1.3966  |  0:00:42s\n",
            "epoch 25 | loss: 1.29737 |  0:00:44s\n",
            "epoch 26 | loss: 1.32783 |  0:00:45s\n",
            "epoch 27 | loss: 1.36032 |  0:00:47s\n",
            "epoch 28 | loss: 1.31291 |  0:00:49s\n",
            "epoch 29 | loss: 1.3482  |  0:00:51s\n",
            "epoch 30 | loss: 1.35599 |  0:00:53s\n",
            "epoch 31 | loss: 1.29231 |  0:00:54s\n",
            "epoch 32 | loss: 1.27298 |  0:00:56s\n",
            "epoch 33 | loss: 1.29801 |  0:00:57s\n",
            "epoch 34 | loss: 1.2994  |  0:00:59s\n",
            "epoch 35 | loss: 1.26558 |  0:01:00s\n",
            "epoch 36 | loss: 1.27931 |  0:01:02s\n",
            "epoch 37 | loss: 1.27114 |  0:01:05s\n",
            "epoch 38 | loss: 1.30758 |  0:01:06s\n",
            "epoch 39 | loss: 1.24911 |  0:01:08s\n",
            "epoch 40 | loss: 1.25733 |  0:01:10s\n",
            "epoch 41 | loss: 1.30725 |  0:01:11s\n",
            "epoch 42 | loss: 1.26683 |  0:01:13s\n",
            "epoch 43 | loss: 1.30195 |  0:01:14s\n",
            "epoch 44 | loss: 1.29339 |  0:01:16s\n",
            "epoch 45 | loss: 1.35249 |  0:01:18s\n",
            "epoch 46 | loss: 1.3112  |  0:01:20s\n",
            "epoch 47 | loss: 1.232   |  0:01:22s\n",
            "epoch 48 | loss: 1.28294 |  0:01:23s\n",
            "epoch 49 | loss: 1.23951 |  0:01:25s\n",
            "epoch 50 | loss: 1.23272 |  0:01:26s\n",
            "epoch 51 | loss: 1.29853 |  0:01:28s\n",
            "epoch 52 | loss: 1.25301 |  0:01:30s\n",
            "epoch 53 | loss: 1.22005 |  0:01:32s\n",
            "epoch 54 | loss: 1.25622 |  0:01:34s\n",
            "epoch 55 | loss: 1.30293 |  0:01:35s\n",
            "epoch 56 | loss: 1.28297 |  0:01:37s\n",
            "epoch 57 | loss: 1.2322  |  0:01:38s\n",
            "epoch 58 | loss: 1.17837 |  0:01:40s\n",
            "epoch 59 | loss: 1.18663 |  0:01:41s\n",
            "epoch 60 | loss: 1.21441 |  0:01:43s\n",
            "epoch 61 | loss: 1.225   |  0:01:45s\n",
            "epoch 62 | loss: 1.20206 |  0:01:47s\n",
            "epoch 63 | loss: 1.20455 |  0:01:49s\n",
            "epoch 64 | loss: 1.1944  |  0:01:51s\n",
            "epoch 65 | loss: 1.18096 |  0:01:52s\n",
            "epoch 66 | loss: 1.22909 |  0:01:54s\n",
            "epoch 67 | loss: 1.17894 |  0:01:56s\n",
            "epoch 68 | loss: 1.22542 |  0:01:57s\n",
            "epoch 69 | loss: 1.20012 |  0:01:59s\n",
            "epoch 70 | loss: 1.17554 |  0:02:01s\n",
            "epoch 71 | loss: 1.18029 |  0:02:03s\n",
            "epoch 72 | loss: 1.18897 |  0:02:05s\n",
            "epoch 73 | loss: 1.16926 |  0:02:06s\n",
            "epoch 74 | loss: 1.16258 |  0:02:08s\n",
            "epoch 75 | loss: 1.21457 |  0:02:09s\n",
            "epoch 76 | loss: 1.19201 |  0:02:11s\n",
            "epoch 77 | loss: 1.18254 |  0:02:13s\n",
            "epoch 78 | loss: 1.20008 |  0:02:15s\n",
            "epoch 79 | loss: 1.21147 |  0:02:17s\n",
            "epoch 80 | loss: 1.259   |  0:02:18s\n",
            "epoch 81 | loss: 1.17957 |  0:02:20s\n",
            "epoch 82 | loss: 1.24242 |  0:02:22s\n",
            "epoch 83 | loss: 1.20474 |  0:02:23s\n",
            "epoch 84 | loss: 1.18934 |  0:02:25s\n",
            "epoch 85 | loss: 1.17855 |  0:02:27s\n",
            "epoch 86 | loss: 1.18758 |  0:02:29s\n",
            "epoch 87 | loss: 1.22993 |  0:02:31s\n",
            "epoch 88 | loss: 1.23609 |  0:02:33s\n",
            "epoch 89 | loss: 1.14668 |  0:02:34s\n",
            "epoch 90 | loss: 1.14993 |  0:02:36s\n",
            "epoch 91 | loss: 1.15078 |  0:02:37s\n",
            "epoch 92 | loss: 1.17134 |  0:02:39s\n",
            "epoch 93 | loss: 1.17756 |  0:02:41s\n",
            "epoch 94 | loss: 1.13936 |  0:02:43s\n",
            "epoch 95 | loss: 1.14735 |  0:02:45s\n",
            "epoch 96 | loss: 1.12461 |  0:02:46s\n",
            "epoch 97 | loss: 1.14372 |  0:02:48s\n",
            "epoch 98 | loss: 1.13643 |  0:02:49s\n",
            "epoch 99 | loss: 1.13341 |  0:02:51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.55354 |  0:00:02s\n",
            "epoch 1  | loss: 1.82542 |  0:00:05s\n",
            "epoch 2  | loss: 1.25519 |  0:00:07s\n",
            "epoch 3  | loss: 1.17171 |  0:00:09s\n",
            "epoch 4  | loss: 1.05962 |  0:00:11s\n",
            "epoch 5  | loss: 1.01673 |  0:00:13s\n",
            "epoch 6  | loss: 1.0844  |  0:00:15s\n",
            "epoch 7  | loss: 0.9016  |  0:00:18s\n",
            "epoch 8  | loss: 0.94326 |  0:00:20s\n",
            "epoch 9  | loss: 0.90682 |  0:00:22s\n",
            "epoch 10 | loss: 0.92275 |  0:00:25s\n",
            "epoch 11 | loss: 0.96415 |  0:00:26s\n",
            "epoch 12 | loss: 0.91946 |  0:00:29s\n",
            "epoch 13 | loss: 0.90473 |  0:00:32s\n",
            "epoch 14 | loss: 0.9816  |  0:00:34s\n",
            "epoch 15 | loss: 0.91115 |  0:00:36s\n",
            "epoch 16 | loss: 0.98981 |  0:00:38s\n",
            "epoch 17 | loss: 0.89525 |  0:00:40s\n",
            "epoch 18 | loss: 0.94696 |  0:00:42s\n",
            "epoch 19 | loss: 0.91303 |  0:00:45s\n",
            "epoch 20 | loss: 0.8231  |  0:00:47s\n",
            "epoch 21 | loss: 0.8452  |  0:00:49s\n",
            "epoch 22 | loss: 0.86703 |  0:00:51s\n",
            "epoch 23 | loss: 0.83934 |  0:00:53s\n",
            "epoch 24 | loss: 0.81882 |  0:00:55s\n",
            "epoch 25 | loss: 0.82139 |  0:00:58s\n",
            "epoch 26 | loss: 0.84555 |  0:01:00s\n",
            "epoch 27 | loss: 0.83367 |  0:01:02s\n",
            "epoch 28 | loss: 0.86212 |  0:01:04s\n",
            "epoch 29 | loss: 0.84833 |  0:01:06s\n",
            "epoch 30 | loss: 0.81125 |  0:01:08s\n",
            "epoch 31 | loss: 0.81448 |  0:01:11s\n",
            "epoch 32 | loss: 0.80338 |  0:01:14s\n",
            "epoch 33 | loss: 0.80696 |  0:01:16s\n",
            "epoch 34 | loss: 0.80114 |  0:01:18s\n",
            "epoch 35 | loss: 0.79124 |  0:01:20s\n",
            "epoch 36 | loss: 0.80805 |  0:01:22s\n",
            "epoch 37 | loss: 0.81914 |  0:01:24s\n",
            "epoch 38 | loss: 0.78741 |  0:01:27s\n",
            "epoch 39 | loss: 0.7916  |  0:01:29s\n",
            "epoch 40 | loss: 0.81846 |  0:01:31s\n",
            "epoch 41 | loss: 0.87682 |  0:01:33s\n",
            "epoch 42 | loss: 0.83933 |  0:01:35s\n",
            "epoch 43 | loss: 0.79363 |  0:01:37s\n",
            "epoch 44 | loss: 0.75257 |  0:01:40s\n",
            "epoch 45 | loss: 0.78266 |  0:01:42s\n",
            "epoch 46 | loss: 0.79616 |  0:01:44s\n",
            "epoch 47 | loss: 0.83766 |  0:01:46s\n",
            "epoch 48 | loss: 0.81712 |  0:01:48s\n",
            "epoch 49 | loss: 0.85093 |  0:01:50s\n",
            "epoch 50 | loss: 0.81494 |  0:01:53s\n",
            "epoch 51 | loss: 0.79618 |  0:01:56s\n",
            "epoch 52 | loss: 0.75373 |  0:01:57s\n",
            "epoch 53 | loss: 0.74354 |  0:01:59s\n",
            "epoch 54 | loss: 0.84364 |  0:02:01s\n",
            "epoch 55 | loss: 0.79567 |  0:02:03s\n",
            "epoch 56 | loss: 0.8054  |  0:02:05s\n",
            "epoch 57 | loss: 0.84143 |  0:02:08s\n",
            "epoch 58 | loss: 0.84404 |  0:02:11s\n",
            "epoch 59 | loss: 0.83441 |  0:02:13s\n",
            "epoch 60 | loss: 0.74285 |  0:02:15s\n",
            "epoch 61 | loss: 0.77564 |  0:02:17s\n",
            "epoch 62 | loss: 0.79459 |  0:02:19s\n",
            "epoch 63 | loss: 0.75631 |  0:02:21s\n",
            "epoch 64 | loss: 0.7926  |  0:02:24s\n",
            "epoch 65 | loss: 0.78686 |  0:02:26s\n",
            "epoch 66 | loss: 0.76664 |  0:02:28s\n",
            "epoch 67 | loss: 0.76993 |  0:02:30s\n",
            "epoch 68 | loss: 0.77188 |  0:02:32s\n",
            "epoch 69 | loss: 0.79416 |  0:02:35s\n",
            "epoch 70 | loss: 0.73779 |  0:02:37s\n",
            "epoch 71 | loss: 0.75022 |  0:02:39s\n",
            "epoch 72 | loss: 0.79068 |  0:02:41s\n",
            "epoch 73 | loss: 0.78274 |  0:02:43s\n",
            "epoch 74 | loss: 0.7606  |  0:02:45s\n",
            "epoch 75 | loss: 0.76299 |  0:02:48s\n",
            "epoch 76 | loss: 0.84976 |  0:02:51s\n",
            "epoch 77 | loss: 0.79788 |  0:02:53s\n",
            "epoch 78 | loss: 0.77149 |  0:02:55s\n",
            "epoch 79 | loss: 0.77648 |  0:02:57s\n",
            "epoch 80 | loss: 0.74807 |  0:02:59s\n",
            "epoch 81 | loss: 0.75423 |  0:03:01s\n",
            "epoch 82 | loss: 0.73554 |  0:03:04s\n",
            "epoch 83 | loss: 0.74908 |  0:03:06s\n",
            "epoch 84 | loss: 0.73879 |  0:03:08s\n",
            "epoch 85 | loss: 0.75251 |  0:03:10s\n",
            "epoch 86 | loss: 0.75646 |  0:03:12s\n",
            "epoch 87 | loss: 0.78999 |  0:03:14s\n",
            "epoch 88 | loss: 0.78404 |  0:03:17s\n",
            "epoch 89 | loss: 0.76055 |  0:03:19s\n",
            "epoch 90 | loss: 0.75713 |  0:03:22s\n",
            "epoch 91 | loss: 0.73643 |  0:03:24s\n",
            "epoch 92 | loss: 0.73302 |  0:03:25s\n",
            "epoch 93 | loss: 0.71423 |  0:03:27s\n",
            "epoch 94 | loss: 0.73763 |  0:03:30s\n",
            "epoch 95 | loss: 0.73601 |  0:03:33s\n",
            "epoch 96 | loss: 0.72795 |  0:03:35s\n",
            "epoch 97 | loss: 0.7332  |  0:03:37s\n",
            "epoch 98 | loss: 0.73272 |  0:03:39s\n",
            "epoch 99 | loss: 0.73066 |  0:03:41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 8.36405 |  0:00:02s\n",
            "epoch 1  | loss: 1.95087 |  0:00:05s\n",
            "epoch 2  | loss: 1.38254 |  0:00:07s\n",
            "epoch 3  | loss: 1.39245 |  0:00:09s\n",
            "epoch 4  | loss: 1.02785 |  0:00:11s\n",
            "epoch 5  | loss: 0.8642  |  0:00:13s\n",
            "epoch 6  | loss: 0.88844 |  0:00:15s\n",
            "epoch 7  | loss: 0.83458 |  0:00:18s\n",
            "epoch 8  | loss: 0.81933 |  0:00:20s\n",
            "epoch 9  | loss: 0.70819 |  0:00:22s\n",
            "epoch 10 | loss: 0.68898 |  0:00:24s\n",
            "epoch 11 | loss: 0.70984 |  0:00:26s\n",
            "epoch 12 | loss: 0.71003 |  0:00:28s\n",
            "epoch 13 | loss: 0.76169 |  0:00:31s\n",
            "epoch 14 | loss: 0.73935 |  0:00:33s\n",
            "epoch 15 | loss: 0.70342 |  0:00:35s\n",
            "epoch 16 | loss: 0.68353 |  0:00:37s\n",
            "epoch 17 | loss: 0.80367 |  0:00:39s\n",
            "epoch 18 | loss: 0.77208 |  0:00:42s\n",
            "epoch 19 | loss: 0.63959 |  0:00:45s\n",
            "epoch 20 | loss: 0.67088 |  0:00:47s\n",
            "epoch 21 | loss: 0.61352 |  0:00:49s\n",
            "epoch 22 | loss: 0.64707 |  0:00:51s\n",
            "epoch 23 | loss: 0.65097 |  0:00:53s\n",
            "epoch 24 | loss: 0.66767 |  0:00:55s\n",
            "epoch 25 | loss: 0.63429 |  0:00:58s\n",
            "epoch 26 | loss: 0.65211 |  0:01:00s\n",
            "epoch 27 | loss: 0.67168 |  0:01:02s\n",
            "epoch 28 | loss: 0.63354 |  0:01:04s\n",
            "epoch 29 | loss: 0.69051 |  0:01:06s\n",
            "epoch 30 | loss: 0.73725 |  0:01:08s\n",
            "epoch 31 | loss: 0.67759 |  0:01:10s\n",
            "epoch 32 | loss: 0.66194 |  0:01:13s\n",
            "epoch 33 | loss: 0.65058 |  0:01:15s\n",
            "epoch 34 | loss: 0.6381  |  0:01:17s\n",
            "epoch 35 | loss: 0.6907  |  0:01:20s\n",
            "epoch 36 | loss: 0.70907 |  0:01:21s\n",
            "epoch 37 | loss: 0.66247 |  0:01:24s\n",
            "epoch 38 | loss: 0.61384 |  0:01:27s\n",
            "epoch 39 | loss: 0.59706 |  0:01:29s\n",
            "epoch 40 | loss: 0.6     |  0:01:31s\n",
            "epoch 41 | loss: 0.61312 |  0:01:33s\n",
            "epoch 42 | loss: 0.61776 |  0:01:35s\n",
            "epoch 43 | loss: 0.6013  |  0:01:37s\n",
            "epoch 44 | loss: 0.59937 |  0:01:39s\n",
            "epoch 45 | loss: 0.63968 |  0:01:42s\n",
            "epoch 46 | loss: 0.61976 |  0:01:44s\n",
            "epoch 47 | loss: 0.60624 |  0:01:46s\n",
            "epoch 48 | loss: 0.60822 |  0:01:48s\n",
            "epoch 49 | loss: 0.61296 |  0:01:50s\n",
            "epoch 50 | loss: 0.5816  |  0:01:52s\n",
            "epoch 51 | loss: 0.60286 |  0:01:55s\n",
            "epoch 52 | loss: 0.60124 |  0:01:57s\n",
            "epoch 53 | loss: 0.60795 |  0:01:59s\n",
            "epoch 54 | loss: 0.61745 |  0:02:01s\n",
            "epoch 55 | loss: 0.62809 |  0:02:03s\n",
            "epoch 56 | loss: 0.58395 |  0:02:05s\n",
            "epoch 57 | loss: 0.62788 |  0:02:08s\n",
            "epoch 58 | loss: 0.61603 |  0:02:10s\n",
            "epoch 59 | loss: 0.72577 |  0:02:12s\n",
            "epoch 60 | loss: 0.65436 |  0:02:14s\n",
            "epoch 61 | loss: 0.57859 |  0:02:16s\n",
            "epoch 62 | loss: 0.61623 |  0:02:18s\n",
            "epoch 63 | loss: 0.65127 |  0:02:21s\n",
            "epoch 64 | loss: 0.65221 |  0:02:24s\n",
            "epoch 65 | loss: 0.6277  |  0:02:26s\n",
            "epoch 66 | loss: 0.60188 |  0:02:28s\n",
            "epoch 67 | loss: 0.58023 |  0:02:30s\n",
            "epoch 68 | loss: 0.64864 |  0:02:32s\n",
            "epoch 69 | loss: 0.5931  |  0:02:34s\n",
            "epoch 70 | loss: 0.59231 |  0:02:37s\n",
            "epoch 71 | loss: 0.60576 |  0:02:39s\n",
            "epoch 72 | loss: 0.59223 |  0:02:41s\n",
            "epoch 73 | loss: 0.59446 |  0:02:43s\n",
            "epoch 74 | loss: 0.63052 |  0:02:45s\n",
            "epoch 75 | loss: 0.59279 |  0:02:47s\n",
            "epoch 76 | loss: 0.59891 |  0:02:50s\n",
            "epoch 77 | loss: 0.67127 |  0:02:52s\n",
            "epoch 78 | loss: 0.60073 |  0:02:54s\n",
            "epoch 79 | loss: 0.57231 |  0:02:56s\n",
            "epoch 80 | loss: 0.63309 |  0:02:58s\n",
            "epoch 81 | loss: 0.59065 |  0:03:00s\n",
            "epoch 82 | loss: 0.5556  |  0:03:03s\n",
            "epoch 83 | loss: 0.58069 |  0:03:06s\n",
            "epoch 84 | loss: 0.56019 |  0:03:07s\n",
            "epoch 85 | loss: 0.55911 |  0:03:09s\n",
            "epoch 86 | loss: 0.55442 |  0:03:11s\n",
            "epoch 87 | loss: 0.57355 |  0:03:13s\n",
            "epoch 88 | loss: 0.57733 |  0:03:16s\n",
            "epoch 89 | loss: 0.55218 |  0:03:19s\n",
            "epoch 90 | loss: 0.59548 |  0:03:21s\n",
            "epoch 91 | loss: 0.60303 |  0:03:23s\n",
            "epoch 92 | loss: 0.63444 |  0:03:25s\n",
            "epoch 93 | loss: 0.70366 |  0:03:27s\n",
            "epoch 94 | loss: 0.62259 |  0:03:29s\n",
            "epoch 95 | loss: 0.5655  |  0:03:32s\n",
            "epoch 96 | loss: 0.57736 |  0:03:34s\n",
            "epoch 97 | loss: 0.59804 |  0:03:36s\n",
            "epoch 98 | loss: 0.59193 |  0:03:38s\n",
            "epoch 99 | loss: 0.5861  |  0:03:40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 9.16142 |  0:00:02s\n",
            "epoch 1  | loss: 2.13621 |  0:00:05s\n",
            "epoch 2  | loss: 1.70509 |  0:00:07s\n",
            "epoch 3  | loss: 1.59326 |  0:00:09s\n",
            "epoch 4  | loss: 1.5373  |  0:00:11s\n",
            "epoch 5  | loss: 1.36545 |  0:00:13s\n",
            "epoch 6  | loss: 1.32959 |  0:00:15s\n",
            "epoch 7  | loss: 1.26726 |  0:00:18s\n",
            "epoch 8  | loss: 1.31183 |  0:00:20s\n",
            "epoch 9  | loss: 1.33052 |  0:00:22s\n",
            "epoch 10 | loss: 1.36544 |  0:00:24s\n",
            "epoch 11 | loss: 1.29798 |  0:00:26s\n",
            "epoch 12 | loss: 1.27714 |  0:00:28s\n",
            "epoch 13 | loss: 1.24058 |  0:00:31s\n",
            "epoch 14 | loss: 1.33864 |  0:00:34s\n",
            "epoch 15 | loss: 1.61914 |  0:00:36s\n",
            "epoch 16 | loss: 1.61981 |  0:00:37s\n",
            "epoch 17 | loss: 1.44883 |  0:00:40s\n",
            "epoch 18 | loss: 1.21549 |  0:00:42s\n",
            "epoch 19 | loss: 1.21199 |  0:00:44s\n",
            "epoch 20 | loss: 1.20878 |  0:00:47s\n",
            "epoch 21 | loss: 1.1942  |  0:00:49s\n",
            "epoch 22 | loss: 1.23083 |  0:00:51s\n",
            "epoch 23 | loss: 1.27641 |  0:00:53s\n",
            "epoch 24 | loss: 1.28047 |  0:00:55s\n",
            "epoch 25 | loss: 1.25597 |  0:00:57s\n",
            "epoch 26 | loss: 1.29831 |  0:01:00s\n",
            "epoch 27 | loss: 1.29807 |  0:01:02s\n",
            "epoch 28 | loss: 1.21619 |  0:01:04s\n",
            "epoch 29 | loss: 1.17266 |  0:01:06s\n",
            "epoch 30 | loss: 1.23235 |  0:01:08s\n",
            "epoch 31 | loss: 1.22592 |  0:01:10s\n",
            "epoch 32 | loss: 1.17542 |  0:01:12s\n",
            "epoch 33 | loss: 1.32219 |  0:01:15s\n",
            "epoch 34 | loss: 1.22191 |  0:01:17s\n",
            "epoch 35 | loss: 1.19125 |  0:01:19s\n",
            "epoch 36 | loss: 1.20281 |  0:01:21s\n",
            "epoch 37 | loss: 1.20678 |  0:01:23s\n",
            "epoch 38 | loss: 1.15911 |  0:01:25s\n",
            "epoch 39 | loss: 1.16324 |  0:01:28s\n",
            "epoch 40 | loss: 1.24398 |  0:01:30s\n",
            "epoch 41 | loss: 1.43086 |  0:01:32s\n",
            "epoch 42 | loss: 1.27897 |  0:01:34s\n",
            "epoch 43 | loss: 1.16225 |  0:01:36s\n",
            "epoch 44 | loss: 1.18856 |  0:01:38s\n",
            "epoch 45 | loss: 1.14611 |  0:01:41s\n",
            "epoch 46 | loss: 1.27569 |  0:01:43s\n",
            "epoch 47 | loss: 1.19368 |  0:01:45s\n",
            "epoch 48 | loss: 1.13441 |  0:01:47s\n",
            "epoch 49 | loss: 1.14932 |  0:01:49s\n",
            "epoch 50 | loss: 1.16203 |  0:01:51s\n",
            "epoch 51 | loss: 1.161   |  0:01:54s\n",
            "epoch 52 | loss: 1.14279 |  0:01:57s\n",
            "epoch 53 | loss: 1.17737 |  0:01:58s\n",
            "epoch 54 | loss: 1.16543 |  0:02:01s\n",
            "epoch 55 | loss: 1.15296 |  0:02:03s\n",
            "epoch 56 | loss: 1.1219  |  0:02:05s\n",
            "epoch 57 | loss: 1.11651 |  0:02:07s\n",
            "epoch 58 | loss: 1.13166 |  0:02:10s\n",
            "epoch 59 | loss: 1.14494 |  0:02:12s\n",
            "epoch 60 | loss: 1.1468  |  0:02:14s\n",
            "epoch 61 | loss: 1.16271 |  0:02:16s\n",
            "epoch 62 | loss: 1.14109 |  0:02:18s\n",
            "epoch 63 | loss: 1.12412 |  0:02:20s\n",
            "epoch 64 | loss: 1.19849 |  0:02:22s\n",
            "epoch 65 | loss: 1.13023 |  0:02:25s\n",
            "epoch 66 | loss: 1.11016 |  0:02:27s\n",
            "epoch 67 | loss: 1.10161 |  0:02:29s\n",
            "epoch 68 | loss: 1.12738 |  0:02:31s\n",
            "epoch 69 | loss: 1.13178 |  0:02:33s\n",
            "epoch 70 | loss: 1.12516 |  0:02:35s\n",
            "epoch 71 | loss: 1.12168 |  0:02:38s\n",
            "epoch 72 | loss: 1.16251 |  0:02:40s\n",
            "epoch 73 | loss: 1.07811 |  0:02:42s\n",
            "epoch 74 | loss: 1.10245 |  0:02:44s\n",
            "epoch 75 | loss: 1.1029  |  0:02:46s\n",
            "epoch 76 | loss: 1.09136 |  0:02:48s\n",
            "epoch 77 | loss: 1.1023  |  0:02:50s\n",
            "epoch 78 | loss: 1.13305 |  0:02:53s\n",
            "epoch 79 | loss: 1.10664 |  0:02:55s\n",
            "epoch 80 | loss: 1.14248 |  0:02:57s\n",
            "epoch 81 | loss: 1.1988  |  0:02:59s\n",
            "epoch 82 | loss: 1.14582 |  0:03:01s\n",
            "epoch 83 | loss: 1.11396 |  0:03:03s\n",
            "epoch 84 | loss: 1.18462 |  0:03:06s\n",
            "epoch 85 | loss: 1.0854  |  0:03:08s\n",
            "epoch 86 | loss: 1.09047 |  0:03:10s\n",
            "epoch 87 | loss: 1.14101 |  0:03:12s\n",
            "epoch 88 | loss: 1.15767 |  0:03:14s\n",
            "epoch 89 | loss: 1.12035 |  0:03:16s\n",
            "epoch 90 | loss: 1.11585 |  0:03:18s\n",
            "epoch 91 | loss: 1.15825 |  0:03:21s\n",
            "epoch 92 | loss: 1.16129 |  0:03:23s\n",
            "epoch 93 | loss: 1.12489 |  0:03:25s\n",
            "epoch 94 | loss: 1.16919 |  0:03:27s\n",
            "epoch 95 | loss: 1.15134 |  0:03:29s\n",
            "epoch 96 | loss: 1.10791 |  0:03:31s\n",
            "epoch 97 | loss: 1.11182 |  0:03:34s\n",
            "epoch 98 | loss: 1.1246  |  0:03:36s\n",
            "epoch 99 | loss: 1.08335 |  0:03:38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 21.5335 |  0:00:02s\n",
            "epoch 1  | loss: 1.57828 |  0:00:03s\n",
            "epoch 2  | loss: 1.201   |  0:00:06s\n",
            "epoch 3  | loss: 1.16732 |  0:00:09s\n",
            "epoch 4  | loss: 1.06061 |  0:00:11s\n",
            "epoch 5  | loss: 0.81382 |  0:00:13s\n",
            "epoch 6  | loss: 0.85365 |  0:00:15s\n",
            "epoch 7  | loss: 0.8639  |  0:00:17s\n",
            "epoch 8  | loss: 0.84015 |  0:00:19s\n",
            "epoch 9  | loss: 0.77283 |  0:00:22s\n",
            "epoch 10 | loss: 0.73292 |  0:00:24s\n",
            "epoch 11 | loss: 0.70862 |  0:00:26s\n",
            "epoch 12 | loss: 0.7868  |  0:00:28s\n",
            "epoch 13 | loss: 0.76377 |  0:00:30s\n",
            "epoch 14 | loss: 0.69611 |  0:00:32s\n",
            "epoch 15 | loss: 0.69984 |  0:00:35s\n",
            "epoch 16 | loss: 0.67382 |  0:00:37s\n",
            "epoch 17 | loss: 0.71942 |  0:00:39s\n",
            "epoch 18 | loss: 0.70602 |  0:00:41s\n",
            "epoch 19 | loss: 0.68127 |  0:00:43s\n",
            "epoch 20 | loss: 0.79412 |  0:00:45s\n",
            "epoch 21 | loss: 0.74159 |  0:00:48s\n",
            "epoch 22 | loss: 0.69815 |  0:00:51s\n",
            "epoch 23 | loss: 0.65708 |  0:00:53s\n",
            "epoch 24 | loss: 0.68139 |  0:00:55s\n",
            "epoch 25 | loss: 0.66103 |  0:00:57s\n",
            "epoch 26 | loss: 0.66799 |  0:00:59s\n",
            "epoch 27 | loss: 0.67745 |  0:01:01s\n",
            "epoch 28 | loss: 0.6563  |  0:01:04s\n",
            "epoch 29 | loss: 0.72004 |  0:01:06s\n",
            "epoch 30 | loss: 0.67524 |  0:01:08s\n",
            "epoch 31 | loss: 0.66341 |  0:01:10s\n",
            "epoch 32 | loss: 0.66666 |  0:01:12s\n",
            "epoch 33 | loss: 0.66726 |  0:01:14s\n",
            "epoch 34 | loss: 0.69937 |  0:01:17s\n",
            "epoch 35 | loss: 0.74674 |  0:01:20s\n",
            "epoch 36 | loss: 0.65617 |  0:01:22s\n",
            "epoch 37 | loss: 0.65431 |  0:01:24s\n",
            "epoch 38 | loss: 0.7042  |  0:01:26s\n",
            "epoch 39 | loss: 0.68232 |  0:01:28s\n",
            "epoch 40 | loss: 0.67065 |  0:01:30s\n",
            "epoch 41 | loss: 0.648   |  0:01:33s\n",
            "epoch 42 | loss: 0.6244  |  0:01:35s\n",
            "epoch 43 | loss: 0.63229 |  0:01:37s\n",
            "epoch 44 | loss: 0.64361 |  0:01:39s\n",
            "epoch 45 | loss: 0.69742 |  0:01:41s\n",
            "epoch 46 | loss: 0.69087 |  0:01:43s\n",
            "epoch 47 | loss: 0.63911 |  0:01:46s\n",
            "epoch 48 | loss: 0.70392 |  0:01:48s\n",
            "epoch 49 | loss: 0.75851 |  0:01:50s\n",
            "epoch 50 | loss: 0.67281 |  0:01:52s\n",
            "epoch 51 | loss: 0.65904 |  0:01:54s\n",
            "epoch 52 | loss: 0.68471 |  0:01:56s\n",
            "epoch 53 | loss: 0.79224 |  0:01:59s\n",
            "epoch 54 | loss: 0.69083 |  0:02:01s\n",
            "epoch 55 | loss: 0.69728 |  0:02:03s\n",
            "epoch 56 | loss: 0.67884 |  0:02:05s\n",
            "epoch 57 | loss: 0.63945 |  0:02:07s\n",
            "epoch 58 | loss: 0.63813 |  0:02:09s\n",
            "epoch 59 | loss: 0.68431 |  0:02:12s\n",
            "epoch 60 | loss: 0.66614 |  0:02:14s\n",
            "epoch 61 | loss: 0.6603  |  0:02:16s\n",
            "epoch 62 | loss: 0.65179 |  0:02:18s\n",
            "epoch 63 | loss: 0.65899 |  0:02:20s\n",
            "epoch 64 | loss: 0.60894 |  0:02:22s\n",
            "epoch 65 | loss: 0.608   |  0:02:24s\n",
            "epoch 66 | loss: 0.60158 |  0:02:27s\n",
            "epoch 67 | loss: 0.61686 |  0:02:29s\n",
            "epoch 68 | loss: 0.61596 |  0:02:31s\n",
            "epoch 69 | loss: 0.5946  |  0:02:33s\n",
            "epoch 70 | loss: 0.63514 |  0:02:35s\n",
            "epoch 71 | loss: 0.64632 |  0:02:37s\n",
            "epoch 72 | loss: 0.6552  |  0:02:40s\n",
            "epoch 73 | loss: 0.64158 |  0:02:42s\n",
            "epoch 74 | loss: 0.62601 |  0:02:44s\n",
            "epoch 75 | loss: 0.69835 |  0:02:46s\n",
            "epoch 76 | loss: 0.66218 |  0:02:48s\n",
            "epoch 77 | loss: 0.67281 |  0:02:50s\n",
            "epoch 78 | loss: 0.64341 |  0:02:52s\n",
            "epoch 79 | loss: 0.65191 |  0:02:55s\n",
            "epoch 80 | loss: 0.62538 |  0:02:58s\n",
            "epoch 81 | loss: 0.62359 |  0:03:00s\n",
            "epoch 82 | loss: 0.60695 |  0:03:02s\n",
            "epoch 83 | loss: 0.65622 |  0:03:04s\n",
            "epoch 84 | loss: 0.71823 |  0:03:06s\n",
            "epoch 85 | loss: 0.67603 |  0:03:08s\n",
            "epoch 86 | loss: 0.64089 |  0:03:11s\n",
            "epoch 87 | loss: 0.62109 |  0:03:13s\n",
            "epoch 88 | loss: 0.62646 |  0:03:15s\n",
            "epoch 89 | loss: 0.62896 |  0:03:17s\n",
            "epoch 90 | loss: 0.62743 |  0:03:19s\n",
            "epoch 91 | loss: 0.61096 |  0:03:21s\n",
            "epoch 92 | loss: 0.61004 |  0:03:24s\n",
            "epoch 93 | loss: 0.62209 |  0:03:26s\n",
            "epoch 94 | loss: 0.65053 |  0:03:28s\n",
            "epoch 95 | loss: 0.61859 |  0:03:30s\n",
            "epoch 96 | loss: 0.60236 |  0:03:32s\n",
            "epoch 97 | loss: 0.5867  |  0:03:34s\n",
            "epoch 98 | loss: 0.61279 |  0:03:37s\n",
            "epoch 99 | loss: 0.59075 |  0:03:39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 10.21876|  0:00:01s\n",
            "epoch 1  | loss: 2.65577 |  0:00:03s\n",
            "epoch 2  | loss: 1.82927 |  0:00:06s\n",
            "epoch 3  | loss: 1.41902 |  0:00:08s\n",
            "epoch 4  | loss: 1.49402 |  0:00:11s\n",
            "epoch 5  | loss: 1.25948 |  0:00:13s\n",
            "epoch 6  | loss: 1.2738  |  0:00:15s\n",
            "epoch 7  | loss: 1.27014 |  0:00:17s\n",
            "epoch 8  | loss: 1.54701 |  0:00:19s\n",
            "epoch 9  | loss: 1.32869 |  0:00:21s\n",
            "epoch 10 | loss: 1.26286 |  0:00:24s\n",
            "epoch 11 | loss: 1.15136 |  0:00:26s\n",
            "epoch 12 | loss: 1.11751 |  0:00:28s\n",
            "epoch 13 | loss: 1.09888 |  0:00:30s\n",
            "epoch 14 | loss: 1.13825 |  0:00:32s\n",
            "epoch 15 | loss: 1.07282 |  0:00:34s\n",
            "epoch 16 | loss: 1.0843  |  0:00:37s\n",
            "epoch 17 | loss: 1.11299 |  0:00:39s\n",
            "epoch 18 | loss: 1.07358 |  0:00:41s\n",
            "epoch 19 | loss: 1.02885 |  0:00:43s\n",
            "epoch 20 | loss: 1.03714 |  0:00:45s\n",
            "epoch 21 | loss: 1.06107 |  0:00:47s\n",
            "epoch 22 | loss: 1.0552  |  0:00:50s\n",
            "epoch 23 | loss: 1.09752 |  0:00:52s\n",
            "epoch 24 | loss: 1.0533  |  0:00:54s\n",
            "epoch 25 | loss: 1.13986 |  0:00:57s\n",
            "epoch 26 | loss: 1.04175 |  0:00:59s\n",
            "epoch 27 | loss: 1.04003 |  0:01:01s\n",
            "epoch 28 | loss: 1.04133 |  0:01:03s\n",
            "epoch 29 | loss: 1.03811 |  0:01:06s\n",
            "epoch 30 | loss: 1.00941 |  0:01:08s\n",
            "epoch 31 | loss: 1.02649 |  0:01:10s\n",
            "epoch 32 | loss: 1.00604 |  0:01:12s\n",
            "epoch 33 | loss: 1.02948 |  0:01:14s\n",
            "epoch 34 | loss: 1.06242 |  0:01:16s\n",
            "epoch 35 | loss: 1.04252 |  0:01:19s\n",
            "epoch 36 | loss: 1.0475  |  0:01:21s\n",
            "epoch 37 | loss: 1.04207 |  0:01:23s\n",
            "epoch 38 | loss: 1.03309 |  0:01:25s\n",
            "epoch 39 | loss: 1.0217  |  0:01:27s\n",
            "epoch 40 | loss: 1.0082  |  0:01:29s\n",
            "epoch 41 | loss: 1.0289  |  0:01:32s\n",
            "epoch 42 | loss: 1.01023 |  0:01:35s\n",
            "epoch 43 | loss: 1.05129 |  0:01:37s\n",
            "epoch 44 | loss: 1.07566 |  0:01:39s\n",
            "epoch 45 | loss: 1.03045 |  0:01:41s\n",
            "epoch 46 | loss: 0.96601 |  0:01:43s\n",
            "epoch 47 | loss: 1.00607 |  0:01:45s\n",
            "epoch 48 | loss: 1.06895 |  0:01:48s\n",
            "epoch 49 | loss: 1.03201 |  0:01:50s\n",
            "epoch 50 | loss: 1.02293 |  0:01:52s\n",
            "epoch 51 | loss: 1.00638 |  0:01:54s\n",
            "epoch 52 | loss: 0.99571 |  0:01:56s\n",
            "epoch 53 | loss: 1.02026 |  0:01:58s\n",
            "epoch 54 | loss: 1.0771  |  0:02:01s\n",
            "epoch 55 | loss: 1.11023 |  0:02:03s\n",
            "epoch 56 | loss: 1.04077 |  0:02:05s\n",
            "epoch 57 | loss: 1.03318 |  0:02:07s\n",
            "epoch 58 | loss: 0.9949  |  0:02:09s\n",
            "epoch 59 | loss: 0.99401 |  0:02:11s\n",
            "epoch 60 | loss: 1.02348 |  0:02:14s\n",
            "epoch 61 | loss: 0.98008 |  0:02:17s\n",
            "epoch 62 | loss: 1.01536 |  0:02:19s\n",
            "epoch 63 | loss: 1.01675 |  0:02:21s\n",
            "epoch 64 | loss: 1.02051 |  0:02:23s\n",
            "epoch 65 | loss: 1.12642 |  0:02:25s\n",
            "epoch 66 | loss: 0.99541 |  0:02:27s\n",
            "epoch 67 | loss: 0.9845  |  0:02:30s\n",
            "epoch 68 | loss: 1.07505 |  0:02:32s\n",
            "epoch 69 | loss: 1.10343 |  0:02:34s\n",
            "epoch 70 | loss: 0.98902 |  0:02:36s\n",
            "epoch 71 | loss: 1.05094 |  0:02:38s\n",
            "epoch 72 | loss: 0.94882 |  0:02:40s\n",
            "epoch 73 | loss: 0.9445  |  0:02:43s\n",
            "epoch 74 | loss: 1.02144 |  0:02:46s\n",
            "epoch 75 | loss: 1.06186 |  0:02:47s\n",
            "epoch 76 | loss: 1.05872 |  0:02:49s\n",
            "epoch 77 | loss: 1.01556 |  0:02:51s\n",
            "epoch 78 | loss: 0.96892 |  0:02:53s\n",
            "epoch 79 | loss: 0.99764 |  0:02:56s\n",
            "epoch 80 | loss: 1.06044 |  0:02:59s\n",
            "epoch 81 | loss: 0.98017 |  0:03:01s\n",
            "epoch 82 | loss: 0.96963 |  0:03:03s\n",
            "epoch 83 | loss: 0.9587  |  0:03:05s\n",
            "epoch 84 | loss: 0.9541  |  0:03:07s\n",
            "epoch 85 | loss: 0.99105 |  0:03:09s\n",
            "epoch 86 | loss: 0.9968  |  0:03:12s\n",
            "epoch 87 | loss: 0.98249 |  0:03:14s\n",
            "epoch 88 | loss: 0.95518 |  0:03:16s\n",
            "epoch 89 | loss: 0.94012 |  0:03:18s\n",
            "epoch 90 | loss: 0.97829 |  0:03:20s\n",
            "epoch 91 | loss: 0.94465 |  0:03:22s\n",
            "epoch 92 | loss: 0.94532 |  0:03:25s\n",
            "epoch 93 | loss: 0.96097 |  0:03:27s\n",
            "epoch 94 | loss: 1.00667 |  0:03:29s\n",
            "epoch 95 | loss: 0.96871 |  0:03:31s\n",
            "epoch 96 | loss: 0.9672  |  0:03:33s\n",
            "epoch 97 | loss: 0.96747 |  0:03:35s\n",
            "epoch 98 | loss: 0.983   |  0:03:38s\n",
            "epoch 99 | loss: 0.9921  |  0:03:41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 11.22081|  0:00:01s\n",
            "epoch 1  | loss: 2.0856  |  0:00:03s\n",
            "epoch 2  | loss: 1.69733 |  0:00:05s\n",
            "epoch 3  | loss: 1.29151 |  0:00:07s\n",
            "epoch 4  | loss: 1.52768 |  0:00:10s\n",
            "epoch 5  | loss: 1.16419 |  0:00:13s\n",
            "epoch 6  | loss: 0.992   |  0:00:15s\n",
            "epoch 7  | loss: 0.90353 |  0:00:17s\n",
            "epoch 8  | loss: 0.79526 |  0:00:19s\n",
            "epoch 9  | loss: 0.81329 |  0:00:20s\n",
            "epoch 10 | loss: 0.84324 |  0:00:23s\n",
            "epoch 11 | loss: 0.76188 |  0:00:26s\n",
            "epoch 12 | loss: 0.80412 |  0:00:28s\n",
            "epoch 13 | loss: 0.74347 |  0:00:30s\n",
            "epoch 14 | loss: 0.74744 |  0:00:32s\n",
            "epoch 15 | loss: 0.71387 |  0:00:34s\n",
            "epoch 16 | loss: 0.70103 |  0:00:36s\n",
            "epoch 17 | loss: 0.67713 |  0:00:39s\n",
            "epoch 18 | loss: 0.76664 |  0:00:41s\n",
            "epoch 19 | loss: 0.70121 |  0:00:43s\n",
            "epoch 20 | loss: 0.66839 |  0:00:45s\n",
            "epoch 21 | loss: 0.65796 |  0:00:47s\n",
            "epoch 22 | loss: 0.75698 |  0:00:49s\n",
            "epoch 23 | loss: 0.8425  |  0:00:52s\n",
            "epoch 24 | loss: 0.73741 |  0:00:54s\n",
            "epoch 25 | loss: 0.71223 |  0:00:56s\n",
            "epoch 26 | loss: 0.68961 |  0:00:58s\n",
            "epoch 27 | loss: 0.74515 |  0:01:00s\n",
            "epoch 28 | loss: 0.73577 |  0:01:02s\n",
            "epoch 29 | loss: 0.72224 |  0:01:05s\n",
            "epoch 30 | loss: 0.74343 |  0:01:08s\n",
            "epoch 31 | loss: 0.68197 |  0:01:10s\n",
            "epoch 32 | loss: 0.74108 |  0:01:12s\n",
            "epoch 33 | loss: 0.69692 |  0:01:14s\n",
            "epoch 34 | loss: 0.70251 |  0:01:16s\n",
            "epoch 35 | loss: 0.7126  |  0:01:18s\n",
            "epoch 36 | loss: 0.74717 |  0:01:21s\n",
            "epoch 37 | loss: 0.70648 |  0:01:23s\n",
            "epoch 38 | loss: 0.68229 |  0:01:25s\n",
            "epoch 39 | loss: 0.68845 |  0:01:27s\n",
            "epoch 40 | loss: 0.69868 |  0:01:29s\n",
            "epoch 41 | loss: 0.68207 |  0:01:31s\n",
            "epoch 42 | loss: 0.69379 |  0:01:34s\n",
            "epoch 43 | loss: 0.66637 |  0:01:36s\n",
            "epoch 44 | loss: 0.66316 |  0:01:38s\n",
            "epoch 45 | loss: 0.64463 |  0:01:40s\n",
            "epoch 46 | loss: 0.65616 |  0:01:42s\n",
            "epoch 47 | loss: 0.64345 |  0:01:44s\n",
            "epoch 48 | loss: 0.77746 |  0:01:47s\n",
            "epoch 49 | loss: 0.66355 |  0:01:50s\n",
            "epoch 50 | loss: 0.64887 |  0:01:52s\n",
            "epoch 51 | loss: 0.66782 |  0:01:54s\n",
            "epoch 52 | loss: 0.65845 |  0:01:56s\n",
            "epoch 53 | loss: 0.64091 |  0:01:58s\n",
            "epoch 54 | loss: 0.623   |  0:02:00s\n",
            "epoch 55 | loss: 0.65226 |  0:02:03s\n",
            "epoch 56 | loss: 0.61147 |  0:02:05s\n",
            "epoch 57 | loss: 0.70464 |  0:02:07s\n",
            "epoch 58 | loss: 0.75126 |  0:02:09s\n",
            "epoch 59 | loss: 0.70032 |  0:02:11s\n",
            "epoch 60 | loss: 0.64495 |  0:02:13s\n",
            "epoch 61 | loss: 0.72141 |  0:02:16s\n",
            "epoch 62 | loss: 0.64766 |  0:02:19s\n",
            "epoch 63 | loss: 0.75236 |  0:02:21s\n",
            "epoch 64 | loss: 0.62972 |  0:02:23s\n",
            "epoch 65 | loss: 0.64056 |  0:02:25s\n",
            "epoch 66 | loss: 0.6181  |  0:02:27s\n",
            "epoch 67 | loss: 0.59887 |  0:02:30s\n",
            "epoch 68 | loss: 0.59538 |  0:02:32s\n",
            "epoch 69 | loss: 0.60554 |  0:02:34s\n",
            "epoch 70 | loss: 0.63869 |  0:02:36s\n",
            "epoch 71 | loss: 0.60584 |  0:02:38s\n",
            "epoch 72 | loss: 0.67248 |  0:02:40s\n",
            "epoch 73 | loss: 0.71167 |  0:02:43s\n",
            "epoch 74 | loss: 0.60282 |  0:02:45s\n",
            "epoch 75 | loss: 0.60758 |  0:02:48s\n",
            "epoch 76 | loss: 0.61458 |  0:02:50s\n",
            "epoch 77 | loss: 0.66214 |  0:02:51s\n",
            "epoch 78 | loss: 0.63295 |  0:02:54s\n",
            "epoch 79 | loss: 0.60114 |  0:02:56s\n",
            "epoch 80 | loss: 0.61614 |  0:02:59s\n",
            "epoch 81 | loss: 0.59814 |  0:03:01s\n",
            "epoch 82 | loss: 0.64948 |  0:03:03s\n",
            "epoch 83 | loss: 0.64933 |  0:03:05s\n",
            "epoch 84 | loss: 0.64415 |  0:03:07s\n",
            "epoch 85 | loss: 0.60063 |  0:03:09s\n",
            "epoch 86 | loss: 0.6     |  0:03:12s\n",
            "epoch 87 | loss: 0.60851 |  0:03:14s\n",
            "epoch 88 | loss: 0.59241 |  0:03:16s\n",
            "epoch 89 | loss: 0.5853  |  0:03:18s\n",
            "epoch 90 | loss: 0.57066 |  0:03:20s\n",
            "epoch 91 | loss: 0.60832 |  0:03:22s\n",
            "epoch 92 | loss: 0.57923 |  0:03:25s\n",
            "epoch 93 | loss: 0.59229 |  0:03:28s\n",
            "epoch 94 | loss: 0.5717  |  0:03:30s\n",
            "epoch 95 | loss: 0.59668 |  0:03:32s\n",
            "epoch 96 | loss: 0.61405 |  0:03:34s\n",
            "epoch 97 | loss: 0.58753 |  0:03:36s\n",
            "epoch 98 | loss: 0.59412 |  0:03:38s\n",
            "epoch 99 | loss: 0.63291 |  0:03:41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 11.91547|  0:00:02s\n",
            "epoch 1  | loss: 3.92292 |  0:00:04s\n",
            "epoch 2  | loss: 2.69444 |  0:00:06s\n",
            "epoch 3  | loss: 1.82479 |  0:00:08s\n",
            "epoch 4  | loss: 1.65187 |  0:00:10s\n",
            "epoch 5  | loss: 1.55213 |  0:00:13s\n",
            "epoch 6  | loss: 1.60008 |  0:00:15s\n",
            "epoch 7  | loss: 1.54712 |  0:00:17s\n",
            "epoch 8  | loss: 1.75638 |  0:00:19s\n",
            "epoch 9  | loss: 1.55953 |  0:00:21s\n",
            "epoch 10 | loss: 1.59154 |  0:00:23s\n",
            "epoch 11 | loss: 1.52209 |  0:00:26s\n",
            "epoch 12 | loss: 1.46754 |  0:00:28s\n",
            "epoch 13 | loss: 1.49198 |  0:00:30s\n",
            "epoch 14 | loss: 1.50745 |  0:00:32s\n",
            "epoch 15 | loss: 1.56514 |  0:00:34s\n",
            "epoch 16 | loss: 1.76418 |  0:00:36s\n",
            "epoch 17 | loss: 1.48169 |  0:00:39s\n",
            "epoch 18 | loss: 1.52631 |  0:00:42s\n",
            "epoch 19 | loss: 1.46732 |  0:00:44s\n",
            "epoch 20 | loss: 1.59984 |  0:00:46s\n",
            "epoch 21 | loss: 1.4755  |  0:00:48s\n",
            "epoch 22 | loss: 1.40596 |  0:00:50s\n",
            "epoch 23 | loss: 1.45197 |  0:00:53s\n",
            "epoch 24 | loss: 1.43538 |  0:00:55s\n",
            "epoch 25 | loss: 1.55562 |  0:00:57s\n",
            "epoch 26 | loss: 1.42517 |  0:00:59s\n",
            "epoch 27 | loss: 1.50629 |  0:01:01s\n",
            "epoch 28 | loss: 1.38345 |  0:01:03s\n",
            "epoch 29 | loss: 1.44915 |  0:01:06s\n",
            "epoch 30 | loss: 1.43999 |  0:01:08s\n",
            "epoch 31 | loss: 1.40897 |  0:01:10s\n",
            "epoch 32 | loss: 1.46195 |  0:01:12s\n",
            "epoch 33 | loss: 1.47405 |  0:01:14s\n",
            "epoch 34 | loss: 1.40622 |  0:01:16s\n",
            "epoch 35 | loss: 1.44063 |  0:01:18s\n",
            "epoch 36 | loss: 1.44347 |  0:01:21s\n",
            "epoch 37 | loss: 1.38374 |  0:01:24s\n",
            "epoch 38 | loss: 1.36466 |  0:01:26s\n",
            "epoch 39 | loss: 1.40736 |  0:01:28s\n",
            "epoch 40 | loss: 1.38714 |  0:01:30s\n",
            "epoch 41 | loss: 1.43737 |  0:01:32s\n",
            "epoch 42 | loss: 1.41316 |  0:01:35s\n",
            "epoch 43 | loss: 1.40898 |  0:01:37s\n",
            "epoch 44 | loss: 1.36781 |  0:01:39s\n",
            "epoch 45 | loss: 1.37911 |  0:01:41s\n",
            "epoch 46 | loss: 1.37691 |  0:01:43s\n",
            "epoch 47 | loss: 1.4445  |  0:01:45s\n",
            "epoch 48 | loss: 1.44002 |  0:01:48s\n",
            "epoch 49 | loss: 1.34649 |  0:01:50s\n",
            "epoch 50 | loss: 1.36695 |  0:01:52s\n",
            "epoch 51 | loss: 1.41204 |  0:01:54s\n",
            "epoch 52 | loss: 1.36626 |  0:01:56s\n",
            "epoch 53 | loss: 1.38949 |  0:01:58s\n",
            "epoch 54 | loss: 1.40694 |  0:02:01s\n",
            "epoch 55 | loss: 1.38605 |  0:02:04s\n",
            "epoch 56 | loss: 1.42143 |  0:02:06s\n",
            "epoch 57 | loss: 1.39793 |  0:02:08s\n",
            "epoch 58 | loss: 1.38096 |  0:02:10s\n",
            "epoch 59 | loss: 1.40339 |  0:02:12s\n",
            "epoch 60 | loss: 1.39731 |  0:02:14s\n",
            "epoch 61 | loss: 1.35224 |  0:02:17s\n",
            "epoch 62 | loss: 1.36377 |  0:02:19s\n",
            "epoch 63 | loss: 1.40646 |  0:02:21s\n",
            "epoch 64 | loss: 1.48256 |  0:02:23s\n",
            "epoch 65 | loss: 1.41055 |  0:02:25s\n",
            "epoch 66 | loss: 1.3959  |  0:02:27s\n",
            "epoch 67 | loss: 1.49475 |  0:02:30s\n",
            "epoch 68 | loss: 1.35213 |  0:02:33s\n",
            "epoch 69 | loss: 1.3913  |  0:02:35s\n",
            "epoch 70 | loss: 1.39881 |  0:02:37s\n",
            "epoch 71 | loss: 1.43562 |  0:02:39s\n",
            "epoch 72 | loss: 1.436   |  0:02:41s\n",
            "epoch 73 | loss: 1.48467 |  0:02:44s\n",
            "epoch 74 | loss: 1.38151 |  0:02:46s\n",
            "epoch 75 | loss: 1.33966 |  0:02:48s\n",
            "epoch 76 | loss: 1.38763 |  0:02:50s\n",
            "epoch 77 | loss: 1.35877 |  0:02:53s\n",
            "epoch 78 | loss: 1.36626 |  0:02:54s\n",
            "epoch 79 | loss: 1.37715 |  0:02:57s\n",
            "epoch 80 | loss: 1.35889 |  0:03:00s\n",
            "epoch 81 | loss: 1.35868 |  0:03:02s\n",
            "epoch 82 | loss: 1.354   |  0:03:04s\n",
            "epoch 83 | loss: 1.39237 |  0:03:06s\n",
            "epoch 84 | loss: 1.39024 |  0:03:08s\n",
            "epoch 85 | loss: 1.35576 |  0:03:10s\n",
            "epoch 86 | loss: 1.32285 |  0:03:13s\n",
            "epoch 87 | loss: 1.36492 |  0:03:15s\n",
            "epoch 88 | loss: 1.40715 |  0:03:17s\n",
            "epoch 89 | loss: 1.43647 |  0:03:19s\n",
            "epoch 90 | loss: 1.33371 |  0:03:21s\n",
            "epoch 91 | loss: 1.36943 |  0:03:23s\n",
            "epoch 92 | loss: 1.33258 |  0:03:26s\n",
            "epoch 93 | loss: 1.35466 |  0:03:29s\n",
            "epoch 94 | loss: 1.33451 |  0:03:31s\n",
            "epoch 95 | loss: 1.36154 |  0:03:33s\n",
            "epoch 96 | loss: 1.32901 |  0:03:35s\n",
            "epoch 97 | loss: 1.40507 |  0:03:37s\n",
            "epoch 98 | loss: 1.34296 |  0:03:39s\n",
            "epoch 99 | loss: 1.32759 |  0:03:42s\n",
            "Best Score: 0.41818692867350593\n",
            "Best Parameters: {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n"
          ]
        }
      ],
      "source": [
        "initial_columns = ['namsinh', 'gioitinh', 'dtb_toankhoa', 'dtb_tichluy', 'sotc_tichluy', 'diemtbhk_1']\n",
        "\n",
        "# Duyệt qua các bộ tham số\n",
        "for params in grid:\n",
        "    # Khởi tạo mô hình TabNetRegressor với tham số\n",
        "    model = TabNetRegressor(\n",
        "        n_d=params['n_d'],\n",
        "        n_a=params['n_a'],\n",
        "        n_steps=params['n_steps'],\n",
        "    )\n",
        "\n",
        "    # Biến lưu kết quả\n",
        "    results = []\n",
        "    current_X_columns = initial_columns.copy()\n",
        "\n",
        "    # Lặp qua từng cột làm biến mục tiêu (y)\n",
        "    for i in range(len(initial_columns) + 1, len(df.columns) - 1):\n",
        "        if i + 2 >= len(df.columns):\n",
        "            break\n",
        "\n",
        "        # Xác định cột mục tiêu (y)\n",
        "        target_column = df.columns[i + 2]\n",
        "\n",
        "        # Xác định tập huấn luyện và kiểm tra\n",
        "        X_train = df[current_X_columns].values\n",
        "        y_train = df[target_column].values\n",
        "\n",
        "        X_test = df_test[current_X_columns].values\n",
        "        y_test = df_test[target_column].values\n",
        "\n",
        "        # Huấn luyện mô hình\n",
        "        model.fit(\n",
        "            X_train, y_train.reshape(-1, 1),\n",
        "            max_epochs=100,\n",
        "            patience=10,\n",
        "        )\n",
        "\n",
        "        # Dự đoán\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Đánh giá hiệu suất\n",
        "        mse = np.mean((y_test - y_pred.ravel()) ** 2)  # Mean Squared Error\n",
        "        if mse < best_score:\n",
        "            best_score = mse\n",
        "            best_model = model\n",
        "\n",
        "        # Ghi lại kết quả\n",
        "        results.append({\n",
        "            \"Target Column\": target_column,\n",
        "            \"MSE\": mse,\n",
        "            \"Params\": params\n",
        "        })\n",
        "\n",
        "        # Cập nhật X với cột mới\n",
        "        current_X_columns.append(target_column)\n",
        "\n",
        "# In kết quả tốt nhất\n",
        "print(f\"Best Score: {best_score}\")\n",
        "print(f\"Best Parameters: {params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Oryb-lSBDxEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcbfe2b-0910-4643-9365-8d132c1befa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Target Column       MSE                                Params\n",
            "0    diemtbhk_2  0.822017  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "1    diemtbhk_3  0.593918  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "2    diemtbhk_4  0.939546  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "3    diemtbhk_5  0.569321  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "4    diemtbhk_6  1.103035  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "5    diemtbhk_7  0.501742  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n",
            "6    diemtbhk_8  1.412368  {'n_a': 48, 'n_d': 48, 'n_steps': 7}\n"
          ]
        }
      ],
      "source": [
        "# Tạo DataFrame kết quả\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"tabnet_model_results.csv\", index=False)\n",
        "\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8k7JrKIwDydg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "de5728ec-28ab-4ae2-8dd2-3290fb4c993d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'R2 Score'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'R2 Score'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7e86c4fc7a62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R2 Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'R2 Score'"
          ]
        }
      ],
      "source": [
        "print(results_df['R2 Score'].mean())\n",
        "print(results_df['MSE'].mean())\n",
        "print(results_df['RMSE'].mean())\n",
        "print(results_df['MAE'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbgrCduJjyLB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}